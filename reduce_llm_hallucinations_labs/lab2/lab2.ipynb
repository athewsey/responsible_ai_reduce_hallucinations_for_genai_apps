{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98851f24-a2f5-42c6-8435-219764f5af33",
   "metadata": {},
   "source": [
    "  <center><img src=\"images/2024_reInvent_Logo_wDate_Black_V3.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# <a name=\"0\">AWS re:Invent 2024 | Lab 2: Detect, Measure and Remediate hallucinations  </a>\n",
    "## <a name=\"0\">Using Amazon Bedrock Agents for custom intervention when hallucinations are detected </a>\n",
    "\n",
    "## Lab Overview\n",
    "\n",
    "In this lab, we will set up our own custom workflow to intervene when hallucinations are detected by using [Amazon Bedrock Agents](https://aws.amazon.com/bedrock/agents/) and route to customer service agents bringing in humans in the loop.\n",
    "\n",
    "\n",
    "##### Notebook Kernel\n",
    "Please choose `Python3` as the kernel type of the top right corner of the notebook if that does not appear by default.\n",
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px\">\n",
    "    <h4>This lab auto-cleans up resources to be frugal. </h4>\n",
    "    You can visit this section (<a href=\"#10\"> Clean-up Resources</a>) to change the setting if you need to experiment with prompts and settings. Please run clean-up resources after you are done with experiments. <br/>\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "\n",
    "## Use-Case Overview\n",
    "We want to add our own custom intervention to the RAG powered chatbot we developed in Lab 1.\n",
    "We will be using few of the RAGAS metrics like `answer correctness` and `answer similarity` to develop a custom hallucination score for measuring hallucinations. If the custom hallucination score is less than a custom threshold it indicates that the generated model response is not well aligned with the ground truth. In this situation, we notify a pool of human agents via SNS notification to assist with the query instead of providing the customer with hallucinated model response.\n",
    "\n",
    "\n",
    "To set up this workflow, we leverage AWS services like Amazon Bedrock Agents, Lambdas, Amazon Knowledge Bases as shown in the architecture diagram :\n",
    "\n",
    "The overall workflow involves the following steps as given in the diagram:\n",
    "0. Data Ingestion - S3 raw PDFs ingested to Amazon Knowledge base (we covered this in Lab 1) \n",
    "1. User asks the agent a question relevant to Bedrock User Guide.\n",
    "2. Agent searches for an answer inside the knowledge base.\n",
    "3. The query search goes inside vector database. We are using Opensearch Serverless.\n",
    "4. Relevant answer chunks are retrieved.\n",
    "5. Knowledge base response is generated using `retrieve and generate` api. (covered in lab 1)\n",
    "6. User question and kb response are used to invoke right action group\n",
    "7. User question and kb response are passed as Lambda inputs to calculate hallucination score\n",
    "8. send SNS notification if answer score is lower than the custom threshold (0.9)\n",
    "9. Lambda responds with final KB response if there is no hallucination else sends response that customer agent has been asked to join shortly.\n",
    "10. Final agent response shown to customer UI as elaborated in above step.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"images/lab2-reinvent-arch-diagram-v1.png\" alt=\"This image shows the retrieval augmented generation (RAG) system design setup with knowledge bases, S3, and AOSS. Knowledge corpus is ingested into a vector database using Amazon Bedrock Knowledge Base Agent and then RAG approach is used to work question answering. The question is converted into embeddings followed by semantic similarity search to get similar documents. With the user prompt being augmented with the RAG search response, the LLM is invoked to get the final raw response for the user.\" height=\"700\" width=\"700\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "\n",
    "\n",
    "#### Lab Sections\n",
    "\n",
    "This lab notebook has the following sections:\n",
    "\n",
    "1. <a href=\"#1\">Environment setup and configuration</a>\n",
    "2. <a href=\"#2\">Set up Bedrock for inference</a>\n",
    "3. <a href=\"#3\">Setup agent infrastructure</a>\n",
    "4. <a href=\"#4\">Create an agent</a>\n",
    "5. <a href=\"#5\">Associate knowledge bases, deploy agent, create alias</a>\n",
    "6. <a href=\"#6\">Invoke agent</a>\n",
    "9. <a href=\"#7\">Monitor SNS message count for Human in the Loop setup</a>\n",
    "10. <a href=\"#8\">Clean up resources</a>\n",
    "11. <a href=\"#9\">Challenge exercise and lab quiz</a>\n",
    "    \n",
    "Please work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code.\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54de30-fe9e-4b38-943a-330065bfa7ef",
   "metadata": {},
   "source": [
    "\n",
    "Let's start by installing all required packages as specified in the `requirements.txt` file and importing several libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463f03b-7f8b-4a95-a7c8-0caa46d6ae4b",
   "metadata": {},
   "source": [
    "\n",
    "## <a name=\"1\">Environment setup and configuration</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Before starting, let's import the required packages and configure the support variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad22d83-8384-4fb4-9ea5-9a470a28c78b",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto;\">\n",
    "    <p style=\"text-align: center; margin: auto;\">If you see Throttling Error please increase `time.sleep(10)` to say 20,30 seconds.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83787e3d-4694-498e-9ecc-7df43bd0cae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5428e2-37d0-4199-a234-33521ec995ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "import random\n",
    "import time\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import json\n",
    "import uuid\n",
    "import pprint\n",
    "import os\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from IPython.display import Markdown\n",
    "import warnings\n",
    "from botocore.config import Config\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from agent_utilities.agents_utils import *\n",
    "from agent_utilities.agents_infra_utils_one_kb_setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea10158d-adb7-463e-ae3e-df72da6e850b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting logger\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=41, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a83780-07e5-48ba-9bea-a20598ee58eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_up_trace_files(\"./trace_files/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b84a1f4-9ecb-4e03-a252-7f6fe7832763",
   "metadata": {},
   "source": [
    "### <a name=\"2\">2. Set up Bedrock for inference</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To get started, set up Bedrock and instantiate an active `bedrock-runtime` to query LLMs. The code below leverages [LangChain's Bedrock integration](https://python.langchain.com/docs/integrations/llms/bedrock).\n",
    "```\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "```\n",
    "\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be67a917-11f8-43a0-a8d5-1b379ec77119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('us-west-2', '996757723911')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting boto3 clients for required AWS services\n",
    "bedrock_boto3_config = Config(\n",
    "    connect_timeout=60*10,\n",
    "    read_timeout=60*10,\n",
    ")\n",
    "\n",
    "RETRY_CONFIG = Config(\n",
    "    retries={\n",
    "        'max_attempts': 3,            # Maximum number of retry attempts\n",
    "        'mode': 'adaptive'            # Adaptive mode adjusts based on request limits\n",
    "    },\n",
    "    read_timeout=1000,\n",
    "    connect_timeout=1000\n",
    "    \n",
    ")\n",
    "\n",
    "bedrock_runtime_client = boto3.client(\n",
    "    'bedrock-runtime',\n",
    "    region_name=region,\n",
    "    config=RETRY_CONFIG\n",
    ")\n",
    "\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "iam_client = boto3.client('iam')\n",
    "s3_client = boto3.client('s3')\n",
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "bedrock_agent_client = boto3.client('bedrock-agent', config=RETRY_CONFIG)\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime', config=RETRY_CONFIG)\n",
    "open_search_serverless_client = boto3.client('opensearchserverless', config=RETRY_CONFIG)\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region, account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "273c0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#test if bedrock model access has been enabled \n",
    "input_prompt = \"Who was the first person to land on the sun?\"\n",
    "test_llm_call(input_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec89861-d8dc-4bef-b4f6-f07a6ff49a2b",
   "metadata": {},
   "source": [
    "### <a name=\"3\">3. Setup agent infrastructure</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "High level workflow:\n",
    "- Setup for variables with various agent resources\n",
    "- Create Lambda function for action group\n",
    "- Create Knowledge Base 1 for QnA with latest the Amazon Bedrock User Guide\n",
    "- Creating an agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab1_kb_id = None\n",
    "kb_list = bedrock_agent_client.list_knowledge_bases()['knowledgeBaseSummaries']\n",
    "for kb in kb_list:\n",
    "    if kb['name'] == 'bedrock_user_guide_kb':\n",
    "        lab1_kb_id = kb['knowledgeBaseId']\n",
    "\n",
    "print(lab1_kb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1817d01-b93f-4f33-97a1-4ce341c400ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab 1 store kb_id :: CMKJN2QRK1\n",
      "use_existing_kb :: True\n",
      "existing_kb_id :: CMKJN2QRK1\n"
     ]
    }
   ],
   "source": [
    "kb_id = None\n",
    "%store -r kb_id\n",
    "if kb_id is None:\n",
    "    kb_id = lab1_kb_id\n",
    "# if a kb already exists we can use the same, else the infra setup code will create one by itself using the bedrock user guide.\n",
    "print(f\"Lab 1 store kb_id :: {kb_id}\")\n",
    "use_existing_kb = False\n",
    "existing_kb_id = None\n",
    "if kb_id is not None:\n",
    "    use_existing_kb = True\n",
    "    existing_kb_id = kb_id\n",
    "print(f\"use_existing_kb :: {use_existing_kb}\")\n",
    "print(f\"existing_kb_id :: {existing_kb_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083ad70a-a52f-48c1-9846-0d41cb67ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab 1 store kb_id :: CMKJN2QRK1\n",
      "use_existing_kb :: True\n",
      "existing_kb_id :: CMKJN2QRK1\n"
     ]
    }
   ],
   "source": [
    "schema_filename='hallucination_agent_openapi_schema_with_kb.json'\n",
    "kb_db_file_uri='kb_hallucination'\n",
    "lambda_code_uri='lambda_hallucination_detection.py'\n",
    "sns_topic_name='reinvent2024_hallucination_lab2b_topic'\n",
    "gt_file_name='reinvent2024-hallucinations-questions.csv'\n",
    "\n",
    "\n",
    "\n",
    "kb_id = None\n",
    "%store -r kb_id\n",
    "# if a kb already exists we can use the same, else the infra setup code will create one by itself using the bedrock user guide.\n",
    "print(f\"Lab 1 store kb_id :: {kb_id}\")\n",
    "if kb_id is not None:\n",
    "    use_existing_kb = True\n",
    "    existing_kb_id = kb_id\n",
    "\n",
    "print(f\"use_existing_kb :: {use_existing_kb}\")\n",
    "print(f\"existing_kb_id :: {existing_kb_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b67872-2702-415b-aba9-3218b1ce884f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_bedrock_policy :: None\n",
      "agent_s3_schema_policy :: None\n",
      "kb_db_bedrock_policy :: None\n",
      "kb_aws_bedrock_policy :: None\n",
      "kb_db_s3_policy :: None\n",
      "Lambda :: LambdaAgentsHallucinationDetection is now subscribed to SNS :: arn:aws:sns:us-west-2:996757723911:reinvent2024_hallucination_lab2b_topic and subscriptionArn is arn:aws:sns:us-west-2:996757723911:reinvent2024_hallucination_lab2b_topic:84df315d-6eed-4e5b-b386-ed7df672c3e7\n",
      "Using existing_kb_id :: CMKJN2QRK1\n",
      "CPU times: user 138 ms, sys: 10.4 ms, total: 148 ms\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# For new KB it takes around ~6 minutes for this setup to complete on a t2.medium instance.\n",
    "infra_response = setup_agent_infrastructure(schema_filename=schema_filename,\n",
    "                                           kb_db_file_uri=kb_db_file_uri,\n",
    "                                           lambda_code_uri=lambda_code_uri,\n",
    "                                           sns_topic_name=sns_topic_name,\n",
    "                                           gt_file_name=gt_file_name,\n",
    "                                           use_existing_kb = use_existing_kb,\n",
    "                                           existing_kb_id = existing_kb_id \n",
    "                                           )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce57f567-607a-4dd2-b9de-014eddf6dafb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_name = infra_response[\"agent_name\"]\n",
    "agent_alias_name = infra_response[\"agent_alias_name\"]\n",
    "agent_role = infra_response[\"agent_role\"]\n",
    "bucket_name = infra_response[\"bucket_name\"]\n",
    "schema_key = infra_response[\"schema_key\"]\n",
    "knowledge_base_db_id = infra_response[\"knowledge_base_db_id\"]\n",
    "lambda_name = infra_response[\"lambda_name\"]\n",
    "lambda_function = infra_response[\"lambda_function\"]\n",
    "agent_bedrock_policy = infra_response[\"agent_bedrock_policy\"]\n",
    "agent_s3_schema_policy = infra_response[\"agent_s3_schema_policy\"]\n",
    "agent_role_name = infra_response[\"agent_role_name\"]\n",
    "lambda_role_name = infra_response[\"lambda_role_name\"]\n",
    "kb_db_collection_name = infra_response[\"kb_db_collection_name\"]\n",
    "kb_db_bedrock_policy = infra_response[\"kb_db_bedrock_policy\"]\n",
    "kb_db_aoss_policy = infra_response[\"kb_db_aoss_policy\"]\n",
    "kb_db_s3_policy = infra_response[\"kb_db_s3_policy\"]\n",
    "agent_kb_schema_policy = infra_response[\"agent_kb_schema_policy\"]\n",
    "kb_db_role_name = infra_response[\"kb_db_role_name\"]\n",
    "kb_db_opensearch_collection_response = infra_response[\"kb_db_opensearch_collection_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda7647b-20e1-4064-b5bd-93c0e6cb200c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l2c24deb-reduce-hallucinations-in-genai-apps'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e66db1f-3f77-4540-9be9-f3bafa6d43a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CMKJN2QRK1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_base_db_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a0249-e6b4-46d9-aade-c7b006bb22c3",
   "metadata": {},
   "source": [
    "### <a name=\"4\">Create agent</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b86215-bc3d-47f6-a98c-6f96c513d886",
   "metadata": {},
   "source": [
    "\n",
    "Once the needed IAM role is created, we can use the Bedrock agent client to create a new agent. To do so we use the `create_agent` function. It requires an agent name, underline foundation model and instruction. You can also provide an agent description. Note that the agent created is not yet prepared. We will focus on preparing the agent and then using it to invoke actions and use other APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1d7c63b-6bc0-4b48-a5c0-2db24fa5a21e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NY5CJX56KK'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create agent\n",
    "agent_instruction = \"\"\"\n",
    "You are a question answering agent that helps customers answer questions from the Amazon Bedrock User Guide inside the associated knowledge base.\n",
    "Next you will always use the knowledge base search result to detect and measure any hallucination using the functions provided\"\n",
    "\"\"\"\n",
    "# anthropic.claude-3-sonnet-20240229-v1:0\n",
    "# anthropic.claude-3-haiku-20240307-v1:0\n",
    "\n",
    "response = bedrock_agent_client.create_agent(\n",
    "    agentName=agent_name,\n",
    "    agentResourceRoleArn=agent_role['Role']['Arn'],\n",
    "    description=\"Ask questions to get answers from the latest Amazon Bedrock User Guide\",\n",
    "    idleSessionTTLInSeconds=3600,\n",
    "    foundationModel=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    instruction=agent_instruction,\n",
    ")\n",
    "agent_id = response['agent']['agentId']\n",
    "agent_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89ac0d-b1af-4efa-bbb8-59a8f486a622",
   "metadata": {},
   "source": [
    "Looking at the created agent, we can see its status and agent id. We have saved the `agent_id` in a local variable to use it for the next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b400720-accd-41f7-84f3-c895b2eb3123",
   "metadata": {},
   "source": [
    "### <a name=\"5\">Associate knowledge bases, deploy agent, create alias</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "After we have the agent, we still have to \n",
    "1. Create agent action group\n",
    "2. Allowing agent to invoke action group Lambda\n",
    "3. Associating the agent to the knowledge base\n",
    "4. Prepare the agent\n",
    "5. Create agent alias to deploy agent\n",
    "\n",
    "We cover the detailed implementation inside `setup_agent_after_create()` in `agent_utilties\\agents_infra_utils_one_kb_setup` python file.\n",
    "\n",
    "Once that is done, let's use the `bedrock-agent-runtime` client to invoke this agent and ask user questions on bedrock user guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bad4191-b8b0-4245-870f-3b0f3742046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_alias_name :: l2c24deb-workshop-alias and agent_alias_id :: MO2DZGJWTS\n",
      "CPU times: user 45 ms, sys: 14.1 ms, total: 59.1 ms\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# note:: this can take around 2-3 mins \n",
    "agent_alias, agent_action_group_response = setup_agent_after_create(bedrock_agent_client, \n",
    "                                         agent_id,\n",
    "                                         agent_alias_name,\n",
    "                                         lambda_function,\n",
    "                                         bucket_name,\n",
    "                                         schema_key,\n",
    "                                         lambda_name,\n",
    "                                      knowledge_base_db_id,\n",
    "                                        sns_topic_name)\n",
    "#agent_alias_name = agent_alias['agentAlias']['agentAliasName']\n",
    "agent_alias_id = agent_alias['agentAlias']['agentAliasId']\n",
    "print(f\"agent_alias_name :: {agent_alias_name} and agent_alias_id :: {agent_alias_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada2844c-04fd-4dfc-a87d-0a668afb8f82",
   "metadata": {},
   "source": [
    "### <a name=\"6\">Invoke agent</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now that we've created the agent, let's use the `bedrock-agent-runtime` client to invoke this agent and loop through all user questions inside `reinvent2024-hallucinations-questions.csv` and ask them to the agent.\n",
    "\n",
    "We set the minimum answer score threshold of at least `0.85` for the exact model response to go back to the customer as-is without bringing human in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28360786-bbba-4d31-85cc-3b764ad86878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q001</td>\n",
       "      <td>What models are supported by bedrock agents?</td>\n",
       "      <td>The following models are supported for use with Amazon Bedrock Agents: Anthropic Claude v2 Anthropic Claude v2.1 Anthropic Claude Instant Anthropic Claude 3 Sonnet Anthropic Claude 3 Haiku Anthropic Claude 3.5 Sonnet Titan Text G1 Premier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q002</td>\n",
       "      <td>Which models can I use with Amazon Bedrock Agents?</td>\n",
       "      <td>The following models are supported for use with Amazon Bedrock Agents: Anthropic Claude v2 Anthropic Claude v2.1 Anthropic Claude Instant Anthropic Claude 3 Sonnet Anthropic Claude 3 Haiku Anthropic Claude 3.5 Sonnet Titan Text G1 Premier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q003</td>\n",
       "      <td>Which are the dates for reinvent 2024?</td>\n",
       "      <td>December 2-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q004</td>\n",
       "      <td>What is the Model ID of Amazon Titan Text Premier</td>\n",
       "      <td>The Model ID of Amazon Titan Text G1 - Premier is amazon.titan-text-premier-v1:0.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets see the content of the user-questions and ground truth\n",
    "questions_df = pd.read_csv(\"./reinvent2024-hallucinations-questions.csv\", sep=',')\n",
    "questions_df.style.set_properties(**{'text-align': 'left', 'border': '1px solid black'})\n",
    "questions_df.to_string(justify='left', index=False)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    pretty_print(questions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b773f7db-6135-4050-a2fa-0bb6779c3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE = \"\"\"Question: {question}\n",
    "\n",
    "Given an input question, you will search the Knowledge Base on Bedrock User Guide to answer the user question. \n",
    "If the knowledge base search results does not return any answer you can try answering it to the best of your ability but do not answer anything you do not know. Do not hallucinate.\n",
    "Using this knowledge base search results you will ALWAYS execute the appropriate action group API to measure and detect the hallucination on that knowledge base search results.\n",
    "\n",
    "Remove any XML tags from the knowledge base search results and final user response.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26007b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question ID</th>\n",
       "      <th>User Question</th>\n",
       "      <th>Agent/Chatbot Response</th>\n",
       "      <th>KB Response</th>\n",
       "      <th>Answer Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q001</td>\n",
       "      <td>What models are supported by bedrock agents?</td>\n",
       "      <td>For question = What models are supported by bedrock agents? .. Getting a customer service agent to help you, please wait and stay connected ....</td>\n",
       "      <td>IMPORTANT: USE THIS RESULT VERBATIM. DO NOT SUMMARIZE:<br><br>    &lt;answer_part&gt;&lt;text&gt;<br>Amazon Bedrock supports the following models for use with agents:<br><br>- Anthropic Claude 3 Opus<br>- AI21 Labs Jurassic-2 Mid and Ultra<br>- Cohere Command, Command Light, Command R, and Command R+<br>- Meta Llama 2 Chat 13B and 70B<br>- Meta Llama 2 13B and 70B<br>- Meta Llama 3 8B Instruct, 70B Instruct, 3.1 8B Instruct, 3.1 70B Instruct, and 3.1 405B Instruct<br>- Meta Llama 3.2 1B Instruct, 3B Instruct, 11B Instruct, and 90B Instruct<br>- Mistral AI Mistral 7B Instruct, Mistral Large, Mistral Large 2 24.07, Mixtral 8X7B Instruct, and Mistral Small<br>&lt;/text&gt;&lt;sources&gt;&lt;source&gt;4&lt;/source&gt;&lt;/sources&gt;&lt;/answer_part&gt;&lt;answer_part&gt;&lt;text&gt;<br>The models support various features like knowledge base integration, fine-tuning, tool use, and the Converse API to different extents. For example, the Meta Llama 3.1 models support agents, fine-tuning, tool use, and the Converse API, while the Mistral AI models only support agents and the Converse API except Mistral Large 2 which does not support the Converse API.<br>&lt;/text&gt;&lt;sources&gt;&lt;source&gt;4&lt;/source&gt;&lt;/sources&gt;&lt;/answer_part&gt;</td>\n",
       "      <td>0.460934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question ID</th>\n",
       "      <th>User Question</th>\n",
       "      <th>Agent/Chatbot Response</th>\n",
       "      <th>KB Response</th>\n",
       "      <th>Answer Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q002</td>\n",
       "      <td>Which models can I use with Amazon Bedrock Agents?</td>\n",
       "      <td>For question = Which models can I use with Amazon Bedrock Agents? .. Getting a customer service agent to help you, please wait and stay connected ....</td>\n",
       "      <td>You can use the following models with Amazon Bedrock Agents:<br><br>- Mistral AI Mistral Large 2 24.07<br>- Meta Llama 3.1 Instruct<br>- AI21 Jamba-Instruct<br>- Claude 3.5 Sonnet<br><br>Amazon Bedrock supports using different foundation models from various providers. The supported models are listed on the Models supported page in the Amazon Bedrock documentation.</td>\n",
       "      <td>0.593483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question ID</th>\n",
       "      <th>User Question</th>\n",
       "      <th>Agent/Chatbot Response</th>\n",
       "      <th>KB Response</th>\n",
       "      <th>Answer Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q003</td>\n",
       "      <td>Which are the dates for reinvent 2024?</td>\n",
       "      <td>For question = Which are the dates for reinvent 2024? .. Getting a customer service agent to help you, please wait and stay connected ....</td>\n",
       "      <td>Unfortunately, I could not find any information about the dates for AWS re:Invent 2024 in the provided search results. The search results appear to contain documentation and release notes for the Amazon Bedrock service, but do not mention the AWS re:Invent conference dates.</td>\n",
       "      <td>0.015347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question ID</th>\n",
       "      <th>User Question</th>\n",
       "      <th>Agent/Chatbot Response</th>\n",
       "      <th>KB Response</th>\n",
       "      <th>Answer Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q004</td>\n",
       "      <td>What is the Model ID of Amazon Titan Text Premier</td>\n",
       "      <td>The model ID for Amazon Titan Text G1 - Premier is amazon.titan-text-premier-v1:0.</td>\n",
       "      <td>The model ID for Amazon Titan Text G1 - Premier is amazon.titan-text-premier-v1:0.</td>\n",
       "      <td>0.947762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 149 ms, sys: 20 ms, total: 169 ms\n",
      "Wall time: 7min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "agent_answers = list()\n",
    "for index, row in questions_df.iterrows():\n",
    "    session_id = str(uuid.uuid1())\n",
    "    final_agent_answer = None\n",
    "    question_id = row['question_id']\n",
    "    question_text = row['question']\n",
    "    gt_answer = row['ground_truth_answer']\n",
    "    logger.info(f\"-------------Question ID :: {question_id} Question_text :: {question_text} -------------------\")\n",
    "    final_agent_answer = invoke_agent_generate_response(bedrock_agent_runtime_client,\n",
    "                                           USER_PROMPT_TEMPLATE.format(question=question_text),\n",
    "                                           agent_id, \n",
    "                                           agent_alias_id, \n",
    "                                           session_id = session_id, \n",
    "                                           enable_trace = True,\n",
    "                                           end_session = False,\n",
    "                                           trace_filename_prefix = 'lab2_hallucination_agent_trace',\n",
    "                                           turn_number = index)\n",
    "    \n",
    "    time.sleep(20) # to avoid throttling errors if any, you can update it to greater than 60, say 65 \n",
    "    #print(f\"final_agent_answer --> {final_agent_answer}\")\n",
    "    agent_answers.append(final_agent_answer)\n",
    "    format_final_response(question_id = question_id, \n",
    "                          question = question_text, \n",
    "                          final_answer = final_agent_answer, \n",
    "                          lab_number=2, \n",
    "                          turn_number=index, \n",
    "                          show_detailed=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbebbe7-f35e-4b4a-ae16-28c29de5ae25",
   "metadata": {},
   "source": [
    "### <a name=\"7\">Monitor the SNS messages received for Human in the Loop setup </a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "- To verify the actual SNS message count, you can view the latest  Lambda cloud watch logs following the instructions as given in the [LINK](https://docs.aws.amazon.com/lambda/latest/dg/monitoring-cloudwatchlogs-view.html) . Search for the string `Received SNS message ::` inside the cloudwatch logs. The lambda function for this notebook is called `LambdaAgentsHallucinationDetection`\n",
    "\n",
    "- To check the SNS message count, you can monitor the number of messages in the SNS topic `reinvent2024_hallucination_lab2b_topic` via cloudwatch metric `NumberOfMessagesPublished` as given in the [LINK](https://docs.aws.amazon.com/sns/latest/dg/sns-monitoring-using-cloudwatch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88211718-0f51-455a-8190-cf4301716579",
   "metadata": {},
   "source": [
    "### <a name=\"8\">[Be Frugal] Clean up resources </a>\n",
    "(<a href=\"#0\">Go to top</a>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762505dd",
   "metadata": {},
   "source": [
    "##### In the following cell, we offer the option to raise an exception to avoid auto-executing the next block of lines and optionally clean up all resources. This is useful when the `Kernel > run all` option is used.\n",
    "\n",
    "`Please be frugal if you choose to enable this exception in the code cell below. By default it is disabled and all resources will be cleaned up immediately to avoid additional costs.`\n",
    "\n",
    "##### Within the same kernel session, this will allow experimentation with different prompts without having to recreate agent resources (takes ~5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6aac2b7-dc28-4122-ab3e-5d3d28abd42d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Avoiding Auto-Cleanup of Amazon Bedrock Agent Resources",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# this avoids auto-cleanup\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvoiding Auto-Cleanup of Amazon Bedrock Agent Resources\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Avoiding Auto-Cleanup of Amazon Bedrock Agent Resources"
     ]
    }
   ],
   "source": [
    "# this avoids auto-cleanup\n",
    "raise Exception('Avoiding Auto-Cleanup of Amazon Bedrock Agent Resources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60e89e-01e1-410a-822f-b9641dd5150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cleanup_infrastructure(agent_action_group_response, \n",
    "                       lambda_name, \n",
    "                       lambda_function, \n",
    "                       lambda_role_name, \n",
    "                       agent_id, \n",
    "                       agent_alias_id, \n",
    "                       agent_role_name, \n",
    "                       bucket_name, \n",
    "                       schema_key, \n",
    "                       agent_bedrock_policy, \n",
    "                       agent_s3_schema_policy, \n",
    "                       agent_kb_schema_policy, \n",
    "                       kb_db_bedrock_policy, \n",
    "                       kb_db_aoss_policy, \n",
    "                       kb_db_s3_policy, \n",
    "                       kb_db_role_name, \n",
    "                       kb_db_collection_name, \n",
    "                       kb_db_opensearch_collection_response, \n",
    "                       knowledge_base_db_id, \n",
    "                       sns_topic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810acda7-1a6b-4d55-851c-0e29ebe73e40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a name=\"9\">Challenge Exercise :: Try it Yourself! </a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f3d63-c47b-4573-b5b1-8b8f889ad072",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto;\">\n",
    "    <br>\n",
    "    <p style=\"text-align: center; margin: auto;\"><b>Try the following exercises on this lab and note the observations.</b></p>\n",
    "<p style=\" text-align: left; margin: auto;\">\n",
    "<ol>\n",
    " <li>Try a new set of questions to test against the agent, reference the Amazon Bedrock User Guide to come up with these questions. </li>\n",
    "<li> Notice the questions where the human in the loop are getting invoked? Does question reframing/rewriting help avoid it? </li>\n",
    "<li> Try different chunking strategies supported by Bedrock Knowledge base and ask the same set of questions to compare and contrast against each chunking strategy for this use-case. </li>\n",
    "<li> Try additional RAGAS metrics from the documentation, <a href=\"https://docs.ragas.io/en/v0.1.21/concepts/metrics/index.html\">RAGAS METRICS</a> </li>\n",
    "    <li> Try different open source PDF(s) to verify . </li>\n",
    "</ol>\n",
    "<br>\n",
    "</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e11a07-f94a-454d-9d2c-c530c4acbe16",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We now have an understanding of how to detect, measure and remediate hallucinations with Human in the Loop even after applying RAG workflows with an agentic AI workflow. \n",
    "Furthermore, each failure scenario could be an opportunity to improve the raw datasource for better clarity.\n",
    "\n",
    "\n",
    "### Take aways \n",
    "- Adapt this notebook to create newer hallucination detection and thresholding mechanisms to involve human in the loop for your use-case.\n",
    "\n",
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
