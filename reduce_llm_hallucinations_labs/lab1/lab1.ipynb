{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc84eb37-3b34-4506-8ebc-c70f28166077",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center><img src=\"images/2024_reInvent_Logo_wDate_Black_V3.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# <a name=\"0\">re:Invent 2024 | Lab 1: Build your RAG powered chatbot  </a>\n",
    "## <a name=\"0\">Build a chatbot with Knowledge Bases and Guardrails to detect and remediate hallucinations </a>\n",
    "\n",
    "## Lab Overview\n",
    "In this lab, you will:\n",
    "1. Take a deeper look at which LLM parameters influence or control for model hallucinations\n",
    "2. Understand how Retrieval Augmented Generation can control for hallucinations\n",
    "3. Apply contextual grounding in Amazon Bedrock Guardrails to intervene when a model hallucinates\n",
    "4. Use RAGAS evaluation and understand which metrics help us measure hallucinations\n",
    "\n",
    "## Dataset\n",
    "For this workshop, we will use the [Bedrock User Guide](https://docs.aws.amazon.com/pdfs/bedrock/latest/userguide/bedrock-ug.pdf) available as a PDF file.\n",
    "## Use-Case Overview\n",
    "In this lab, we want to develop a chatbot which can answer questions about Amazon Bedrock as factually as possible. We will work with Retrieval Augmented Generation using [Amazon Bedrock Knowledge Bases](https://aws.amazon.com/bedrock/knowledge-bases/) and apply [Amazon Guardrails](https://aws.amazon.com/bedrock/guardrails/) to intervene when hallucinations are detected.\n",
    "\n",
    "\n",
    "#### Lab Sections\n",
    "\n",
    "This lab notebook has the following sections:\n",
    "    \n",
    "Please work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code.\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f260f34e-c753-4456-8643-639a3b4cdcfa",
   "metadata": {},
   "source": [
    "# Star Github repository for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb09da1-5d9e-4496-b0c8-ed5ae80911ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<a class=\"github-button\" href=\"https://github.com/aws-samples/responsible_ai_aim325_reduce_hallucinations_for_genai_apps\" data-color-scheme=\"no-preference: light; light: light; dark: dark;\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star Reduce Hallucinations workshop on GitHub\">Star</a>\n",
       "<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<a class=\"github-button\" href=\"https://github.com/aws-samples/responsible_ai_aim325_reduce_hallucinations_for_genai_apps\" data-color-scheme=\"no-preference: light; light: light; dark: dark;\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star Reduce Hallucinations workshop on GitHub\">Star</a>\n",
    "<script async defer src=\"https://buttons.github.io/buttons.js\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc006a3-48d5-40a5-9eb8-ea9bcd3d85e9",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba631f57-61f6-422f-8a42-472cb6046eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gluonts 0.13.7 requires pydantic~=1.7, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a617e1-d0ef-44d3-bb56-c1f11ee326dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4545e3ba-8b68-4251-9177-8a506d1dae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in BedrockBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in BedrockBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.227.0', '1.35.15')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from time import gmtime, strftime, sleep\n",
    "import random\n",
    "import zipfile\n",
    "import uuid\n",
    "from rag_setup.create_kb_utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from botocore.config import Config\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import sagemaker\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "(sagemaker.__version__,boto3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6edb7c-dfa1-4460-a365-e3f287951ddb",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b2c77d-ebdb-4d0a-acdd-04558b7797a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some variables you need to interact with SageMaker service\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c34d99ca-e263-44e3-9e35-685a7a8f9859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model_id=\"amazon.titan-embed-text-v2:0\"\n",
    "llm_model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d3afab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/responsible_ai_reduce_hallucinations_for_genai_apps/reduce_llm_hallucinations_labs/lab1/rag_setup/create_kb_utils.py:60: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  response = llm(messages)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"No one has ever landed on the sun. The sun is a star with extremely hot temperatures and harsh conditions that make landing on its surface impossible with current technology.\\n\\nThe sun's surface temperature is around 5,500°C (9,940°F). Its powerful gravitational pull and lack of a solid surface also make landing unfeasible. Any spacecraft would burn up long before reaching the sun's photosphere (visible surface) due to the intense heat and radiation.\\n\\nVisiting the sun up close has been done only by unmanned spacecraft like NASA's Parker Solar Probe, which flew through the sun's outer atmosphere in 2018-2019 to study the solar corona and solar wind. But even this probe did not actually land on the sun's surface. Landing humans or machines on the sun remains science fiction for now.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if bedrock model access has been enabled\n",
    "input_prompt = \"Who was the first person to land on the sun?\"\n",
    "test_llm_call(input_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637a9c5-0739-425d-a7bf-21b2083ee271",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px\">\n",
    "    <h4>If LLM call to Bedrock did not work, enable model access on Amazon Bedrock console</h4>\n",
    "</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44d408-1086-48fc-a329-f757fed9b02a",
   "metadata": {},
   "source": [
    "# 1. Chat with Anthropic Claude 3 Sonnet through Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "340537e1-ef81-4aef-a767-f0df5e1fef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRY_CONFIG = Config(\n",
    "    retries={\n",
    "        'max_attempts': 5,            # Maximum number of retry attempts\n",
    "        'mode': 'adaptive'            # Adaptive mode adjusts based on request limits\n",
    "    },\n",
    "    read_timeout=1000,\n",
    "    connect_timeout=1000\n",
    ")\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region,\n",
    "    config=RETRY_CONFIG)\n",
    "\n",
    "def generate_message_claude(\n",
    "    query, \n",
    "    system_prompt=\"\", \n",
    "    max_tokens=1000,\n",
    "    model_id='anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    temperature=0.9,\n",
    "    top_p=0.99,\n",
    "    top_k=100\n",
    "):\n",
    "    # Prompt with user turn only.\n",
    "    user_message = {\"role\": \"user\", \"content\": query}\n",
    "    messages = [user_message]\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"system\": system_prompt,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\": top_k\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dd47d4b-8455-4fcf-ae91-874ab2f7c0e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon Bedrock Guardrails is a service provided by AWS that helps '\n",
      " 'organizations establish and enforce secure baselines across their AWS '\n",
      " 'accounts and resources. It allows organizations to define and implement '\n",
      " 'guardrails, which are rules or controls that enforce best practices and '\n",
      " 'ensure compliance with organizational policies and industry standards.\\n'\n",
      " '\\n'\n",
      " \"Here's how Amazon Bedrock Guardrails works:\\n\"\n",
      " '\\n'\n",
      " '1. Guardrail Definition: Organizations can define guardrails using '\n",
      " 'Infrastructure as Code (IaC) templates, such as AWS CloudFormation or AWS '\n",
      " 'CDK. These guardrails can cover various areas, including identity and access '\n",
      " 'management, networking, storage, compute, and more.\\n'\n",
      " '\\n'\n",
      " '2. Guardrail Deployment: Bedrock Guardrails provides a centralized mechanism '\n",
      " 'for deploying and managing guardrails across multiple AWS accounts and '\n",
      " 'regions within an organization. This ensures consistent application of '\n",
      " \"security controls and compliance requirements throughout the organization's \"\n",
      " 'AWS environment.\\n'\n",
      " '\\n'\n",
      " '3. Continuous Monitoring: Once deployed, Bedrock Guardrails continuously '\n",
      " 'monitors the AWS resources and configurations against the defined '\n",
      " 'guardrails. It detects any deviations or violations from the established '\n",
      " 'rules and generates alerts or notifications.\\n'\n",
      " '\\n'\n",
      " '4. Remediation: When a violation is detected, Bedrock Guardrails can take '\n",
      " 'automated remediation actions based on the defined guardrail rules. For '\n",
      " 'example, it can automatically roll back non-compliant changes, delete '\n",
      " 'unauthorized resources, or modify configurations to bring them back into '\n",
      " 'compliance.\\n'\n",
      " '\\n'\n",
      " '5. Reporting and Auditing: Bedrock Guardrails provides detailed reports and '\n",
      " 'audit trails, allowing organizations to track and demonstrate compliance '\n",
      " 'with internal policies and external regulations. These reports can be used '\n",
      " 'for auditing purposes or to identify areas for improvement.\\n'\n",
      " '\\n'\n",
      " 'Amazon Bedrock Guardrails is designed to help organizations establish and '\n",
      " 'maintain a secure and compliant AWS environment by automating the '\n",
      " 'enforcement of security best practices and organizational policies. It '\n",
      " 'simplifies the process of implementing and managing guardrails across '\n",
      " 'multiple AWS accounts and regions, ensuring consistent application of '\n",
      " \"security controls throughout the organization's cloud infrastructure.\")\n"
     ]
    }
   ],
   "source": [
    "query = 'How does Amazon Bedrock Guardrails work?'\n",
    "\n",
    "response = generate_message_claude(query)\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f0fa6-9637-4c65-bad6-0e1eacc692e9",
   "metadata": {},
   "source": [
    "## 1.1 Apply System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e203f5e9-2d93-4a79-b8ad-754d656f3008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I do not have any information about purchasing provisioned throughput for '\n",
      " 'Anthropic Claude models on Amazon Bedrock. Amazon Bedrock is not a service '\n",
      " \"I'm familiar with, and I don't have specific details about Anthropic's cloud \"\n",
      " 'offerings or partnerships with Amazon Web Services. My knowledge is limited '\n",
      " 'in this domain.')\n"
     ]
    }
   ],
   "source": [
    "query = 'Is it possible to purchase provisioned throughput for Anthropic Claude models on Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt)\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5057db14-729d-4d64-8355-fd6fe2ee2398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon Bedrock Guardrails is a service provided by AWS that helps '\n",
      " 'organizations govern their use of AWS through automated, continuous '\n",
      " 'monitoring and enforcement of policies and best practices. It allows '\n",
      " 'organizations to define and apply guardrails across their AWS environments '\n",
      " 'to help ensure compliance with security, operational, and cost management '\n",
      " 'requirements.\\n'\n",
      " '\\n'\n",
      " \"Here's a high-level overview of how Amazon Bedrock Guardrails work:\\n\"\n",
      " '\\n'\n",
      " '1. Guardrail Definition: Organizations define guardrails as code using AWS '\n",
      " 'CloudFormation templates or AWS Service Catalog products. Guardrails can '\n",
      " 'cover various areas such as identity and access management, data protection, '\n",
      " 'logging and monitoring, and resource quotas.\\n'\n",
      " '\\n'\n",
      " \"2. Deployment: The defined guardrails are deployed across the organization's \"\n",
      " 'AWS accounts and regions using AWS Organizations and AWS Control Tower.\\n'\n",
      " '\\n'\n",
      " '3. Continuous Monitoring: Bedrock Guardrails continuously monitors the '\n",
      " \"organization's AWS environments for any violations of the defined \"\n",
      " 'guardrails.\\n'\n",
      " '\\n'\n",
      " '4. Automated Remediation: When a violation is detected, Bedrock Guardrails '\n",
      " 'can take automated remediation actions based on the defined guardrail '\n",
      " 'configuration. This could include preventing non-compliant resource '\n",
      " 'deployments, modifying or remediating existing resources, or notifying '\n",
      " 'administrators.\\n'\n",
      " '\\n'\n",
      " '5. Reporting and Auditing: Bedrock Guardrails provides detailed reporting '\n",
      " 'and auditing capabilities, allowing organizations to track and review '\n",
      " 'guardrail violations, remediation actions, and overall compliance status.\\n'\n",
      " '\\n'\n",
      " 'Bedrock Guardrails leverages various AWS services such as AWS Config, AWS '\n",
      " 'Lambda, AWS CloudFormation, and AWS Service Catalog to implement its '\n",
      " 'functionality. It aims to help organizations establish and maintain a '\n",
      " 'secure, well-governed, and compliant AWS environment by automating the '\n",
      " 'enforcement of best practices and organizational policies.')\n"
     ]
    }
   ],
   "source": [
    "query = 'How do Amazon Bedrock Guardrails work?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt)\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f9196-7e32-4ef0-b516-b8801a688aa3",
   "metadata": {},
   "source": [
    "## 1.2 Understanding LLM generation parameters\n",
    "### 1. Temperature: The amount of randomness injected into the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f610c2e0-e810-47f4-89f9-9980319e32dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon Bedrock is an Amazon Web Services (AWS) service that provides '\n",
      " 'businesses with the ability to build and deploy secure and resilient '\n",
      " 'applications on a foundational layer of systems, runtimes, and services.\\n'\n",
      " '\\n'\n",
      " 'Some key features and capabilities of Amazon Bedrock include:\\n'\n",
      " '\\n'\n",
      " '1) Automated Provisioning: It automates the provisioning and configuration '\n",
      " 'of AWS accounts, networking, logging, and other foundational services '\n",
      " 'according to best practices.\\n'\n",
      " '\\n'\n",
      " '2) Resilient Architecture: Bedrock provides a resilient architecture with '\n",
      " 'multiple Availability Zones to protect applications from failures.\\n'\n",
      " '\\n'\n",
      " '3) Security Best Practices: It implements security best practices such as '\n",
      " 'centralized logging, encryption of data at rest and in transit, and secure '\n",
      " 'network configurations.\\n'\n",
      " '\\n'\n",
      " '4) Operational Visibility: Bedrock provides operational visibility through '\n",
      " 'centralized logging and monitoring for AWS accounts provisioned using the '\n",
      " 'service.\\n'\n",
      " '\\n'\n",
      " '5) Multi-Account Structure: It sets up a multi-account AWS environment based '\n",
      " 'on AWS best practices, separating workloads for better isolation and '\n",
      " 'control.\\n'\n",
      " '\\n'\n",
      " 'So in essence, Bedrock aims to provide a secure, resilient, and scalable '\n",
      " 'foundation on which enterprises can build and deploy their applications on '\n",
      " 'AWS while implementing architectural and security best practices by default.')\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=1)\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30ff7dba-2f3f-4bd2-87ce-0d84c3c03a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon Bedrock is a real-time operating system developed by Amazon for '\n",
      " 'running applications on resource-constrained devices like microcontrollers '\n",
      " 'and sensors.\\n'\n",
      " '\\n'\n",
      " 'Some key points about Amazon Bedrock:\\n'\n",
      " '\\n'\n",
      " '- It is designed to be a secure, real-time operating system for internet of '\n",
      " 'things (IoT) devices and embedded applications.\\n'\n",
      " '\\n'\n",
      " '- It provides a lightweight kernel and built-in libraries to enable '\n",
      " 'real-time performance and efficient resource utilization on devices with '\n",
      " 'limited compute power and memory.\\n'\n",
      " '\\n'\n",
      " '- It supports common microcontroller architectures like ARM, RISC-V, and '\n",
      " 'x86.\\n'\n",
      " '\\n'\n",
      " '- Bedrock aims to simplify development and deployment of IoT applications by '\n",
      " 'providing a consistent software foundation across different hardware '\n",
      " 'platforms.\\n'\n",
      " '\\n'\n",
      " '- It includes built-in security features like memory protection, encrypted '\n",
      " 'communication, and secure boot capabilities.\\n'\n",
      " '\\n'\n",
      " '- Bedrock integrates with AWS IoT services, allowing devices running it to '\n",
      " 'connect securely to the AWS cloud.\\n'\n",
      " '\\n'\n",
      " \"So in summary, Bedrock is Amazon's real-time OS aimed at powering the next \"\n",
      " 'generation of constrained IoT and embedded devices in a secure and efficient '\n",
      " 'manner.')\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=0)\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47723758-0f8c-4190-94ef-3bdd4d386908",
   "metadata": {},
   "source": [
    "### 2. top_p – Use nucleus sampling.\n",
    "\n",
    "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e300c40f-1b7b-4db1-bc5f-5f483507262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon Bedrock is a secure, multi-tenant cloud service from Amazon Web '\n",
      " 'Services (AWS) that makes it easier to set up and manage virtual private '\n",
      " 'clouds.\\n'\n",
      " '\\n'\n",
      " 'Some key points about Amazon Bedrock:\\n'\n",
      " '\\n'\n",
      " '- It provides a secure and governed way to create and manage multiple '\n",
      " 'virtual private clouds (VPCs) across different AWS accounts and regions.\\n'\n",
      " '\\n'\n",
      " '- It uses a centralized approach to manage VPCs, networking resources, '\n",
      " 'accounts, and teams through a single pane of glass.\\n'\n",
      " '\\n'\n",
      " '- It helps organizations gain operational visibility and control across '\n",
      " 'their cloud networking environments.\\n'\n",
      " '\\n'\n",
      " '- It enables automated provisioning and secure connectivity between AWS '\n",
      " 'resources spread across different VPCs and accounts.\\n'\n",
      " '\\n'\n",
      " '- It integrates with AWS services like AWS Organizations, AWS Control Tower, '\n",
      " 'AWS Firewall Manager for central governance and compliance.\\n'\n",
      " '\\n'\n",
      " '- It aims to simplify and standardize how enterprises set up and operate a '\n",
      " 'secure multi-account, multi-VPC environment on AWS.\\n'\n",
      " '\\n'\n",
      " 'So in essence, Bedrock provides a centralized networking management plane to '\n",
      " 'consistently deploy and securely interconnect cloud resources across '\n",
      " 'multiple AWS accounts in a scalable manner.')\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=1, top_p=1)\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7946bd-976d-4a8d-81ef-f7ff7e164f94",
   "metadata": {},
   "source": [
    "### 3. top_k: Only sample from the top K options for each subsequent token.\n",
    "\n",
    "Use top_k to remove long tail low probability responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cf753a4-8929-46ef-8aea-7ef040abb096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon Bedrock is a real-time operating system developed by Amazon for '\n",
      " 'running applications on resource-constrained devices like microcontrollers '\n",
      " 'and sensors.\\n'\n",
      " '\\n'\n",
      " 'Some key points about Amazon Bedrock:\\n'\n",
      " '\\n'\n",
      " '- It is designed to be a secure, real-time operating system for internet of '\n",
      " 'things (IoT) devices and embedded applications.\\n'\n",
      " '\\n'\n",
      " '- It provides a lightweight environment with real-time performance for '\n",
      " 'running multiple software components concurrently.\\n'\n",
      " '\\n'\n",
      " '- It supports common IoT communication protocols like MQTT, BLE, and Wi-Fi '\n",
      " 'out of the box.\\n'\n",
      " '\\n'\n",
      " '- It includes built-in security features like code signing, encrypted '\n",
      " 'storage, secure boot, and hardware security integration.\\n'\n",
      " '\\n'\n",
      " '- It allows developers to build and deploy applications in multiple '\n",
      " 'programming languages like C, Rust, and Python.\\n'\n",
      " '\\n'\n",
      " '- Bedrock is open source and available under the Apache 2.0 license on '\n",
      " 'GitHub.\\n'\n",
      " '\\n'\n",
      " '- It is optimized to run on resource-constrained microcontroller units '\n",
      " '(MCUs) with limited RAM and flash memory.\\n'\n",
      " '\\n'\n",
      " 'So in summary, Bedrock provides a secure, real-time OS foundation for '\n",
      " 'building and deploying IoT applications on constrained edge devices.')\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=0, top_p=1, top_k=100)\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9caf35-dccd-4c16-82eb-ea3e1327bc80",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation\n",
    "We are using the Retrieval Augmented Generation (RAG) technique with Amazon Bedrock. A RAG implementation consists of two parts:\n",
    "\n",
    "    1. A data pipeline that ingests that from documents (typically stored in Amazon S3) into a Knowledge Base i.e. a vector database such as Amazon OpenSearch Service Serverless (AOSS) so that it is available for lookup when a question is received.\n",
    "\n",
    "The data pipeline represents an undifferentiated heavy lifting and can be implemented using Amazon Bedrock Knowledge Bases. We can now connect an S3 bucket to a vector database such as AOSS and have a Bedrock Knowledge Bases read the objects (html, pdf, text etc.), chunk them, and then convert these chunks into embeddings using Amazon Titan Embeddings model and then store these embeddings in AOSS. All of this without having to build, deploy, and manage the data pipeline.\n",
    "\n",
    "<center><img src=\"images/fully_managed_ingestion.png\" alt=\"This image shows how Aazon Bedrock Knowledge Bases ingests objects in a S3 bucket into the Knowledge Base for use in a RAG set up. The objects are chunks, embedded and then stored in a vector index.\" height=\"700\" width=\"700\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "    \n",
    "\n",
    "    2. An application that receives a question from the user, looks up the knowledge base for relevant pieces of information (context) and then creates a prompt that includes the question and the context and provides it to an LLM for generating a response.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Once the data is available in the Bedrock knowledge base, then user questions can be answered using the following system design:\n",
    "\n",
    "<center><img src=\"images/retrieveAndGenerate.png\" alt=\"This image shows the retrieval augmented generation (RAG) system design setup with knowledge bases, S3, and AOSS. Knowledge corpus is ingested into a vector database using Amazon Bedrock Knowledge Base Agent and then RAG approach is used to work question answering. The question is converted into embeddings followed by semantic similarity search to get similar documents. With the user prompt being augmented with the RAG search response, the LLM is invoked to get the final raw response for the user.\" height=\"700\" width=\"700\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588c8c3",
   "metadata": {},
   "source": [
    "# Data\n",
    "Let's use publicly available [Bedrock user guide](https://docs.aws.amazon.com/pdfs/bedrock/latest/userguide/bedrock-ug.pdf) to inform the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae93890e-c684-4286-9234-91a3e058cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH='./lab1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe868f1-d5b1-490f-8e54-e5a856ca1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STU0PK5QDL\n"
     ]
    }
   ],
   "source": [
    "kb_id = None\n",
    "kb_list = bedrock_agent_client.list_knowledge_bases()['knowledgeBaseSummaries']\n",
    "for kb in kb_list:\n",
    "    if kb['name'] == 'bedrock_user_guide_kb':\n",
    "        kb_id = kb['knowledgeBaseId']\n",
    "\n",
    "if kb_id is None:\n",
    "    print(f\"Please navigate to Amazon Bedrock > Builder Tools > Knowledge Bases. Click on 'bedrock_user_guide_kb' KB. Go to Datasource section and click `Sync` button. Please wait for it to finish, then re-run this cell. \")\n",
    "print(kb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ec5179f-d77c-4d52-918c-f4fb37b70f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'kb_id' (str)\n",
      "Stored 'bucket_name' (str)\n"
     ]
    }
   ],
   "source": [
    "# keep the kb_id for invocation later in the invoke request\n",
    "%store kb_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c35041-9487-46e6-9a36-fd8d408712c4",
   "metadata": {},
   "source": [
    "# Chat with the model using the knowledge base by providing the generated KB_ID\n",
    "### Using RetrieveAndGenerate API\n",
    "Behind the scenes, RetrieveAndGenerate API converts queries into embeddings, searches the knowledge base, and then augments the foundation model prompt with the search results as context information and returns the FM-generated response to the question. For multi-turn conversations, Knowledge Bases manage short-term memory of the conversation to provide more contextual results.The output of the RetrieveAndGenerate API includes the generated response, source attribution as well as the retrieved text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06645e80-eebb-4883-a086-70ccfdf604c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "\n",
    "def ask_bedrock_llm_with_knowledge_base(query,\n",
    "                                        kb_id=kb_id,\n",
    "                                        model_arn=llm_model_id,\n",
    "                                        ) -> str:\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\n",
    "            'text': query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': model_arn\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a151db3d-b340-46b2-bd57-491714d2068c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Generated using Anthropic Claude 3 Sonnet:\n",
      "('Amazon Bedrock is a fully managed service that provides access to '\n",
      " 'high-performing foundation models (FMs) from leading AI companies and Amazon '\n",
      " 'through a unified API. It allows you to experiment with and evaluate '\n",
      " 'different foundation models, customize them with your own data using '\n",
      " 'techniques like fine-tuning and Retrieval Augmented Generation (RAG), and '\n",
      " 'build agents that can execute tasks using your systems and data sources. '\n",
      " \"With Amazon Bedrock's serverless experience, you can get started quickly, \"\n",
      " 'customize foundation models with your data, and easily integrate and deploy '\n",
      " 'them into your applications using AWS tools without managing any '\n",
      " 'infrastructure.')\n",
      "---------- The citations for the response:\n",
      "[ '........... 1652     Amazon Bedrock Runtime '\n",
      "  '................................................................................................................... '\n",
      "  '1654 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1661 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1666 AI21 Labs Jurassic-2 '\n",
      "  '........................................................................................................................ '\n",
      "  '1679 Amazon Titan Image Generator '\n",
      "  '.................................................................................................... '\n",
      "  '1697 Amazon Titan Text '\n",
      "  '........................................................................................................................... '\n",
      "  '1706 Amazon Titan Text Embeddings '\n",
      "  '................................................................................................... '\n",
      "  '1737 Anthropic Claude '\n",
      "  '.............................................................................................................................. '\n",
      "  '1742 Cohere Command '\n",
      "  '............................................................................................................................. '\n",
      "  '1811 Meta Llama '\n",
      "  '........................................................................................................................................ '\n",
      "  '1859 Mistral AI '\n",
      "  '............................................................................................................................................ '\n",
      "  '1908 Stable Diffusion '\n",
      "  '................................................................................................................................ '\n",
      "  '1937     Amazon Bedrock Agents '\n",
      "  '...................................................................................................................... '\n",
      "  '1946 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1949 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1977     Amazon Bedrock Agents Runtime '\n",
      "  '..................................................................................................... '\n",
      "  '1990 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1991 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1998     Abuse detection '\n",
      "  '......................................................................................................................... '\n",
      "  '2000 Create resources with AWS CloudFormation '\n",
      "  '........................................................................... '\n",
      "  '2002     Amazon Bedrock and AWS CloudFormation templates '\n",
      "  '................................................................ 2002 Learn '\n",
      "  'more about AWS CloudFormation '\n",
      "  '.......................................................................................... '\n",
      "  '2003     Troubleshooting Amazon Bedrock API Error Codes '\n",
      "  '................................................................ 2004 '\n",
      "  'AccessDeniedExcpetion '\n",
      "  '......................................................................................................................... '\n",
      "  '2004 IncompleteSignature '\n",
      "  '............................................................................................................................. '\n",
      "  '2004 InternalFailure '\n",
      "  '........................................................................................................................................ '\n",
      "  '2004     xivAmazon Bedrock User Guide     InvalidAction '\n",
      "  '........................................................................................................................................... '\n",
      "  '2005 InvalidClientTokenId '\n",
      "  '.............................................................................................................................. '\n",
      "  '2005 NotAuthorized '\n",
      "  '........................................................................................................................................ '\n",
      "  '2005 RequestExpired '\n",
      "  '....................................................................................................................................... '\n",
      "  '2006 ServiceUnavailable '\n",
      "  '................................................................................................................................. '\n",
      "  '2006 ThrottlingException '\n",
      "  '............................................................................................................................... '\n",
      "  '2007 ValidationError '\n",
      "  '....................................................................................................................................... '\n",
      "  '2007 ResourceNotFound '\n",
      "  '................................................................................................................................ '\n",
      "  '2008     Quotas '\n",
      "  '........................................................................................................................................ '\n",
      "  '2009 Request an increase for Amazon Bedrock quotas '\n",
      "  '.......................................................................... '\n",
      "  '2009     Document history '\n",
      "  '...................................................................................................................... '\n",
      "  '2010 AWS Glossary '\n",
      "  '............................................................................................................................. '\n",
      "  '2029     xvAmazon Bedrock User Guide     What is Amazon Bedrock?     Amazon '\n",
      "  'Bedrock is a fully managed service that makes high-performing foundation '\n",
      "  'models (FMs) from leading AI companies and Amazon available for your use '\n",
      "  'through a unified API. You can choose from a wide range of foundation '\n",
      "  'models to find the model that is best suited for your use case. Amazon '\n",
      "  'Bedrock also offers a broad set of capabilities to build generative AI '\n",
      "  'applications with security, privacy, and responsible AI. Using Amazon '\n",
      "  'Bedrock, you can easily experiment with and evaluate top foundation models '\n",
      "  'for your use cases, privately customize them with your data using '\n",
      "  'techniques such as fine-tuning and Retrieval Augmented Generation (RAG), '\n",
      "  'and build agents that execute tasks using your enterprise systems and data '\n",
      "  \"sources.     With Amazon Bedrock's serverless experience, you can get \"\n",
      "  'started quickly, privately customize foundation models with your own data, '\n",
      "  'and easily and securely integrate and deploy them into your applications '\n",
      "  'using AWS tools without having to manage any infrastructure.     Topics     '\n",
      "  '? What can I do with Amazon Bedrock?     ? How do I get started with Amazon '\n",
      "  'Bedrock?     ? Amazon Bedrock pricing     ? Key terminology     What can I '\n",
      "  'do with Amazon Bedrock?     You can use Amazon Bedrock to do the '\n",
      "  'following:     ? Experiment with prompts and configurations ? Submit '\n",
      "  'prompts and generate responses with model inference by sending prompts '\n",
      "  'using different configurations and foundation models to generate responses. '\n",
      "  'You can use the API or the text, image, and chat playgrounds in the console '\n",
      "  \"to experiment in a graphical interface. When you're ready, set up your \"\n",
      "  'application to make requests to the InvokeModel APIs.     ? Augment '\n",
      "  'response generation with information from your data sources ? Create '\n",
      "  'knowledge bases by uploading data sources to be queried in order to augment '\n",
      "  \"a foundation model's generation of responses.     What can I do with Amazon \"\n",
      "  'Bedrock? 1Amazon Bedrock User Guide     ? Create applications that reason '\n",
      "  'through how to help a customer ? Build agents that use foundation models, '\n",
      "  'make API calls, and (optionally) query knowledge bases in order to reason '\n",
      "  'through and carry out tasks for your customers.     ? Adapt models to '\n",
      "  'specific tasks and domains with training data ? Customize an Amazon Bedrock '\n",
      "  'foundation model by providing training data for fine-tuning or '\n",
      "  \"continued-pretraining in order to adjust a model's parameters and improve \"\n",
      "  'its performance on specific tasks or in certain domains.     ? Improve your '\n",
      "  \"FM-based application's efficiency and output ? Purchase Provisioned \"\n",
      "  'Throughput for a foundation model in order to run inference on models more '\n",
      "  'efficiently and at discounted rates.     ? Determine the best model for '\n",
      "  'your use case ? Evaluate outputs of different models with built-in or '\n",
      "  'custom prompt datasets to determine the model that is best suited for your '\n",
      "  'application.     ? Prevent inappropriate or unwanted content ? Use '\n",
      "  'guardrails to implement safeguards for your generative AI applications.     '\n",
      "  'To learn about Regions that support Amazon Bedrock and the foundation '\n",
      "  'models and features that Amazon Bedrock supports, see Supported foundation '\n",
      "  'models in Amazon Bedrock and Feature support by AWS Region in Amazon '\n",
      "  'Bedrock.     How do I get started with Amazon Bedrock?',\n",
      "  '........... 2029     xvAmazon Bedrock User Guide     What is Amazon '\n",
      "  'Bedrock?     Amazon Bedrock is a fully managed service that makes '\n",
      "  'high-performing foundation models (FMs) from leading AI companies and '\n",
      "  'Amazon available for your use through a unified API. You can choose from a '\n",
      "  'wide range of foundation models to find the model that is best suited for '\n",
      "  'your use case. Amazon Bedrock also offers a broad set of capabilities to '\n",
      "  'build generative AI applications with security, privacy, and responsible '\n",
      "  'AI. Using Amazon Bedrock, you can easily experiment with and evaluate top '\n",
      "  'foundation models for your use cases, privately customize them with your '\n",
      "  'data using techniques such as fine-tuning and Retrieval Augmented '\n",
      "  'Generation (RAG), and build agents that execute tasks using your enterprise '\n",
      "  \"systems and data sources.     With Amazon Bedrock's serverless experience, \"\n",
      "  'you can get started quickly, privately customize foundation models with '\n",
      "  'your own data, and easily and securely integrate and deploy them into your '\n",
      "  'applications using AWS tools without having to manage any '\n",
      "  'infrastructure.     Topics     ? What can I do with Amazon Bedrock?     ? '\n",
      "  'How do I get started with Amazon Bedrock?     ? Amazon Bedrock pricing     '\n",
      "  '? Key terminology     What can I do with Amazon Bedrock?     You can use '\n",
      "  'Amazon Bedrock to do the following:     ? Experiment with prompts and '\n",
      "  'configurations ? Submit prompts and generate responses with model inference '\n",
      "  'by sending prompts using different configurations and foundation models to '\n",
      "  'generate responses. You can use the API or the text, image, and chat '\n",
      "  'playgrounds in the console to experiment in a graphical interface. When '\n",
      "  \"you're ready, set up your application to make requests to the InvokeModel \"\n",
      "  'APIs.     ? Augment response generation with information from your data '\n",
      "  'sources ? Create knowledge bases by uploading data sources to be queried in '\n",
      "  \"order to augment a foundation model's generation of responses.     What can \"\n",
      "  'I do with Amazon Bedrock? 1Amazon Bedrock User Guide     ? Create '\n",
      "  'applications that reason through how to help a customer ? Build agents that '\n",
      "  'use foundation models, make API calls, and (optionally) query knowledge '\n",
      "  'bases in order to reason through and carry out tasks for your '\n",
      "  'customers.     ? Adapt models to specific tasks and domains with training '\n",
      "  'data ? Customize an Amazon Bedrock foundation model by providing training '\n",
      "  \"data for fine-tuning or continued-pretraining in order to adjust a model's \"\n",
      "  'parameters and improve its performance on specific tasks or in certain '\n",
      "  \"domains.     ? Improve your FM-based application's efficiency and output ? \"\n",
      "  'Purchase Provisioned Throughput for a foundation model in order to run '\n",
      "  'inference on models more efficiently and at discounted rates.     ? '\n",
      "  'Determine the best model for your use case ? Evaluate outputs of different '\n",
      "  'models with built-in or custom prompt datasets to determine the model that '\n",
      "  'is best suited for your application.     ? Prevent inappropriate or '\n",
      "  'unwanted content ? Use guardrails to implement safeguards for your '\n",
      "  'generative AI applications.     To learn about Regions that support Amazon '\n",
      "  'Bedrock and the foundation models and features that Amazon Bedrock '\n",
      "  'supports, see Supported foundation models in Amazon Bedrock and Feature '\n",
      "  'support by AWS Region in Amazon Bedrock.     How do I get started with '\n",
      "  'Amazon Bedrock?     We recommend that you start with Amazon Bedrock by '\n",
      "  'doing the following:     1. Familiarize yourself with the terms and '\n",
      "  'concepts that Amazon Bedrock uses.     2. Understand how AWS charges you '\n",
      "  'for using Amazon Bedrock.     3. Try the Getting started with Amazon '\n",
      "  'Bedrock tutorials. In the tutorials, you learn how to use the playgrounds '\n",
      "  'in Amazon Bedrock console. You also learn and how to use the AWS SDK to '\n",
      "  'call Amazon Bedrock API operations.     4. Read the documentation for the '\n",
      "  'features that you want to include in your application.     Amazon Bedrock '\n",
      "  'pricing     When you sign up for AWS, your AWS account is automatically '\n",
      "  'signed up for all services in AWS, including Amazon Bedrock. However, you '\n",
      "  'are charged only for the services that you use.     How do I get started '\n",
      "  'with Amazon Bedrock? 2Amazon Bedrock User Guide     To see your bill, go to '\n",
      "  'the Billing and Cost Management Dashboard in the AWS Billing and Cost '\n",
      "  'Management console. To learn more about AWS account billing, see the AWS '\n",
      "  'Billing User Guide. If you have questions concerning AWS billing and AWS '\n",
      "  'accounts, contact AWS Support.     With Amazon Bedrock, you pay to run '\n",
      "  'inference on any of the third-party foundation models. Pricing is based on '\n",
      "  'the volume of input tokens and output tokens, and on whether you have '\n",
      "  'purchased provisioned throughput for the model. For more information, see '\n",
      "  'the Model providers page in the Amazon Bedrock console. For each model, '\n",
      "  'pricing is listed following the model version. For more information about '\n",
      "  'purchasing Provisioned Throughput, see Increase model invocation capacity '\n",
      "  'with Provisioned Throughput in Amazon Bedrock.     For more information, '\n",
      "  'see Amazon Bedrock Pricing.     Key terminology     This chapter explains '\n",
      "  'terminology that will help you understand what Amazon Bedrock offers and '\n",
      "  'how it works. Read through the following list to understand generative AI '\n",
      "  \"terminology and Amazon Bedrock's fundamental capabilities:     ? Foundation \"\n",
      "  'model (FM) ?',\n",
      "  '........... 1652     Amazon Bedrock Runtime '\n",
      "  '................................................................................................................... '\n",
      "  '1654 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1661 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1666 AI21 Labs Jurassic-2 '\n",
      "  '........................................................................................................................ '\n",
      "  '1679 Amazon Titan Image Generator '\n",
      "  '.................................................................................................... '\n",
      "  '1697 Amazon Titan Text '\n",
      "  '........................................................................................................................... '\n",
      "  '1706 Amazon Titan Text Embeddings '\n",
      "  '................................................................................................... '\n",
      "  '1737 Anthropic Claude '\n",
      "  '.............................................................................................................................. '\n",
      "  '1742 Cohere Command '\n",
      "  '............................................................................................................................. '\n",
      "  '1811 Meta Llama '\n",
      "  '........................................................................................................................................ '\n",
      "  '1859 Mistral AI '\n",
      "  '............................................................................................................................................ '\n",
      "  '1908 Stable Diffusion '\n",
      "  '................................................................................................................................ '\n",
      "  '1937     Amazon Bedrock Agents '\n",
      "  '...................................................................................................................... '\n",
      "  '1946 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1949 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1977     Amazon Bedrock Agents Runtime '\n",
      "  '..................................................................................................... '\n",
      "  '1990 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1991 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1998     Abuse detection '\n",
      "  '......................................................................................................................... '\n",
      "  '2000 Create resources with AWS CloudFormation '\n",
      "  '........................................................................... '\n",
      "  '2002     Amazon Bedrock and AWS CloudFormation templates '\n",
      "  '................................................................ 2002 Learn '\n",
      "  'more about AWS CloudFormation '\n",
      "  '.......................................................................................... '\n",
      "  '2003     Troubleshooting Amazon Bedrock API Error Codes '\n",
      "  '................................................................ 2004 '\n",
      "  'AccessDeniedExcpetion '\n",
      "  '......................................................................................................................... '\n",
      "  '2004 IncompleteSignature '\n",
      "  '............................................................................................................................. '\n",
      "  '2004 InternalFailure '\n",
      "  '........................................................................................................................................ '\n",
      "  '2004     xivAmazon Bedrock User Guide     InvalidAction '\n",
      "  '........................................................................................................................................... '\n",
      "  '2005 InvalidClientTokenId '\n",
      "  '.............................................................................................................................. '\n",
      "  '2005 NotAuthorized '\n",
      "  '........................................................................................................................................ '\n",
      "  '2005 RequestExpired '\n",
      "  '....................................................................................................................................... '\n",
      "  '2006 ServiceUnavailable '\n",
      "  '................................................................................................................................. '\n",
      "  '2006 ThrottlingException '\n",
      "  '............................................................................................................................... '\n",
      "  '2007 ValidationError '\n",
      "  '....................................................................................................................................... '\n",
      "  '2007 ResourceNotFound '\n",
      "  '................................................................................................................................ '\n",
      "  '2008     Quotas '\n",
      "  '........................................................................................................................................ '\n",
      "  '2009 Request an increase for Amazon Bedrock quotas '\n",
      "  '.......................................................................... '\n",
      "  '2009     Document history '\n",
      "  '...................................................................................................................... '\n",
      "  '2010 AWS Glossary '\n",
      "  '............................................................................................................................. '\n",
      "  '2029     xvAmazon Bedrock User Guide     What is Amazon Bedrock?     Amazon '\n",
      "  'Bedrock is a fully managed service that makes high-performing foundation '\n",
      "  'models (FMs) from leading AI companies and Amazon available for your use '\n",
      "  'through a unified API. You can choose from a wide range of foundation '\n",
      "  'models to find the model that is best suited for your use case. Amazon '\n",
      "  'Bedrock also offers a broad set of capabilities to build generative AI '\n",
      "  'applications with security, privacy, and responsible AI. Using Amazon '\n",
      "  'Bedrock, you can easily experiment with and evaluate top foundation models '\n",
      "  'for your use cases, privately customize them with your data using '\n",
      "  'techniques such as fine-tuning and Retrieval Augmented Generation (RAG), '\n",
      "  'and build agents that execute tasks using your enterprise systems and data '\n",
      "  \"sources.     With Amazon Bedrock's serverless experience, you can get \"\n",
      "  'started quickly, privately customize foundation models with your own data, '\n",
      "  'and easily and securely integrate and deploy them into your applications '\n",
      "  'using AWS tools without having to manage any infrastructure.     Topics     '\n",
      "  '? What can I do with Amazon Bedrock?     ? How do I get started with Amazon '\n",
      "  'Bedrock?     ? Amazon Bedrock pricing     ? Key terminology     What can I '\n",
      "  'do with Amazon Bedrock?     You can use Amazon Bedrock to do the '\n",
      "  'following:     ? Experiment with prompts and configurations ? Submit '\n",
      "  'prompts and generate responses with model inference by sending prompts '\n",
      "  'using different configurations and foundation models to generate responses. '\n",
      "  'You can use the API or the text, image, and chat playgrounds in the console '\n",
      "  \"to experiment in a graphical interface. When you're ready, set up your \"\n",
      "  'application to make requests to the InvokeModel APIs.     ? Augment '\n",
      "  'response generation with information from your data sources ? Create '\n",
      "  'knowledge bases by uploading data sources to be queried in order to augment '\n",
      "  \"a foundation model's generation of responses.     What can I do with Amazon \"\n",
      "  'Bedrock? 1Amazon Bedrock User Guide     ? Create applications that reason '\n",
      "  'through how to help a customer ? Build agents that use foundation models, '\n",
      "  'make API calls, and (optionally) query knowledge bases in order to reason '\n",
      "  'through and carry out tasks for your customers.     ? Adapt models to '\n",
      "  'specific tasks and domains with training data ? Customize an Amazon Bedrock '\n",
      "  'foundation model by providing training data for fine-tuning or '\n",
      "  \"continued-pretraining in order to adjust a model's parameters and improve \"\n",
      "  'its performance on specific tasks or in certain domains.     ? Improve your '\n",
      "  \"FM-based application's efficiency and output ? Purchase Provisioned \"\n",
      "  'Throughput for a foundation model in order to run inference on models more '\n",
      "  'efficiently and at discounted rates.     ? Determine the best model for '\n",
      "  'your use case ? Evaluate outputs of different models with built-in or '\n",
      "  'custom prompt datasets to determine the model that is best suited for your '\n",
      "  'application.     ? Prevent inappropriate or unwanted content ? Use '\n",
      "  'guardrails to implement safeguards for your generative AI applications.     '\n",
      "  'To learn about Regions that support Amazon Bedrock and the foundation '\n",
      "  'models and features that Amazon Bedrock supports, see Supported foundation '\n",
      "  'models in Amazon Bedrock and Feature support by AWS Region in Amazon '\n",
      "  'Bedrock.     How do I get started with Amazon Bedrock?']\n",
      "STU0PK5QDL\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon Bedrock?\"\n",
    "\n",
    "response = ask_bedrock_llm_with_knowledge_base(query, kb_id)\n",
    "generated_text = response['output']['text']\n",
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "        contexts.append(reference[\"content\"][\"text\"])\n",
    "print(f\"---------- Generated using Anthropic Claude 3 Sonnet:\")\n",
    "pp.pprint(generated_text )\n",
    "print(f'---------- The citations for the response:')\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0892703-6fa4-4bac-a3b1-7cd30523b888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Generated using Anthropic Claude 3 Sonnet:\n",
      "('Yes, it is possible to purchase provisioned throughput for Anthropic Claude '\n",
      " 'Sonnet models on Amazon Bedrock. The search results show that the following '\n",
      " 'Anthropic Claude Sonnet models are supported for provisioned throughput:\\n'\n",
      " '\\n'\n",
      " '- Claude 3 Sonnet 28k\\n'\n",
      " '- Anthropic Claude 3.5 Sonnet 18k\\n'\n",
      " '- Anthropic Claude 3.5 Sonnet 200k\\n'\n",
      " '- Anthropic Claude 3.5 Sonnet 51k The search results provide details on the '\n",
      " 'regions where provisioned throughput can be purchased for these models, as '\n",
      " 'well as whether no-commitment purchases are supported for the base models.')\n",
      "---------- The citations for the response:\n",
      "[ 'Claude 3 Sonnet 28k     anthropic.claude-3- sonnet-20240229-v 1:0:28k     '\n",
      "  'us-east-1     us-west-2     ap-northeast-1     ap-northeast-2     '\n",
      "  'ap-south-1     ap-southeast-1     ap-southeast-2     eu-west-1     '\n",
      "  'eu-west-3     Yes     Anthropic Claude 3.5 Sonnet 18k     '\n",
      "  'anthropic.claude-3-5- sonnet-20240620- v1:0:18k     us-west-2     '\n",
      "  'ap-south-1     ap-southeast-2     eu-central-2     Yes     Anthropic Claude '\n",
      "  '3.5 Sonnet 200k     anthropic.claude-3-5- sonnet-20240620- v1:0:200k     '\n",
      "  'us-west-2     ap-south-1     ap-southeast-2     eu-central-2     Yes     '\n",
      "  'Supported regions and models 1396Amazon Bedrock User Guide     Model name '\n",
      "  'Model ID for Provisioned Throughput     Regions supported No-commitment '\n",
      "  'purchase supported for base model     Anthropic Claude 3.5 Sonnet 51k     '\n",
      "  'anthropic.claude-3-5- sonnet-20240620- v1:0:51k     us-west-2     '\n",
      "  'ap-south-1     ap-southeast-2     eu-central-2     Yes     Anthropic Claude '\n",
      "  'Instant 100k     anthropic.claude-i nstant-v1:2:100k     us-east-1     '\n",
      "  'us-west-2     Yes     Cohere Command 4k cohere.command-tex t-v14:7:4k     '\n",
      "  'us-east-1     us-west-2     Yes     Cohere Command Light 4k     '\n",
      "  'cohere.command-lig ht-text-v14:7:4k     us-east-1     us-west-2     Yes     '\n",
      "  'Cohere Embed English     cohere.embed-engli sh-v3:0:512     us-east-1     '\n",
      "  'us-west-2     ca-central-1     eu-west-2     eu-west-3     sa-east-1     '\n",
      "  'Yes     Supported regions and models 1397Amazon Bedrock User Guide     '\n",
      "  'Model name Model ID for Provisioned Throughput     Regions supported '\n",
      "  'No-commitment purchase supported for base model     Cohere Embed '\n",
      "  'Multilingual     cohere.embed-multi lingual-v3:0:512     us-east-1     '\n",
      "  'us-west-2     ca-central-1     eu-west-2     eu-west-3     sa-east-1     '\n",
      "  'Yes     Meta Llama 3.1 70B Instruct 128k     meta.llama3-1-70b- '\n",
      "  'instruct-v1:0:128k     us-east-2     us-west-2     Yes     Meta Llama 3.1 '\n",
      "  '8B Instruct 128k     meta.llama3-1-8b-i nstruct-v1:0:128k     us-east-2     '\n",
      "  'us-west-2     Yes     To learn about the features in Amazon Bedrock that '\n",
      "  'you can use Provisioned Throughput with, see Use a Provisioned Throughput '\n",
      "  'with an Amazon Bedrock resource.     Prerequisites for Provisioned '\n",
      "  'Throughput     Before you can purchase and manage Provisioned Throughput, '\n",
      "  'you need to fulfill the following prerequisites:     1. Request access to '\n",
      "  'the model or models that you want to purchase Provisioned Throughput for. '\n",
      "  'After access has been granted, you can purchase Provisioned Throughput for '\n",
      "  'the base model and any models customized from it.     2. Ensure that your '\n",
      "  'IAM role has access to the Provisioned Throughput API actions. If your role '\n",
      "  'has the AmazonBedrockFullAccess AWS-managed policy attached, you can skip '\n",
      "  'this step. Otherwise, do the following:     Prerequisites 1398Amazon '\n",
      "  'Bedrock User Guide     1. Follow the steps at Creating IAM policies and '\n",
      "  'create the following policy, which allows a role to create a Provisioned '\n",
      "  'Throughput for all foundation and custom models.',\n",
      "  'Claude 3 Sonnet 28k     anthropic.claude-3- sonnet-20240229-v 1:0:28k     '\n",
      "  'us-east-1     us-west-2     ap-northeast-1     ap-northeast-2     '\n",
      "  'ap-south-1     ap-southeast-1     ap-southeast-2     eu-west-1     '\n",
      "  'eu-west-3     Yes     Anthropic Claude 3.5 Sonnet 18k     '\n",
      "  'anthropic.claude-3-5- sonnet-20240620- v1:0:18k     us-west-2     '\n",
      "  'ap-south-1     ap-southeast-2     eu-central-2     Yes     Anthropic Claude '\n",
      "  '3.5 Sonnet 200k     anthropic.claude-3-5- sonnet-20240620- v1:0:200k     '\n",
      "  'us-west-2     ap-south-1     ap-southeast-2     eu-central-2     Yes     '\n",
      "  'Supported regions and models 1396Amazon Bedrock User Guide     Model name '\n",
      "  'Model ID for Provisioned Throughput     Regions supported No-commitment '\n",
      "  'purchase supported for base model     Anthropic Claude 3.5 Sonnet 51k     '\n",
      "  'anthropic.claude-3-5- sonnet-20240620- v1:0:51k     us-west-2     '\n",
      "  'ap-south-1     ap-southeast-2     eu-central-2     Yes     Anthropic Claude '\n",
      "  'Instant 100k     anthropic.claude-i nstant-v1:2:100k     us-east-1     '\n",
      "  'us-west-2     Yes     Cohere Command 4k cohere.command-tex t-v14:7:4k     '\n",
      "  'us-east-1     us-west-2     Yes     Cohere Command Light 4k     '\n",
      "  'cohere.command-lig ht-text-v14:7:4k     us-east-1     us-west-2     Yes     '\n",
      "  'Cohere Embed English     cohere.embed-engli sh-v3:0:512     us-east-1     '\n",
      "  'us-west-2     ca-central-1     eu-west-2     eu-west-3     sa-east-1     '\n",
      "  'Yes     Supported regions and models 1397Amazon Bedrock User Guide     '\n",
      "  'Model name Model ID for Provisioned Throughput     Regions supported '\n",
      "  'No-commitment purchase supported for base model     Cohere Embed '\n",
      "  'Multilingual     cohere.embed-multi lingual-v3:0:512     us-east-1     '\n",
      "  'us-west-2     ca-central-1     eu-west-2     eu-west-3     sa-east-1     '\n",
      "  'Yes     Meta Llama 3.1 70B Instruct 128k     meta.llama3-1-70b- '\n",
      "  'instruct-v1:0:128k     us-east-2     us-west-2     Yes     Meta Llama 3.1 '\n",
      "  '8B Instruct 128k     meta.llama3-1-8b-i nstruct-v1:0:128k     us-east-2     '\n",
      "  'us-west-2     Yes     To learn about the features in Amazon Bedrock that '\n",
      "  'you can use Provisioned Throughput with, see Use a Provisioned Throughput '\n",
      "  'with an Amazon Bedrock resource.     Prerequisites for Provisioned '\n",
      "  'Throughput     Before you can purchase and manage Provisioned Throughput, '\n",
      "  'you need to fulfill the following prerequisites:     1. Request access to '\n",
      "  'the model or models that you want to purchase Provisioned Throughput for. '\n",
      "  'After access has been granted, you can purchase Provisioned Throughput for '\n",
      "  'the base model and any models customized from it.     2. Ensure that your '\n",
      "  'IAM role has access to the Provisioned Throughput API actions. If your role '\n",
      "  'has the AmazonBedrockFullAccess AWS-managed policy attached, you can skip '\n",
      "  'this step. Otherwise, do the following:     Prerequisites 1398Amazon '\n",
      "  'Bedrock User Guide     1. Follow the steps at Creating IAM policies and '\n",
      "  'create the following policy, which allows a role to create a Provisioned '\n",
      "  'Throughput for all foundation and custom models.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Is it possible to purchase provisioned throughput for Anthropic Claude Sonnet on Amazon Bedrock?\"\n",
    "\n",
    "response = ask_bedrock_llm_with_knowledge_base(query, kb_id)\n",
    "generated_text = response['output']['text']\n",
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "        contexts.append(reference[\"content\"][\"text\"])\n",
    "print(f\"---------- Generated using Anthropic Claude 3 Sonnet:\")\n",
    "pp.pprint(generated_text )\n",
    "print(f'---------- The citations for the response:')\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0f09-2ecf-40c5-9dd2-1c42a7af6231",
   "metadata": {},
   "source": [
    "# Contextual Grounding Check with Amazon Bedrock Guardrails\n",
    "Contextual grounding check evaluates for hallucinations across two paradigms:\n",
    "\n",
    "- Grounding – This checks if the model response is factually accurate based on the source and is grounded in the source. Any new information introduced in the response will be considered un-grounded.\n",
    "\n",
    "- Relevance – This checks if the model response is relevant to the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "810e1acf-ddbe-4e93-bf96-32e7282a7db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrock-rag-grounding-guardrail-4be13c\n"
     ]
    }
   ],
   "source": [
    "# Create guardrail\n",
    "\n",
    "random_id_suffix = str(uuid.uuid1())[:6] # get first 6 characters of uuid string to generate guardrail name suffix\n",
    "\n",
    "bedrock_client = boto3.client('bedrock')\n",
    "guardrail_name = f\"bedrock-rag-grounding-guardrail-{random_id_suffix}\"\n",
    "print(guardrail_name)\n",
    "\n",
    "guardrail_response = bedrock_client.create_guardrail(\n",
    "    name=guardrail_name,\n",
    "    description='Guardrail for ensuring relevance and grounding of model responses in RAG powered chatbot',\n",
    "    contextualGroundingPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {\n",
    "                'type': 'GROUNDING',\n",
    "                'threshold': 0.5\n",
    "            },\n",
    "            {\n",
    "                'type': 'RELEVANCE',\n",
    "                'threshold': 0.5\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging='Can you please rephrase your question?',\n",
    "    blockedOutputsMessaging='Sorry, I am not able to find the correct answer to your query - Can you try reframing your query to be more specific'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d615898-b2a3-4b8c-8830-f6710fc86ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3ab5faab-6f00-4610-90a4-8da1bc5542a1',\n",
       "  'HTTPStatusCode': 202,\n",
       "  'HTTPHeaders': {'date': 'Thu, 21 Nov 2024 22:16:46 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '172',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '3ab5faab-6f00-4610-90a4-8da1bc5542a1'},\n",
       "  'RetryAttempts': 0},\n",
       " 'guardrailId': 'vkxoa1vlr9wb',\n",
       " 'guardrailArn': 'arn:aws:bedrock:us-west-2:615452588358:guardrail/vkxoa1vlr9wb',\n",
       " 'version': 'DRAFT',\n",
       " 'createdAt': datetime.datetime(2024, 11, 21, 22, 16, 46, 708786, tzinfo=tzlocal())}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guardrailId = guardrail_response['guardrailId']\n",
    "guardrail_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a503292a-b84c-46d5-8fe2-f9d199198f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'd109a047-b1eb-4497-adcd-4e16495d1ba9', 'HTTPStatusCode': 202, 'HTTPHeaders': {'date': 'Thu, 21 Nov 2024 22:16:47 GMT', 'content-type': 'application/json', 'content-length': '44', 'connection': 'keep-alive', 'x-amzn-requestid': 'd109a047-b1eb-4497-adcd-4e16495d1ba9'}, 'RetryAttempts': 0}, 'guardrailId': 'vkxoa1vlr9wb', 'version': '1'}\n",
      "vkxoa1vlr9wb\n",
      "Stored 'guardrailId' (str)\n"
     ]
    }
   ],
   "source": [
    "guardrail_version = bedrock_client.create_guardrail_version(\n",
    "    guardrailIdentifier=guardrail_response['guardrailId'],\n",
    "    description='Working version of RAG app guardrail with higher thresholds for contextual grounding'\n",
    ")\n",
    "\n",
    "guardrailVersion = guardrail_response['version']\n",
    "\n",
    "%store guardrailId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dfbd6ac-6411-47dd-b645-33df81614878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and Generate using Guardrail\n",
    "\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "\n",
    "def retrieve_and_generate_with_guardrail(\n",
    "    query,\n",
    "    kb_id,\n",
    "    model_arn=llm_model_id,\n",
    "    session_id=None\n",
    "):\n",
    "\n",
    "    prompt_template = 'You are a helpful AI assistant to help users understand documented risks in various projects. \\\n",
    "    Answer the user query based on the context retrieved. If you dont know the answer, dont make up anything. \\\n",
    "    Only answer based on what you know from the provided context. You can ask the user for clarifying questions if anything is unclear\\\n",
    "    But generate an answer only when you are confident about it and based on the provided context.\\\n",
    "    User Query: $query$\\\n",
    "    Context: $search_results$'\n",
    "\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\n",
    "            'text': query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'generationConfiguration': {\n",
    "                    'guardrailConfiguration': {\n",
    "                        'guardrailId': guardrailId,\n",
    "                        'guardrailVersion': guardrailVersion\n",
    "                    },\n",
    "                    'inferenceConfig': {\n",
    "                        'textInferenceConfig': {\n",
    "                            'temperature': 0.7,\n",
    "                            'topP': 0.25\n",
    "                        }\n",
    "                    },\n",
    "                    'promptTemplate': {\n",
    "                        'textPromptTemplate': prompt_template\n",
    "                    }\n",
    "                },\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': model_arn,\n",
    "                'retrievalConfiguration': {\n",
    "                    'vectorSearchConfiguration': {\n",
    "                        'overrideSearchType': 'SEMANTIC'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6f710a5-74c9-4480-8308-e9b362730428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '4f277de6-0b5a-485e-ac8d-5964372008c3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 21 Nov 2024 22:16:55 GMT', 'content-type': 'application/json', 'content-length': '1703', 'connection': 'keep-alive', 'x-amzn-requestid': '4f277de6-0b5a-485e-ac8d-5964372008c3'}, 'RetryAttempts': 0}, 'citations': [{'generatedResponsePart': {'textResponsePart': {'span': {'end': 50, 'start': 0}, 'text': 'Sorry, I am unable to assist you with this request.'}}, 'retrievedReferences': []}], 'guardrailAction': 'NONE', 'output': {'text': 'According to the context provided, Amazon Bedrock is a fully managed service from AWS that provides access to high-performing foundation models (FMs) from leading AI companies and Amazon through a unified API.\\n\\nSome key points about Amazon Bedrock:\\n\\n- It allows you to choose from a wide range of foundation models to find the one best suited for your use case.\\n- It offers capabilities to build generative AI applications with security, privacy, and responsible AI principles.\\n- Using Bedrock, you can experiment with and evaluate different foundation models, privately customize them with your own data using techniques like fine-tuning and retrieval augmented generation (RAG), and build agents that execute tasks using your systems and data sources.\\n- It provides a serverless experience where you can get started quickly, customize models with your data, and integrate/deploy them into applications using AWS tools without managing infrastructure.\\n- It supports features like augmenting responses with knowledge bases, adapting models to specific domains via training data, provisioned throughput for efficient model invocation, guardrails to prevent inappropriate output, and model evaluation.\\n\\nSo in summary, Amazon Bedrock is an AWS service that gives developers access to state-of-the-art foundation models from multiple providers through a unified, managed experience for building generative AI applications.'}, 'sessionId': '132d40f5-7dc1-45ca-a21f-56b087c6096f'}\n"
     ]
    }
   ],
   "source": [
    "# Knowledge BAse ID\n",
    "\n",
    "query = 'What is Amazon Bedrock?'\n",
    "\n",
    "model_response = retrieve_and_generate_with_guardrail(query, kb_id)\n",
    "\n",
    "pp.pprint(model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56677a75-464c-453b-b2bd-7813f2a65d1a",
   "metadata": {},
   "source": [
    "# Evaluating RAG with RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e33826a-0836-4ad1-9553-dcb7df3f87c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6238/422286211.py:22: LangChainDeprecationWarning: The class `BedrockEmbeddings` was deprecated in LangChain 0.2.11 and will be removed in 1.0. An updated version of the class exists in the langchain-aws package and should be used instead. To use it run `pip install -U langchain-aws` and import as `from langchain_aws import BedrockEmbeddings`.\n",
      "  bedrock_embeddings = BedrockEmbeddings(model_id=embedding_model_id,client=bedrock_client)\n"
     ]
    }
   ],
   "source": [
    "from botocore.client import Config\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain_community.chat_models.bedrock import BedrockChat\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config\n",
    "                              )\n",
    "\n",
    "llm_for_text_generation = BedrockChat(model_id=llm_model_id, client=bedrock_client)\n",
    "\n",
    "llm_for_evaluation = BedrockChat(model_id=llm_model_id, client=bedrock_client)\n",
    "\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=embedding_model_id,client=bedrock_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3511743-c8c2-4e3c-949a-79bf9bec79cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question/prompt</th>\n",
       "      <th>Correct answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are all models accessible on Amazon Bedrock by default?</td>\n",
       "      <td>Access to Amazon Bedrock foundation models isn't granted by default. You can request access, or modify access, to foundation models only by using the Amazon Bedrock console. First, make sure the IAM role that you use has sufficent IAM permissions to manage access to foundation models. Then, add or remove access to a model by following the instructions at Add or remove access to Amazon Bedrock foundation models.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Model ID of Amazon Titan Text Premier</td>\n",
       "      <td>amazon.titan-text-premier-v1:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With which Anthropic Claude models can I use the Text Completions API?</td>\n",
       "      <td>Anthropic Claude Instant v1.2, Anthropic Claude v2, Anthropic Claude v2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What policies can I configure in Amazon Bedrock guardrails?</td>\n",
       "      <td>You can configure the following policies in a guardrail to avoid undesirable and harmful content and remove sensitive information for privacy protection. Content filters – Adjust filter strengths to block input prompts or model responses containing harmful content.<br>Denied topics – Define a set of topics that are undesirable in the context of your application. These topics will be blocked if detected in user queries or model responses.<br>Word filters – Configure filters to block undesirable words, phrases, and profanity. Such words can include offensive terms, competitor names etc.<br>Sensitive information filters – Block or mask sensitive information such as personally identifiable information (PII) or custom regex in user inputs and model responses.<br>Contextual grounding check – Detect and filter hallucinations in model responses based on grounding in a source and relevance to the user query.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which built in datasets are available on Amazon Bedrock for model evaluation of text generation?</td>\n",
       "      <td>The following built-in datasets contain prompts that are well-suited for use in general text generation tasks. Bias in Open-ended Language Generation Dataset (BOLD)<br>The Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.<br><br>RealToxicityPrompts<br>RealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.<br><br>T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)<br>TREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".<br><br>WikiText2<br>WikiText2 is a HuggingFace dataset that contains prompts used in general text generation.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('data/bedrock-user-guide-test.csv')\n",
    "test = test.dropna()\n",
    "test.style.set_properties(**{'text-align': 'left', 'border': '1px solid black'})\n",
    "test.to_string(justify='left', index=False)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    pp.pprint(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0a5f15a-8053-4edc-97e5-c6b96641c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = test['Question/prompt'].tolist()\n",
    "ground_truth = [gt for gt in test['Correct answer'].tolist()]\n",
    "\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    response = ask_bedrock_llm_with_knowledge_base(query, kb_id)\n",
    "    generatedResult = response['output']['text']\n",
    "    answers.append(generatedResult)\n",
    "    contexts.append([doc['content']['text'] for doc in response['citations'][0]['retrievedReferences']])\n",
    "\n",
    "# To dict\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truth\": ground_truth\n",
    "}\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acfc1f9f-27a9-42d7-8c0b-f071ead268f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Access to Amazon Bedrock foundation models isn't granted by default. You can request access, or modify access, to foundation models only by using the Amazon Bedrock console. First, make sure the IAM role that you use has\\xa0sufficent IAM permissions\\xa0to manage access to foundation models. Then, add or remove access to a model by following the instructions at\\xa0Add or remove access to Amazon Bedrock foundation models.\",\n",
       " 'amazon.titan-text-premier-v1:0',\n",
       " 'Anthropic Claude Instant v1.2, Anthropic Claude v2, Anthropic Claude v2.1',\n",
       " 'You can configure the following policies in a guardrail to avoid undesirable and harmful content and remove sensitive information for privacy protection. Content filters\\xa0– Adjust filter strengths to block input prompts or model responses containing harmful content.\\nDenied topics\\xa0– Define a set of topics that are undesirable in the context of your application. These topics will be blocked if detected in user queries or model responses.\\nWord filters\\xa0– Configure filters to block undesirable words, phrases, and profanity. Such words can include offensive terms, competitor names etc.\\nSensitive information filters\\xa0– Block or mask sensitive information such as personally identifiable information (PII) or custom regex in user inputs and model responses.\\nContextual grounding check\\xa0– Detect and filter hallucinations in model responses based on grounding in a source and relevance to the user query.',\n",
       " 'The following built-in datasets contain prompts that are well-suited for use in general text generation tasks. Bias in Open-ended Language Generation Dataset (BOLD)\\nThe Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.\\n\\nRealToxicityPrompts\\nRealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.\\n\\nT-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)\\nTREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".\\n\\nWikiText2\\nWikiText2 is a HuggingFace dataset that contains prompts used in general text generation.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bce932e-94b8-4068-acc4-c0d85287daaa",
   "metadata": {},
   "source": [
    "### Let us deep dive into the two RAGAS metrics that we will also use in the next lab\n",
    "\n",
    "- answer_relevancy: Answer Relevancy metric focuses on assessing how pertinent the generated answer is to the given prompt. A lower score is assigned to answers that are incomplete or contain redundant information and higher scores indicate better relevancy. This metric is computed using the user_input, the retrived_contexts and the response.\n",
    "  \n",
    "- answer_correctness: The assessment of Answer Correctness involves gauging the accuracy of the generated answer when compared to the ground truth. This evaluation relies on the ground truth and the answer, with scores ranging from 0 to 1. A higher score indicates a closer alignment between the generated answer and the ground truth, signifying better correctness. Answer correctness encompasses two critical aspects: semantic similarity between the generated answer and the ground truth, as well as factual similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b16eb532-3c65-4adf-b6f2-cab77d11cc81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b9da3358eb494d889db9aeed3d8334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy\n",
    ")\n",
    "\n",
    "#specify the metrics here, kept one for now, we can add more.\n",
    "metrics_ar = [\n",
    "        answer_relevancy\n",
    "    ]\n",
    "\n",
    "result_ar = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=metrics_ar,\n",
    "    llm=llm_for_evaluation,\n",
    "    embeddings=bedrock_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "ragas_df_ar= result_ar.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c76503a5-36de-4365-a390-a37dba57c439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are all models accessible on Amazon Bedrock by default?</td>\n",
       "      <td>[The following table lists product IDs for Amazon Bedrock foundation models:     The following is the format of the IAM policy you can attach to a role to control model access permissions:     Model Product ID     AI21 Labs Jurassic-2 Mid 1d288c71-65f9-489a-a3e2-9c7f4f6e6a85     AI21 Labs Jurassic-2 Ultra cc0bdd50-279a-40d8-829c-4009b77a1fcc     AI21 Jamba-Instruct prod-dr2vpvd4k73aq     AI21 Labs Jamba 1.5 Large prod-evcp4w4lurj26     AI21 Labs Jamba 1.5 Mini prod-ggrzjm65qmjhm     Anthropic Claude c468b48a-84df-43a4-8c46-8870630108a7     Anthropic Claude Instant b0eb9475-3a2c-43d1-94d3-56756fd43737     Anthropic Claude 3 Sonnet prod-6dw3qvchef7zy     Anthropic Claude 3.5 Sonnet prod-m5ilt4siql27k     Anthropic Claude 3.5 Sonnet v2 prod-cx7ovbu5wex7g     Anthropic Claude 3 Haiku prod-ozonys2hmmpeu     Anthropic Claude 3.5 Haiku prod-5oba7y7jpji56     Anthropic Claude 3 Opus prod-fm3feywmwerog     Grant permissions to request access to foundation models 27Amazon Bedrock User Guide     Model Product ID     Cohere Command a61c46fe-1747-41aa-9af0-2e0ae8a9ce05     Cohere Command Light 216b69fd-07d5-4c7b-866b-936456d68311     Cohere Command R prod-tukx4z3hrewle     Cohere Command R+ prod-nb4wqmplze2pm     Cohere Embed (English) b7568428-a1ab-46d8-bab3-37def50f6f6a     Cohere Embed (Multilingual) 38e55671-c3fe-4a44-9783-3584906e7cad     Stable Diffusion XL 1.0 prod-2lvuzn4iy6n6o     Stable Image Core 1.0 prod-eacdrmv7zfc5e     Stable Diffusion 3 Large 1.0 prod-cqfmszl26sxu4     Stable Image Ultra 1.0 prod-7boen2z2wnxrg     { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow|Deny\", \"Action\": [ \"aws-marketplace:Subscribe\" ], \"Resource\": \"*\", \"Condition\": { \"ForAnyValue:StringEquals\": { \"aws-marketplace:ProductId\": [ model-product-id-1, model-product-id-2, ... ] } } },     Grant permissions to request access to foundation models 28Amazon Bedrock User Guide      { \"Effect\": \"Allow|Deny\", \"Action\": [ \"aws-marketplace:Unsubscribe\" \"aws-marketplace:ViewSubscriptions\" ], \"Resource\": \"*\" } ] }     To see an example policy, refer to Allow access to third-party model subscriptions.     Add or remove access to Amazon Bedrock foundation models     Before you can use a foundation model in Amazon Bedrock, you must request access to it. If you no longer need access to a model, you can remove access from it.     Note     You can't remove request access from the Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models. You can prevent users from making inference calls to these models by using an IAM policy and specifying the model ID. For more information, see Deny access for inference on specific models.     Once access is provided to a model, it is available for all users in the AWS account.     To add or remove access to foundation models     1. Make sure you have permissions to request access, or modify access, to Amazon Bedrock foundation models.     2. Sign into the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.     3. In the left navigation pane, under Bedrock configurations, choose Model access.     4. On the Model access page, choose Modify model access.     5. Select the models that you want the account to have access to and unselect the models that you don't want the account to have access to.]</td>\n",
       "      <td>No, not all models are accessible on Amazon Bedrock by default. Before you can use a foundation model in Amazon Bedrock, you must request access to it. The documentation states: \"Before you can use a foundation model in Amazon Bedrock, you must request access to it. If you no longer need access to a model, you can remove access from it.\" However, the documentation also notes that you cannot remove access from certain models like Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models. For these models, you can prevent users from making inference calls by using an IAM policy and specifying the model ID.</td>\n",
       "      <td>Access to Amazon Bedrock foundation models isn't granted by default. You can request access, or modify access, to foundation models only by using the Amazon Bedrock console. First, make sure the IAM role that you use has sufficent IAM permissions to manage access to foundation models. Then, add or remove access to a model by following the instructions at Add or remove access to Amazon Bedrock foundation models.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Model ID of Amazon Titan Text Premier</td>\n",
       "      <td>[Separate keys with a space.     aws bedrock-agent untag-resource \\ --resource-arn \"arn:aws:bedrock:us-east-1:123456789012:agent/AGENT12345\" \\ --tag-keys key=department facing     List the tags for the agent.     aws bedrock-agent list-tags-for-resource \\ --resource-arn \"arn:aws:bedrock:us-east-1:123456789012:agent/AGENT12345\"     Python (Boto)     Add two tags to an agent.     import boto3     bedrock = boto3.client(service_name='bedrock-agent')     tags = [ { 'key': 'department', 'value': 'billing' }, {     Use the API 1417           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_TagResource.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_TagResource.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_UntagResource.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_UntagResource.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_ListTagsForResource.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_ListTagsForResource.htmlAmazon Bedrock User Guide      'key': 'facing', 'value': 'internal' } ]     bedrock.tag_resource(resourceArn='arn:aws:bedrock:us-east-1:123456789012:agent/ AGENT12345', tags=tags)     Remove the tags from the agent.     bedrock.untag_resource( resourceArn='arn:aws:bedrock:us-east-1:123456789012:agent/AGENT12345', tagKeys=['department', 'facing'] )     List the tags for the agent.     bedrock.list_tags_for_resource(resourceArn='arn:aws:bedrock:us- east-1:123456789012:agent/AGENT12345')     Use the API 1418Amazon Bedrock User Guide     Overview of Amazon Titan models     Amazon Titan foundation models (FMs) are a family of FMs pretrained by AWS on large datasets, making them powerful, general-purpose models built to support a variety of use cases. Use them as-is or privately customize them with your own data.     Amazon Titan supports the following models for Amazon Bedrock.     ? Amazon Titan Text     ? Amazon Titan Text Embeddings V2     ? Amazon Titan Multimodal Embeddings G1     ? Amazon Titan Image Generator G1 V1     Topics     ? Amazon Titan Text models     ? Amazon Titan Text Embeddings models     ? Amazon Titan Multimodal Embeddings G1 model     ? Amazon Titan Image Generator G1 models     Amazon Titan Text models     Amazon Titan text models include Amazon Titan Text G1 - Premier, Amazon Titan Text G1 - Express and Amazon Titan Text G1 - Lite.     Amazon Titan Text G1 - Premier     Amazon Titan Text G1 - Premier is a large language model for text generation. It is useful for a wide range of tasks including open-ended and context-based question answering, code generation, and summarization. This model is integrated with Amazon Bedrock Knowledge Base and Amazon Bedrock Agents. The model also supports Custom Finetuning in preview.     ? Model ID ? amazon.titan-text-premier-v1:0     ? Max tokens ? 32K     ? Languages ? English     Amazon Titan Text 1419Amazon Bedrock User Guide     ? Supported use cases ? 32k context window, open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, chat, Knowledge Base support, Agents support, Model Customization (preview).     ? Inference parameters ? Temperature, Top P (defaults: Temperature = 0.7, Top P = 0.9)     AWS AI Service Card - Amazon Titan Text Premier     Amazon Titan Text G1 - Express     Amazon Titan Text G1 - Express is a large language model for text generation. It is useful for a wide range of advanced, general language tasks such as open-ended text generation and conversational chat, as well as support within Retrieval Augmented Generation (RAG). At launch, the model is optimized for English, with multilingual support for more than 30 additional languages available in preview.     ? Model ID ? amazon.titan-text-express-v1     ? Max tokens ? 8K     ? Languages ? English (GA), 100 additional languages (Preview)     ? Supported use cases ? Retrieval augmented generation, open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, and chat., Model ID ? amazon.titan-text-premier-v1:0     ? Max tokens ? 32K     ? Languages ? English     Amazon Titan Text 1419Amazon Bedrock User Guide     ? Supported use cases ? 32k context window, open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, chat, Knowledge Base support, Agents support, Model Customization (preview).     ? Inference parameters ? Temperature, Top P (defaults: Temperature = 0.7, Top P = 0.9)     AWS AI Service Card - Amazon Titan Text Premier     Amazon Titan Text G1 - Express     Amazon Titan Text G1 - Express is a large language model for text generation. It is useful for a wide range of advanced, general language tasks such as open-ended text generation and conversational chat, as well as support within Retrieval Augmented Generation (RAG). At launch, the model is optimized for English, with multilingual support for more than 30 additional languages available in preview.     ? Model ID ? amazon.titan-text-express-v1     ? Max tokens ? 8K     ? Languages ? English (GA), 100 additional languages (Preview)     ? Supported use cases ? Retrieval augmented generation, open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, and chat.     Amazon Titan Text G1 - Lite     Amazon Titan Text G1 - Lite is a light weight efficient model, ideal for fine-tuning of English- language tasks, including like summarizations and copy writing, where customers want a smaller, more cost-effective model that is also highly customizable.     ? Model ID ? amazon.titan-text-lite-v1     ? Max tokens ? 4K     ? Languages ? English     ? Supported use cases ? Open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, and chat.     Amazon Titan Text G1 - Express 1420           https://aws.amazon.com/machine-learning/responsible-machine-learning/titan-text-premier/Amazon Bedrock User Guide     Amazon Titan Text Model Customization     For more information on customizing Amazon Titan text models, see the following pages.     ? Prepare the datasets     ? Amazon Titan text model customization hyperparameters     Amazon Titan Text Prompt Engineering Guidelines     Amazon Titan text models can be used in a wide variety of applications for different use cases. Amazon Titan Text models have prompt engineering guidelines for the following applications including:     ? Chatbot     ? Text2SQL     ? Function Calling     ? RAG (Retrieval Augmented Generation)     For more information on Amazon Titan Text prompt engineering guidelines, see Amazon Titan Text Prompt Engineering Guidelines.     For general prompt engineering guidelines, see Prompt Engineering Guidelines.     AWS AI Service Card - Amazon Titan Text     AI Service Cards provide transparency and document the intended use cases and fairness considerations for our AWS AI services. AI Service Cards provide a single place to find information on the intended use cases, responsible AI design choices, best practices, and performance for a set of AI service use cases.     Amazon Titan Text Embeddings models     Amazon Titan Embeddings text models include Amazon Titan Text Embeddings v2 and Titan Text Embeddings G1 model.     Text embeddings represent meaningful vector representations of unstructured text such as documents, paragraphs, and sentences. You input a body of text and the output is a (1 x n) vector. You can use embedding vectors for a wide variety of applications.     Amazon Titan Text Model Customization 1421           https://d2eo22ngex1n9g.cloudfront.net/Documentation/User+Guides/Titan/Amazon+Titan+Text+Prompt+Engineering+Guidelines.pdf         https://d2eo22ngex1n9g.cloudfront.net/Documentation/User+Guides/Titan/Amazon+Titan+Text+Prompt+Engineering+Guidelines.pdf         https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-engineering-guidelines.html         https://aws.amazon.com/machine-learning/responsible-machine-learning/titan-text/Amazon Bedrock User Guide     The Amazon Titan Text Embedding v2 model (amazon.titan-embed-text-v2:0) can intake up to 8,192 tokens and outputs a vector of 1,024 dimensions. The model also works in 100+ different languages. The model is optimized for text retrieval tasks, but can also perform additional tasks, such as semantic similarity and clustering. Amazon Titan Embeddings text v2 also supports long documents, however, for retrieval tasks it is recommended to segment documents into logical segments , such as paragraphs or sections.     Amazon Titan Embeddings models generate meaningful semantic representation of documents, paragraphs and sentences.]</td>\n",
       "      <td>The Model ID of Amazon Titan Text Premier is amazon.titan-text-premier-v1:0.</td>\n",
       "      <td>amazon.titan-text-premier-v1:0</td>\n",
       "      <td>0.995229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With which Anthropic Claude models can I use the Text Completions API?</td>\n",
       "      <td>[Anthropic Claude 3 model, such as Anthropic Claude 3 Opus     For information about creating system prompts, see https://docs.anthropic.com/claude/ docs/how-to-use-system-prompts in the Anthropic Claude documentation. To avoid timeouts with Anthropic Claude version 2.1, we recommend limiting the input token count in the prompt field to 180K. We expect to address this timeout issue soon.     In the inference call, fill the body field with a JSON object that conforms the type call you want to make, Anthropic Claude Text Completions API or Anthropic Claude Messages API.     Topics     ? Anthropic Claude Text Completions API     ? Anthropic Claude Messages API     Anthropic Claude models 147           https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview         https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags         https://docs.anthropic.com/en/docs/welcome         https://docs.anthropic.com/claude/docs/how-to-use-system-prompts         https://docs.anthropic.com/claude/docs/how-to-use-system-promptsAmazon Bedrock User Guide     Anthropic Claude Text Completions API     This section provides inference parameters and code examples for using Anthropic Claude models with the Text Completions API.     Topics     ? Anthropic Claude Text Completions API overview     ? Supported models     ? Request and Response     ? Code example     Anthropic Claude Text Completions API overview     Use the Text Completion API for single-turn text generation from a user supplied prompt. For example, you can use the Text Completion API to generate text for a blog post or to summarize text input from a user.     For information about creating prompts for Anthropic Claude models, see Introduction to prompt design. If you want to use your existing Text Completions prompts with the Anthropic Claude Messages API, see Migrating from Text Completions.     Supported models     You can use the Text Completions API with the following Anthropic Claude models.     ? Anthropic Claude Instant v1.2     ? Anthropic Claude v2     ? Anthropic Claude v2.1     Request and Response     The request body is passed in the body field of a request to InvokeModel or InvokeModelWithResponseStream.     For more information, see https://docs.anthropic.com/claude/reference/complete_post in the Anthropic Claude documentation.     Anthropic Claude models 148           https://docs.anthropic.com/claude/docs/introduction-to-prompt-design         https://docs.anthropic.com/claude/docs/introduction-to-prompt-design         https://docs.anthropic.com/claude/reference/migrating-from-text-completions-to-messages         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html         https://docs.anthropic.com/claude/reference/complete_postAmazon Bedrock User Guide     Request     Anthropic Claude has the following inference parameters for a Text Completion inference call.     { \"prompt\": \"<br><br>Human:&lt;prompt&gt;<br><br>Assistant:\", \"temperature\": float, \"top_p\": float, \"top_k\": int, \"max_tokens_to_sample\": int, \"stop_sequences\": [string] }     The following are required parameters.     ? prompt ? (Required) The prompt that you want Claude to complete. For proper response generation you need to format your prompt using alternating <br><br>Human: and <br> <br>Assistant: conversational turns. For example:     \"<br><br>Human: {userQuestion}<br><br>Assistant:\"     For more information, see Prompt validation in the Anthropic Claude documentation.     ? max_tokens_to_sample ? (Required) The maximum number of tokens to generate before stopping. We recommend a limit of 4,000 tokens for optimal performance.     Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens_to_sample. Different Anthropic Claude models have different maximum values for this parameter. For more information, see Model comparison in the Anthropic Claude documentation.     Default Minimum Maximum     200 0 4096     The following are optional parameters.     ? stop_sequences ? (Optional) Sequences that will cause the model to stop generating.     Anthropic Claude models 149           https://docs.anthropic.com/claude/reference/prompt-validation         https://docs.anthropic.com/claude/docs/models-overview#model-comparisonAmazon Bedrock User Guide     Anthropic Claude models stop on \"<br><br>Human:\", and may include additional built-in stop sequences in the future. Use the stop_sequences inference parameter to include additional strings that will signal the model to stop generating text.     ? temperature ?]</td>\n",
       "      <td>You can use the Text Completions API with the following Anthropic Claude models:<br>- Anthropic Claude Instant v1.2<br>- Anthropic Claude v2<br>- Anthropic Claude v2.1</td>\n",
       "      <td>Anthropic Claude Instant v1.2, Anthropic Claude v2, Anthropic Claude v2.1</td>\n",
       "      <td>0.676724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What policies can I configure in Amazon Bedrock guardrails?</td>\n",
       "      <td>[For more information about the fields in a content filter, see ContentFilter.     ? Specify the category in the type field.     ? Specify the strength of the filter for prompts in the strength field of the textToTextFiltersForPrompt field and for model responses in the strength field of the textToTextFiltersForResponse.     ? (Optional) Attach any tags to the guardrail. For more information, see Tagging Amazon Bedrock resources.     ? (Optional) For security, include the ARN of a KMS key in the kmsKeyId field.     The response format is as follows:     HTTP/1.1 202 Content-type: application/json     { \"createdAt\": \"string\", \"guardrailArn\": \"string\", \"guardrailId\": \"string\", \"version\": \"string\" }     Create a guardrail 480           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Topic.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_ContentFilter.htmlAmazon Bedrock User Guide     Set up permissions to use guardrails for content filtering     To set up a role with permissions for guardrails, create an IAM role and attach the following permissions by following the steps at Creating a role to delegate permissions to an AWS service.     If you are using guardrails with an agent, attach the permissions to a service role with permissions to create and manage agents. You can set up this role in the console or create a custom role by following the steps at Create a service role for Amazon Bedrock Agents.     ? Permissions to invoke guardrails with foundation models     ? Permissions to create and manage guardrails     ? (Optional) Permissions to decrypt your customer-managed AWS KMS key for the guardrail     Permissions to create and manage guardrails for the policy role     Append the following statement to the Statement field in the policy for your role to use guardrails.     { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"CreateAndManageGuardrails\", \"Effect\": \"Allow\", \"Action\": [ \"bedrock:CreateGuardrail\", \"bedrock:CreateGuardrailVersion\", \"bedrock:DeleteGuardrail\", \"bedrock:GetGuardrail\", \"bedrock:ListGuardrails\", \"bedrock:UpdateGuardrail\" ], \"Resource\": \"*\" } ] }     Permissions for Amazon Bedrock Guardrails 481           https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.htmlAmazon Bedrock User Guide     Permissions you need to invoke guardrails to filter content     Append the following statement to the Statement field in the policy for the role to allow for model inference and to invoke guardrails.     { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"InvokeFoundationModel\", \"Effect\": \"Allow\", \"Action\": [ \"bedrock:InvokeModel\", \"bedrock:InvokeModelWithResponseStream\" ], \"Resource\": [ \"arn:aws:bedrock:region::foundation-model/*\" ] }, { \"Sid\": \"ApplyGuardrail\", \"Effect\": \"Allow\", \"Action\": [ \"bedrock:ApplyGuardrail\" ], \"Resource\": [ \"arn:aws:bedrock:region:account-id:guardrail/guardrail-id\" ] } ] }     (Optional) Create a customer managed key for your guardrail for additional security     Any user with CreateKey permissions can create customer managed keys using either the AWS Key Management Service (AWS KMS) console or the CreateKey operation. Make sure to create a symmetric encryption key. After you create your key, set up the following permissions.     Permissions you need to invoke guardrails to filter content 482           https://docs.aws.amazon.com/kms/latest/APIReference/API_CreateKey.htmlAmazon Bedrock User Guide     1. Follow the steps at Creating a key policy to create a resource-based policy for your KMS key. Add the following policy statements to grant permissions to guardrails users and guardrails creators. Replace each role with the role that you want to allow to carry out the specified actions.     { \"Version\": \"2012-10-17\", \"Id\": \"KMS Key Policy\", \"Statement\": [ { \"Sid\": \"PermissionsForGuardrailsCreators\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::account-id:user/role\" }, \"Action\": [ \"kms:Decrypt\", \"kms:GenerateDataKey\", \"kms:DescribeKey\", \"kms:CreateGrant\" ], \"Resource\": \"*\" }, { \"Sid\": \"PermissionsForGuardrailsUusers\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::account-id:user/role\" }, \"Action\": \"kms:Decrypt\", \"Resource\": \"*\" } }     2. Attach the following identity-based policy to a role to allow it to create and manage guardrails., API     To create a guardrail, send a CreateGuardrail request. The request format is as follows:     POST /guardrails HTTP/1.1 Content-type: application/json     { \"blockedInputMessaging\": \"string\", \"blockedOutputsMessaging\": \"string\", \"contentPolicyConfig\": { \"filtersConfig\": [ { \"inputStrength\": \"NONE | LOW | MEDIUM | HIGH\", \"outputStrength\": \"NONE | LOW | MEDIUM | HIGH\", \"type\": \"SEXUAL | VIOLENCE | HATE | INSULTS | MISCONDUCT | PROMPT_ATTACK\" } ] }, \"wordPolicyConfig\": { \"wordsConfig\": [ { \"text\": \"string\" } ],     Create a guardrail 478           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_CreateGuardrail.htmlAmazon Bedrock User Guide      \"managedWordListsConfig\": [ { \"type\": \"string\" } ] }, \"sensitiveInformationPolicyConfig\": { \"piiEntitiesConfig\": [ { \"type\": \"string\", \"action\": \"string\" } ], \"regexesConfig\": [ { \"name\": \"string\", \"description\": \"string\", \"regex\": \"string\", \"action\": \"string\" } ] }, \"description\": \"string\", \"kmsKeyId\": \"string\", \"name\": \"string\", \"tags\": [ { \"key\": \"string\", \"value\": \"string\" } ], \"topicPolicyConfig\": { \"topicsConfig\": [ { \"definition\": \"string\", \"examples\": [ \"string\" ], \"name\": \"string\", \"type\": \"DENY\" } ] } }     Create a guardrail 479Amazon Bedrock User Guide     ? Specify a name and description for the guardrail.     ? Specify messages for when the guardrail successfully blocks a prompt or a model response in the blockedInputMessaging and blockedOutputsMessaging fields.     ? Specify topics for the guardrail to deny in the topicPolicy object. Each item in the topics list pertains to one topic. For more information about the fields in a topic, see Topic.     ? Give a name and description so that the guardrail can properly identify the topic.     ? Specify DENY in the action field.     ? (Optional) Provide up to five examples that you would categorize as belonging to the topic in the examples list.     ? Specify filter strengths for the harmful categories defined in Amazon Bedrock in the contentPolicy object. Each item in the filters list pertains to a harmful category. For more information, see Block harmful words and conversations with content filters. For more information about the fields in a content filter, see ContentFilter.     ? Specify the category in the type field.     ? Specify the strength of the filter for prompts in the strength field of the textToTextFiltersForPrompt field and for model responses in the strength field of the textToTextFiltersForResponse.     ? (Optional) Attach any tags to the guardrail. For more information, see Tagging Amazon Bedrock resources.     ? (Optional) For security, include the ARN of a KMS key in the kmsKeyId field.     The response format is as follows:     HTTP/1.1 202 Content-type: application/json     { \"createdAt\": \"string\", \"guardrailArn\": \"string\", \"guardrailId\": \"string\", \"version\": \"string\" }     Create a guardrail 480           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Topic.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_ContentFilter.htmlAmazon Bedrock User Guide     Set up permissions to use guardrails for content filtering     To set up a role with permissions for guardrails, create an IAM role and attach the following permissions by following the steps at Creating a role to delegate permissions to an AWS service.     If you are using guardrails with an agent, attach the permissions to a service role with permissions to create and manage agents. You can set up this role in the console or create a custom role by following the steps at Create a service role for Amazon Bedrock Agents.     ? Permissions to invoke guardrails with foundation models     ? Permissions to create and manage guardrails     ? (Optional) Permissions to decrypt your customer-managed AWS KMS key for the guardrail     Permissions to create and manage guardrails for the policy role     Append the following statement to the Statement field in the policy for your role to use guardrails.]</td>\n",
       "      <td>In Amazon Bedrock guardrails, you can configure the following policies:<br><br>1. Content filters: You can specify filter strengths (none, low, medium, high) for harmful categories like sexual content, violence, hate speech, insults, and misconduct.<br><br>2. Word filters: You can specify lists of words or phrases to block or allow.<br><br>3. Sensitive information filters: You can specify types of personally identifiable information (PII) like names, addresses, etc. to block or mask, as well as custom regular expressions to match sensitive information.<br><br>4. Topic filters: You can specify topics to deny, including a definition, examples, and name for each topic.</td>\n",
       "      <td>You can configure the following policies in a guardrail to avoid undesirable and harmful content and remove sensitive information for privacy protection. Content filters – Adjust filter strengths to block input prompts or model responses containing harmful content.<br>Denied topics – Define a set of topics that are undesirable in the context of your application. These topics will be blocked if detected in user queries or model responses.<br>Word filters – Configure filters to block undesirable words, phrases, and profanity. Such words can include offensive terms, competitor names etc.<br>Sensitive information filters – Block or mask sensitive information such as personally identifiable information (PII) or custom regex in user inputs and model responses.<br>Contextual grounding check – Detect and filter hallucinations in model responses based on grounding in a source and relevance to the user query.</td>\n",
       "      <td>0.981290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which built in datasets are available on Amazon Bedrock for model evaluation of text generation?</td>\n",
       "      <td>[Applications that use text classification include content recommendation, spam detection, language identification and trend analysis on social media. Imbalanced classes, ambiguous data, noisy data, and bias in labeling are some issues that can cause errors in text classification.     Model evaluation task types 555           https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/         https://github.com/google-research-datasets/boolean-questions         https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/         https://github.com/google-research-datasets/boolean-questions         https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/Amazon Bedrock User Guide     Important     For text classification, there is a known system issue that prevents Cohere models from completing the toxicity evaluation successfully.     The following built-in datasets are recommended for use with the text classification task type.     Women's E-Commerce Clothing Reviews     Women's E-Commerce Clothing Reviews is a dataset that contains clothing reviews written by customers. This dataset is used in text classification tasks.     The following table summarizes the metrics calculated, and recommended built-in datasets. To successfully specify the available built-in datasets using the AWS CLI, or a supported AWSSDK use the parameter names in the column, Built-in datasets (API).     Available built-in datasets in Amazon Bedrock     Task type Metric Built-in datasets (console)     Built- in datasets (API)     Computed metric     Accuracy Women's Ecommerce Clothing Reviews     Builtin.W omensEcom merceClot hingBoolQ     Accuracy (Binary Accuracy from class ification_accuracy_score)     Text classific ation     Robustnes s     Women's Ecommerce Clothing Reviews     Builtin.W omensEcom merceClot hingBoolQ     classification_accuracy_score and delta_ classification_accuracy_score     Model evaluation task types 556           https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviewsAmazon Bedrock User Guide     To learn more about how the computed metric for each built-in dataset is calculated, see Review model evaluation job reports and metrics in Amazon Bedrock     Use prompt datasets for model evaluation in Amazon Bedrock     To create a model evaluation job you must specify a prompt dataset the model uses during inference. Amazon Bedrock provides built-in datasets that can be used in automatic model evaluations, or you can bring your own prompt dataset. For model evaluation jobs that use human workers you must use your own prompt dataset.     Use the following sections to learn more about available built-in prompt datasets and creating your custom prompt datasets.     To learn more about creating your first model evaluation job in Amazon Bedrock, see Choose the best performing model using Amazon Bedrock evaluations.     Topics     ? Use built-in prompt datasets for automatic model evaluation in Amazon Bedrock     ? Use custom prompt dataset for model evaluation in Amazon Bedrock     Use built-in prompt datasets for automatic model evaluation in Amazon Bedrock     Amazon Bedrock provides multiple built-in prompt datasets that you can use in an automatic model evaluation job. Each built-in dataset is based off an open-source dataset. We have randomly down sampled each open-source dataset to include only 100 prompts.     When you create an automatic model evaluation job and choose a Task type Amazon Bedrock provides you with a list of recommended metrics. For each metric, Amazon Bedrock also provides recommended built-in datasets. To learn more about available task types, see Model evaluation task types in Amazon Bedrock.     Bias in Open-ended Language Generation Dataset (BOLD)     The Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.     Prompt datasets for model evaluation 557Amazon Bedrock User Guide     RealToxicityPrompts     RealToxicityPrompts is a dataset that evaluates toxicity., row=3Amazon Bedrock User Guide     Task type MetricBuilt-in datasets     Computed metric     Robustnes s     Gigaword BERTScore and deltaBERTScore     BoolQ     NaturalQu estions     Accuracy     TriviaQA     NLP-F1     BoolQ     NaturalQu estions     Robustnes s     TriviaQA     F1 and deltaF1     BoolQ     NaturalQu estions     Question and answer     Toxicity     TriviaQA     Toxicity     AccuracyWomen's Ecommerce Clothing Reviews     Accuracy (Binary accuracy from classification_accuracy_s core)     Text classific ation     Robustnes s     Women's Ecommerce Clothing Reviews     classification_accuracy_score and delta_classifica tion_accuracy_score     Topics     ? General text generation for model evaluation in Amazon Bedrock     Model evaluation task types 550           https://huggingface.co/datasets/gigaword?row=3         https://github.com/google-research-datasets/boolean-questions         https://github.com/google-research-datasets/natural-questions         https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/         https://github.com/google-research-datasets/boolean-questions         https://github.com/google-research-datasets/natural-questions         https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/         https://github.com/google-research-datasets/boolean-questions         https://github.com/google-research-datasets/natural-questions         https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviewsAmazon Bedrock User Guide     ? Text summarization for model evaluation in Amazon Bedrock     ? Question and answer for model evaluation in Amazon Bedrock     ? Text classification for model evaluation in Amazon Bedrock     General text generation for model evaluation in Amazon Bedrock     General text generation is a task used by applications that include chatbots. The responses generated by a model to general questions are influenced by the correctness, relevance, and bias contained in the text used to train the model.     Important     For general text generation, there is a known system issue that prevents Cohere models from completing the toxicity evaluation successfully.     The following built-in datasets contain prompts that are well-suited for use in general text generation tasks.     Bias in Open-ended Language Generation Dataset (BOLD)     The Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.     RealToxicityPrompts     RealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.     T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)     TREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".     Model evaluation task types 551Amazon Bedrock User Guide     WikiText2     WikiText2 is a HuggingFace dataset that contains prompts used in general text generation.     The following table summarizes the metrics calculated, and recommended built-in dataset that are available for automatic model evaluation jobs., RealToxicityPrompts     RealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.     T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)     TREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".     Model evaluation task types 551Amazon Bedrock User Guide     WikiText2     WikiText2 is a HuggingFace dataset that contains prompts used in general text generation.     The following table summarizes the metrics calculated, and recommended built-in dataset that are available for automatic model evaluation jobs. To successfully specify the available built-in datasets using the AWS CLI, or a supported AWSSDK use the parameter names in the column, Built- in datasets (API).     Available built-in datasets for general text generation in Amazon Bedrock     Task type Metric Built-in datasets (Console)     Built-in datasets (API)     Computed metric     Accuracy TREX Builtin.T-REx Real world knowledge (RWK) score     BOLD Builtin.BOLD     WikiText2 Builtin.W ikiText2     Robustnes s     TREX Builtin.T-REx     Word error rate     RealToxicityPrompts Builtin.R ealToxici tyPrompts     General text generation     Toxicity     BOLD Builtin.Bold     Toxicity     To learn more about how the computed metric for each built-in dataset is calculated, see Review model evaluation job reports and metrics in Amazon Bedrock     Text summarization for model evaluation in Amazon Bedrock     Text summarization is used for tasks including creating summaries of news, legal documents, academic papers, content previews, and content curation. The ambiguity, coherence, bias, and     Model evaluation task types 552           https://hadyelsahar.github.io/t-rex/         https://github.com/amazon-science/bold         https://huggingface.co/datasets/wikitext         https://hadyelsahar.github.io/t-rex/         https://github.com/allenai/real-toxicity-prompts         https://github.com/amazon-science/boldAmazon Bedrock User Guide     fluency of the text used to train the model as well as information loss, accuracy, relevance, or context mismatch can influence the quality of responses.     Important     For text summarization, there is a known system issue that prevents Cohere models from completing the toxicity evaluation successfully.     The following built-in dataset is supported for use with the task summarization task type.     Gigaword     The Gigaword dataset consists of news article headlines. This dataset is used in text summarization tasks.     The following table summarizes the metrics calculated, and recommended built-in dataset. To successfully specify the available built-in datasets using the AWS CLI, or a supported AWSSDK use the parameter names in the column, Built-in datasets (API).     Available built-in datasets for text summarization in Amazon Bedrock     Task type Metric Built-in datasets (console)     Built-in datasets (API) Computed metric     Accuracy Gigaword Builtin.Gigaword BERTScore     Toxicity Gigaword Builtin.Gigaword Toxicity     Text summariza tion     Robustnes s     Gigaword Builtin.Gigaword BERTScore and deltaBERT Score     To learn more about how the computed metric for each built-in dataset is calculated, see Review model evaluation job reports and metrics in Amazon Bedrock     Model evaluation task types 553           https://huggingface.co/datasets/gigaword?row=3         https://huggingface.co/datasets/gigaword?row=3         https://huggingface.co/datasets/gigaword?row=3Amazon Bedrock User Guide     Question and answer for model evaluation in Amazon Bedrock     Question and answer is used for tasks including generating automatic help-desk responses, information retrieval, and e-learning. If the text used to train the foundation model contains issues including incomplete or inaccurate data, sarcasm or irony, the quality of responses can deteriorate.     Important     For question and answer, there is a known system issue that prevents Cohere models from completing the toxicity evaluation successfully.     The following built-in datasets are recommended for use with the question andg answer task type.     BoolQ     BoolQ is a dataset consisting of yes/no question and answer pairs.]</td>\n",
       "      <td>The following built-in datasets are available on Amazon Bedrock for model evaluation of text generation:<br><br>- Bias in Open-ended Language Generation Dataset (BOLD): Evaluates fairness in general text generation across domains like profession, gender, race, religious ideologies, and political ideologies.<br>- RealToxicityPrompts: Evaluates toxicity by attempting to get the model to generate racist, sexist, or otherwise toxic language.<br>- T-Rex: A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX): Consists of Knowledge Base Triples extracted from Wikipedia to evaluate real-world knowledge.<br>- WikiText2: Contains prompts used in general text generation.</td>\n",
       "      <td>The following built-in datasets contain prompts that are well-suited for use in general text generation tasks. Bias in Open-ended Language Generation Dataset (BOLD)<br>The Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.<br><br>RealToxicityPrompts<br>RealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.<br><br>T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)<br>TREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".<br><br>WikiText2<br>WikiText2 is a HuggingFace dataset that contains prompts used in general text generation.</td>\n",
       "      <td>0.958349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ragas_df_ar.style.set_properties(**{'text-align': 'left', 'border': '1px solid black'})\n",
    "ragas_df_ar.to_string(justify='left', index=False)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    pp.pprint(ragas_df_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7cbce17-792b-47da-b9a9-1053e3ae11be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a220929649493ba8cf4293c635f5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#specify the metrics here, kept one for now, we can add more.\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "metrics_ac = [\n",
    "        answer_correctness\n",
    "    ]\n",
    "\n",
    "result_ac = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=metrics_ac,\n",
    "    llm=llm_for_evaluation,\n",
    "    embeddings=bedrock_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "ragas_df_ac = result_ac.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b78fd21d-f3e4-496d-8f34-bbfda4c91687",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are all models accessible on Amazon Bedrock by default?</td>\n",
       "      <td>[The following table lists product IDs for Amazon Bedrock foundation models:     The following is the format of the IAM policy you can attach to a role to control model access permissions:     Model Product ID     AI21 Labs Jurassic-2 Mid 1d288c71-65f9-489a-a3e2-9c7f4f6e6a85     AI21 Labs Jurassic-2 Ultra cc0bdd50-279a-40d8-829c-4009b77a1fcc     AI21 Jamba-Instruct prod-dr2vpvd4k73aq     AI21 Labs Jamba 1.5 Large prod-evcp4w4lurj26     AI21 Labs Jamba 1.5 Mini prod-ggrzjm65qmjhm     Anthropic Claude c468b48a-84df-43a4-8c46-8870630108a7     Anthropic Claude Instant b0eb9475-3a2c-43d1-94d3-56756fd43737     Anthropic Claude 3 Sonnet prod-6dw3qvchef7zy     Anthropic Claude 3.5 Sonnet prod-m5ilt4siql27k     Anthropic Claude 3.5 Sonnet v2 prod-cx7ovbu5wex7g     Anthropic Claude 3 Haiku prod-ozonys2hmmpeu     Anthropic Claude 3.5 Haiku prod-5oba7y7jpji56     Anthropic Claude 3 Opus prod-fm3feywmwerog     Grant permissions to request access to foundation models 27Amazon Bedrock User Guide     Model Product ID     Cohere Command a61c46fe-1747-41aa-9af0-2e0ae8a9ce05     Cohere Command Light 216b69fd-07d5-4c7b-866b-936456d68311     Cohere Command R prod-tukx4z3hrewle     Cohere Command R+ prod-nb4wqmplze2pm     Cohere Embed (English) b7568428-a1ab-46d8-bab3-37def50f6f6a     Cohere Embed (Multilingual) 38e55671-c3fe-4a44-9783-3584906e7cad     Stable Diffusion XL 1.0 prod-2lvuzn4iy6n6o     Stable Image Core 1.0 prod-eacdrmv7zfc5e     Stable Diffusion 3 Large 1.0 prod-cqfmszl26sxu4     Stable Image Ultra 1.0 prod-7boen2z2wnxrg     { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow|Deny\", \"Action\": [ \"aws-marketplace:Subscribe\" ], \"Resource\": \"*\", \"Condition\": { \"ForAnyValue:StringEquals\": { \"aws-marketplace:ProductId\": [ model-product-id-1, model-product-id-2, ... ] } } },     Grant permissions to request access to foundation models 28Amazon Bedrock User Guide      { \"Effect\": \"Allow|Deny\", \"Action\": [ \"aws-marketplace:Unsubscribe\" \"aws-marketplace:ViewSubscriptions\" ], \"Resource\": \"*\" } ] }     To see an example policy, refer to Allow access to third-party model subscriptions.     Add or remove access to Amazon Bedrock foundation models     Before you can use a foundation model in Amazon Bedrock, you must request access to it. If you no longer need access to a model, you can remove access from it.     Note     You can't remove request access from the Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models. You can prevent users from making inference calls to these models by using an IAM policy and specifying the model ID. For more information, see Deny access for inference on specific models.     Once access is provided to a model, it is available for all users in the AWS account.     To add or remove access to foundation models     1. Make sure you have permissions to request access, or modify access, to Amazon Bedrock foundation models.     2. Sign into the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.     3. In the left navigation pane, under Bedrock configurations, choose Model access.     4. On the Model access page, choose Modify model access.     5. Select the models that you want the account to have access to and unselect the models that you don't want the account to have access to.]</td>\n",
       "      <td>No, not all models are accessible on Amazon Bedrock by default. Before you can use a foundation model in Amazon Bedrock, you must request access to it. The documentation states: \"Before you can use a foundation model in Amazon Bedrock, you must request access to it. If you no longer need access to a model, you can remove access from it.\" However, the documentation also notes that you cannot remove access from certain models like Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models. For these models, you can prevent users from making inference calls by using an IAM policy and specifying the model ID.</td>\n",
       "      <td>Access to Amazon Bedrock foundation models isn't granted by default. You can request access, or modify access, to foundation models only by using the Amazon Bedrock console. First, make sure the IAM role that you use has sufficent IAM permissions to manage access to foundation models. Then, add or remove access to a model by following the instructions at Add or remove access to Amazon Bedrock foundation models.</td>\n",
       "      <td>0.551098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Model ID of Amazon Titan Text Premier</td>\n",
       "      <td>[Separate keys with a space.     aws bedrock-agent untag-resource \\ --resource-arn \"arn:aws:bedrock:us-east-1:123456789012:agent/AGENT12345\" \\ --tag-keys key=department facing     List the tags for the agent.     aws bedrock-agent list-tags-for-resource \\ --resource-arn \"arn:aws:bedrock:us-east-1:123456789012:agent/AGENT12345\"     Python (Boto)     Add two tags to an agent.     import boto3     bedrock = boto3.client(service_name='bedrock-agent')     tags = [ { 'key': 'department', 'value': 'billing' }, {     Use the API 1417           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_TagResource.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_TagResource.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_UntagResource.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_UntagResource.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_ListTagsForResource.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_ListTagsForResource.htmlAmazon Bedrock User Guide      'key': 'facing', 'value': 'internal' } ]     bedrock.tag_resource(resourceArn='arn:aws:bedrock:us-east-1:123456789012:agent/ AGENT12345', tags=tags)     Remove the tags from the agent.     bedrock.untag_resource( resourceArn='arn:aws:bedrock:us-east-1:123456789012:agent/AGENT12345', tagKeys=['department', 'facing'] )     List the tags for the agent.     bedrock.list_tags_for_resource(resourceArn='arn:aws:bedrock:us- east-1:123456789012:agent/AGENT12345')     Use the API 1418Amazon Bedrock User Guide     Overview of Amazon Titan models     Amazon Titan foundation models (FMs) are a family of FMs pretrained by AWS on large datasets, making them powerful, general-purpose models built to support a variety of use cases. Use them as-is or privately customize them with your own data.     Amazon Titan supports the following models for Amazon Bedrock.     ? Amazon Titan Text     ? Amazon Titan Text Embeddings V2     ? Amazon Titan Multimodal Embeddings G1     ? Amazon Titan Image Generator G1 V1     Topics     ? Amazon Titan Text models     ? Amazon Titan Text Embeddings models     ? Amazon Titan Multimodal Embeddings G1 model     ? Amazon Titan Image Generator G1 models     Amazon Titan Text models     Amazon Titan text models include Amazon Titan Text G1 - Premier, Amazon Titan Text G1 - Express and Amazon Titan Text G1 - Lite.     Amazon Titan Text G1 - Premier     Amazon Titan Text G1 - Premier is a large language model for text generation. It is useful for a wide range of tasks including open-ended and context-based question answering, code generation, and summarization. This model is integrated with Amazon Bedrock Knowledge Base and Amazon Bedrock Agents. The model also supports Custom Finetuning in preview.     ? Model ID ? amazon.titan-text-premier-v1:0     ? Max tokens ? 32K     ? Languages ? English     Amazon Titan Text 1419Amazon Bedrock User Guide     ? Supported use cases ? 32k context window, open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, chat, Knowledge Base support, Agents support, Model Customization (preview).     ? Inference parameters ? Temperature, Top P (defaults: Temperature = 0.7, Top P = 0.9)     AWS AI Service Card - Amazon Titan Text Premier     Amazon Titan Text G1 - Express     Amazon Titan Text G1 - Express is a large language model for text generation. It is useful for a wide range of advanced, general language tasks such as open-ended text generation and conversational chat, as well as support within Retrieval Augmented Generation (RAG). At launch, the model is optimized for English, with multilingual support for more than 30 additional languages available in preview.     ? Model ID ? amazon.titan-text-express-v1     ? Max tokens ? 8K     ? Languages ? English (GA), 100 additional languages (Preview)     ? Supported use cases ? Retrieval augmented generation, open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, and chat., Model ID ? amazon.titan-text-premier-v1:0     ? Max tokens ? 32K     ? Languages ? English     Amazon Titan Text 1419Amazon Bedrock User Guide     ? Supported use cases ? 32k context window, open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, chat, Knowledge Base support, Agents support, Model Customization (preview).     ? Inference parameters ? Temperature, Top P (defaults: Temperature = 0.7, Top P = 0.9)     AWS AI Service Card - Amazon Titan Text Premier     Amazon Titan Text G1 - Express     Amazon Titan Text G1 - Express is a large language model for text generation. It is useful for a wide range of advanced, general language tasks such as open-ended text generation and conversational chat, as well as support within Retrieval Augmented Generation (RAG). At launch, the model is optimized for English, with multilingual support for more than 30 additional languages available in preview.     ? Model ID ? amazon.titan-text-express-v1     ? Max tokens ? 8K     ? Languages ? English (GA), 100 additional languages (Preview)     ? Supported use cases ? Retrieval augmented generation, open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, and chat.     Amazon Titan Text G1 - Lite     Amazon Titan Text G1 - Lite is a light weight efficient model, ideal for fine-tuning of English- language tasks, including like summarizations and copy writing, where customers want a smaller, more cost-effective model that is also highly customizable.     ? Model ID ? amazon.titan-text-lite-v1     ? Max tokens ? 4K     ? Languages ? English     ? Supported use cases ? Open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, and chat.     Amazon Titan Text G1 - Express 1420           https://aws.amazon.com/machine-learning/responsible-machine-learning/titan-text-premier/Amazon Bedrock User Guide     Amazon Titan Text Model Customization     For more information on customizing Amazon Titan text models, see the following pages.     ? Prepare the datasets     ? Amazon Titan text model customization hyperparameters     Amazon Titan Text Prompt Engineering Guidelines     Amazon Titan text models can be used in a wide variety of applications for different use cases. Amazon Titan Text models have prompt engineering guidelines for the following applications including:     ? Chatbot     ? Text2SQL     ? Function Calling     ? RAG (Retrieval Augmented Generation)     For more information on Amazon Titan Text prompt engineering guidelines, see Amazon Titan Text Prompt Engineering Guidelines.     For general prompt engineering guidelines, see Prompt Engineering Guidelines.     AWS AI Service Card - Amazon Titan Text     AI Service Cards provide transparency and document the intended use cases and fairness considerations for our AWS AI services. AI Service Cards provide a single place to find information on the intended use cases, responsible AI design choices, best practices, and performance for a set of AI service use cases.     Amazon Titan Text Embeddings models     Amazon Titan Embeddings text models include Amazon Titan Text Embeddings v2 and Titan Text Embeddings G1 model.     Text embeddings represent meaningful vector representations of unstructured text such as documents, paragraphs, and sentences. You input a body of text and the output is a (1 x n) vector. You can use embedding vectors for a wide variety of applications.     Amazon Titan Text Model Customization 1421           https://d2eo22ngex1n9g.cloudfront.net/Documentation/User+Guides/Titan/Amazon+Titan+Text+Prompt+Engineering+Guidelines.pdf         https://d2eo22ngex1n9g.cloudfront.net/Documentation/User+Guides/Titan/Amazon+Titan+Text+Prompt+Engineering+Guidelines.pdf         https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-engineering-guidelines.html         https://aws.amazon.com/machine-learning/responsible-machine-learning/titan-text/Amazon Bedrock User Guide     The Amazon Titan Text Embedding v2 model (amazon.titan-embed-text-v2:0) can intake up to 8,192 tokens and outputs a vector of 1,024 dimensions. The model also works in 100+ different languages. The model is optimized for text retrieval tasks, but can also perform additional tasks, such as semantic similarity and clustering. Amazon Titan Embeddings text v2 also supports long documents, however, for retrieval tasks it is recommended to segment documents into logical segments , such as paragraphs or sections.     Amazon Titan Embeddings models generate meaningful semantic representation of documents, paragraphs and sentences.]</td>\n",
       "      <td>The Model ID of Amazon Titan Text Premier is amazon.titan-text-premier-v1:0.</td>\n",
       "      <td>amazon.titan-text-premier-v1:0</td>\n",
       "      <td>0.164179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With which Anthropic Claude models can I use the Text Completions API?</td>\n",
       "      <td>[Anthropic Claude 3 model, such as Anthropic Claude 3 Opus     For information about creating system prompts, see https://docs.anthropic.com/claude/ docs/how-to-use-system-prompts in the Anthropic Claude documentation. To avoid timeouts with Anthropic Claude version 2.1, we recommend limiting the input token count in the prompt field to 180K. We expect to address this timeout issue soon.     In the inference call, fill the body field with a JSON object that conforms the type call you want to make, Anthropic Claude Text Completions API or Anthropic Claude Messages API.     Topics     ? Anthropic Claude Text Completions API     ? Anthropic Claude Messages API     Anthropic Claude models 147           https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview         https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags         https://docs.anthropic.com/en/docs/welcome         https://docs.anthropic.com/claude/docs/how-to-use-system-prompts         https://docs.anthropic.com/claude/docs/how-to-use-system-promptsAmazon Bedrock User Guide     Anthropic Claude Text Completions API     This section provides inference parameters and code examples for using Anthropic Claude models with the Text Completions API.     Topics     ? Anthropic Claude Text Completions API overview     ? Supported models     ? Request and Response     ? Code example     Anthropic Claude Text Completions API overview     Use the Text Completion API for single-turn text generation from a user supplied prompt. For example, you can use the Text Completion API to generate text for a blog post or to summarize text input from a user.     For information about creating prompts for Anthropic Claude models, see Introduction to prompt design. If you want to use your existing Text Completions prompts with the Anthropic Claude Messages API, see Migrating from Text Completions.     Supported models     You can use the Text Completions API with the following Anthropic Claude models.     ? Anthropic Claude Instant v1.2     ? Anthropic Claude v2     ? Anthropic Claude v2.1     Request and Response     The request body is passed in the body field of a request to InvokeModel or InvokeModelWithResponseStream.     For more information, see https://docs.anthropic.com/claude/reference/complete_post in the Anthropic Claude documentation.     Anthropic Claude models 148           https://docs.anthropic.com/claude/docs/introduction-to-prompt-design         https://docs.anthropic.com/claude/docs/introduction-to-prompt-design         https://docs.anthropic.com/claude/reference/migrating-from-text-completions-to-messages         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html         https://docs.anthropic.com/claude/reference/complete_postAmazon Bedrock User Guide     Request     Anthropic Claude has the following inference parameters for a Text Completion inference call.     { \"prompt\": \"<br><br>Human:&lt;prompt&gt;<br><br>Assistant:\", \"temperature\": float, \"top_p\": float, \"top_k\": int, \"max_tokens_to_sample\": int, \"stop_sequences\": [string] }     The following are required parameters.     ? prompt ? (Required) The prompt that you want Claude to complete. For proper response generation you need to format your prompt using alternating <br><br>Human: and <br> <br>Assistant: conversational turns. For example:     \"<br><br>Human: {userQuestion}<br><br>Assistant:\"     For more information, see Prompt validation in the Anthropic Claude documentation.     ? max_tokens_to_sample ? (Required) The maximum number of tokens to generate before stopping. We recommend a limit of 4,000 tokens for optimal performance.     Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens_to_sample. Different Anthropic Claude models have different maximum values for this parameter. For more information, see Model comparison in the Anthropic Claude documentation.     Default Minimum Maximum     200 0 4096     The following are optional parameters.     ? stop_sequences ? (Optional) Sequences that will cause the model to stop generating.     Anthropic Claude models 149           https://docs.anthropic.com/claude/reference/prompt-validation         https://docs.anthropic.com/claude/docs/models-overview#model-comparisonAmazon Bedrock User Guide     Anthropic Claude models stop on \"<br><br>Human:\", and may include additional built-in stop sequences in the future. Use the stop_sequences inference parameter to include additional strings that will signal the model to stop generating text.     ? temperature ?]</td>\n",
       "      <td>You can use the Text Completions API with the following Anthropic Claude models:<br>- Anthropic Claude Instant v1.2<br>- Anthropic Claude v2<br>- Anthropic Claude v2.1</td>\n",
       "      <td>Anthropic Claude Instant v1.2, Anthropic Claude v2, Anthropic Claude v2.1</td>\n",
       "      <td>0.887015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What policies can I configure in Amazon Bedrock guardrails?</td>\n",
       "      <td>[For more information about the fields in a content filter, see ContentFilter.     ? Specify the category in the type field.     ? Specify the strength of the filter for prompts in the strength field of the textToTextFiltersForPrompt field and for model responses in the strength field of the textToTextFiltersForResponse.     ? (Optional) Attach any tags to the guardrail. For more information, see Tagging Amazon Bedrock resources.     ? (Optional) For security, include the ARN of a KMS key in the kmsKeyId field.     The response format is as follows:     HTTP/1.1 202 Content-type: application/json     { \"createdAt\": \"string\", \"guardrailArn\": \"string\", \"guardrailId\": \"string\", \"version\": \"string\" }     Create a guardrail 480           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Topic.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_ContentFilter.htmlAmazon Bedrock User Guide     Set up permissions to use guardrails for content filtering     To set up a role with permissions for guardrails, create an IAM role and attach the following permissions by following the steps at Creating a role to delegate permissions to an AWS service.     If you are using guardrails with an agent, attach the permissions to a service role with permissions to create and manage agents. You can set up this role in the console or create a custom role by following the steps at Create a service role for Amazon Bedrock Agents.     ? Permissions to invoke guardrails with foundation models     ? Permissions to create and manage guardrails     ? (Optional) Permissions to decrypt your customer-managed AWS KMS key for the guardrail     Permissions to create and manage guardrails for the policy role     Append the following statement to the Statement field in the policy for your role to use guardrails.     { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"CreateAndManageGuardrails\", \"Effect\": \"Allow\", \"Action\": [ \"bedrock:CreateGuardrail\", \"bedrock:CreateGuardrailVersion\", \"bedrock:DeleteGuardrail\", \"bedrock:GetGuardrail\", \"bedrock:ListGuardrails\", \"bedrock:UpdateGuardrail\" ], \"Resource\": \"*\" } ] }     Permissions for Amazon Bedrock Guardrails 481           https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.htmlAmazon Bedrock User Guide     Permissions you need to invoke guardrails to filter content     Append the following statement to the Statement field in the policy for the role to allow for model inference and to invoke guardrails.     { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"InvokeFoundationModel\", \"Effect\": \"Allow\", \"Action\": [ \"bedrock:InvokeModel\", \"bedrock:InvokeModelWithResponseStream\" ], \"Resource\": [ \"arn:aws:bedrock:region::foundation-model/*\" ] }, { \"Sid\": \"ApplyGuardrail\", \"Effect\": \"Allow\", \"Action\": [ \"bedrock:ApplyGuardrail\" ], \"Resource\": [ \"arn:aws:bedrock:region:account-id:guardrail/guardrail-id\" ] } ] }     (Optional) Create a customer managed key for your guardrail for additional security     Any user with CreateKey permissions can create customer managed keys using either the AWS Key Management Service (AWS KMS) console or the CreateKey operation. Make sure to create a symmetric encryption key. After you create your key, set up the following permissions.     Permissions you need to invoke guardrails to filter content 482           https://docs.aws.amazon.com/kms/latest/APIReference/API_CreateKey.htmlAmazon Bedrock User Guide     1. Follow the steps at Creating a key policy to create a resource-based policy for your KMS key. Add the following policy statements to grant permissions to guardrails users and guardrails creators. Replace each role with the role that you want to allow to carry out the specified actions.     { \"Version\": \"2012-10-17\", \"Id\": \"KMS Key Policy\", \"Statement\": [ { \"Sid\": \"PermissionsForGuardrailsCreators\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::account-id:user/role\" }, \"Action\": [ \"kms:Decrypt\", \"kms:GenerateDataKey\", \"kms:DescribeKey\", \"kms:CreateGrant\" ], \"Resource\": \"*\" }, { \"Sid\": \"PermissionsForGuardrailsUusers\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::account-id:user/role\" }, \"Action\": \"kms:Decrypt\", \"Resource\": \"*\" } }     2. Attach the following identity-based policy to a role to allow it to create and manage guardrails., API     To create a guardrail, send a CreateGuardrail request. The request format is as follows:     POST /guardrails HTTP/1.1 Content-type: application/json     { \"blockedInputMessaging\": \"string\", \"blockedOutputsMessaging\": \"string\", \"contentPolicyConfig\": { \"filtersConfig\": [ { \"inputStrength\": \"NONE | LOW | MEDIUM | HIGH\", \"outputStrength\": \"NONE | LOW | MEDIUM | HIGH\", \"type\": \"SEXUAL | VIOLENCE | HATE | INSULTS | MISCONDUCT | PROMPT_ATTACK\" } ] }, \"wordPolicyConfig\": { \"wordsConfig\": [ { \"text\": \"string\" } ],     Create a guardrail 478           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_CreateGuardrail.htmlAmazon Bedrock User Guide      \"managedWordListsConfig\": [ { \"type\": \"string\" } ] }, \"sensitiveInformationPolicyConfig\": { \"piiEntitiesConfig\": [ { \"type\": \"string\", \"action\": \"string\" } ], \"regexesConfig\": [ { \"name\": \"string\", \"description\": \"string\", \"regex\": \"string\", \"action\": \"string\" } ] }, \"description\": \"string\", \"kmsKeyId\": \"string\", \"name\": \"string\", \"tags\": [ { \"key\": \"string\", \"value\": \"string\" } ], \"topicPolicyConfig\": { \"topicsConfig\": [ { \"definition\": \"string\", \"examples\": [ \"string\" ], \"name\": \"string\", \"type\": \"DENY\" } ] } }     Create a guardrail 479Amazon Bedrock User Guide     ? Specify a name and description for the guardrail.     ? Specify messages for when the guardrail successfully blocks a prompt or a model response in the blockedInputMessaging and blockedOutputsMessaging fields.     ? Specify topics for the guardrail to deny in the topicPolicy object. Each item in the topics list pertains to one topic. For more information about the fields in a topic, see Topic.     ? Give a name and description so that the guardrail can properly identify the topic.     ? Specify DENY in the action field.     ? (Optional) Provide up to five examples that you would categorize as belonging to the topic in the examples list.     ? Specify filter strengths for the harmful categories defined in Amazon Bedrock in the contentPolicy object. Each item in the filters list pertains to a harmful category. For more information, see Block harmful words and conversations with content filters. For more information about the fields in a content filter, see ContentFilter.     ? Specify the category in the type field.     ? Specify the strength of the filter for prompts in the strength field of the textToTextFiltersForPrompt field and for model responses in the strength field of the textToTextFiltersForResponse.     ? (Optional) Attach any tags to the guardrail. For more information, see Tagging Amazon Bedrock resources.     ? (Optional) For security, include the ARN of a KMS key in the kmsKeyId field.     The response format is as follows:     HTTP/1.1 202 Content-type: application/json     { \"createdAt\": \"string\", \"guardrailArn\": \"string\", \"guardrailId\": \"string\", \"version\": \"string\" }     Create a guardrail 480           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Topic.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_ContentFilter.htmlAmazon Bedrock User Guide     Set up permissions to use guardrails for content filtering     To set up a role with permissions for guardrails, create an IAM role and attach the following permissions by following the steps at Creating a role to delegate permissions to an AWS service.     If you are using guardrails with an agent, attach the permissions to a service role with permissions to create and manage agents. You can set up this role in the console or create a custom role by following the steps at Create a service role for Amazon Bedrock Agents.     ? Permissions to invoke guardrails with foundation models     ? Permissions to create and manage guardrails     ? (Optional) Permissions to decrypt your customer-managed AWS KMS key for the guardrail     Permissions to create and manage guardrails for the policy role     Append the following statement to the Statement field in the policy for your role to use guardrails.]</td>\n",
       "      <td>In Amazon Bedrock guardrails, you can configure the following policies:<br><br>1. Content filters: You can specify filter strengths (none, low, medium, high) for harmful categories like sexual content, violence, hate speech, insults, and misconduct.<br><br>2. Word filters: You can specify lists of words or phrases to block or allow.<br><br>3. Sensitive information filters: You can specify types of personally identifiable information (PII) like names, addresses, etc. to block or mask, as well as custom regular expressions to match sensitive information.<br><br>4. Topic filters: You can specify topics to deny, including a definition, examples, and name for each topic.</td>\n",
       "      <td>You can configure the following policies in a guardrail to avoid undesirable and harmful content and remove sensitive information for privacy protection. Content filters – Adjust filter strengths to block input prompts or model responses containing harmful content.<br>Denied topics – Define a set of topics that are undesirable in the context of your application. These topics will be blocked if detected in user queries or model responses.<br>Word filters – Configure filters to block undesirable words, phrases, and profanity. Such words can include offensive terms, competitor names etc.<br>Sensitive information filters – Block or mask sensitive information such as personally identifiable information (PII) or custom regex in user inputs and model responses.<br>Contextual grounding check – Detect and filter hallucinations in model responses based on grounding in a source and relevance to the user query.</td>\n",
       "      <td>0.810356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which built in datasets are available on Amazon Bedrock for model evaluation of text generation?</td>\n",
       "      <td>[Applications that use text classification include content recommendation, spam detection, language identification and trend analysis on social media. Imbalanced classes, ambiguous data, noisy data, and bias in labeling are some issues that can cause errors in text classification.     Model evaluation task types 555           https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/         https://github.com/google-research-datasets/boolean-questions         https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/         https://github.com/google-research-datasets/boolean-questions         https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/Amazon Bedrock User Guide     Important     For text classification, there is a known system issue that prevents Cohere models from completing the toxicity evaluation successfully.     The following built-in datasets are recommended for use with the text classification task type.     Women's E-Commerce Clothing Reviews     Women's E-Commerce Clothing Reviews is a dataset that contains clothing reviews written by customers. This dataset is used in text classification tasks.     The following table summarizes the metrics calculated, and recommended built-in datasets. To successfully specify the available built-in datasets using the AWS CLI, or a supported AWSSDK use the parameter names in the column, Built-in datasets (API).     Available built-in datasets in Amazon Bedrock     Task type Metric Built-in datasets (console)     Built- in datasets (API)     Computed metric     Accuracy Women's Ecommerce Clothing Reviews     Builtin.W omensEcom merceClot hingBoolQ     Accuracy (Binary Accuracy from class ification_accuracy_score)     Text classific ation     Robustnes s     Women's Ecommerce Clothing Reviews     Builtin.W omensEcom merceClot hingBoolQ     classification_accuracy_score and delta_ classification_accuracy_score     Model evaluation task types 556           https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviewsAmazon Bedrock User Guide     To learn more about how the computed metric for each built-in dataset is calculated, see Review model evaluation job reports and metrics in Amazon Bedrock     Use prompt datasets for model evaluation in Amazon Bedrock     To create a model evaluation job you must specify a prompt dataset the model uses during inference. Amazon Bedrock provides built-in datasets that can be used in automatic model evaluations, or you can bring your own prompt dataset. For model evaluation jobs that use human workers you must use your own prompt dataset.     Use the following sections to learn more about available built-in prompt datasets and creating your custom prompt datasets.     To learn more about creating your first model evaluation job in Amazon Bedrock, see Choose the best performing model using Amazon Bedrock evaluations.     Topics     ? Use built-in prompt datasets for automatic model evaluation in Amazon Bedrock     ? Use custom prompt dataset for model evaluation in Amazon Bedrock     Use built-in prompt datasets for automatic model evaluation in Amazon Bedrock     Amazon Bedrock provides multiple built-in prompt datasets that you can use in an automatic model evaluation job. Each built-in dataset is based off an open-source dataset. We have randomly down sampled each open-source dataset to include only 100 prompts.     When you create an automatic model evaluation job and choose a Task type Amazon Bedrock provides you with a list of recommended metrics. For each metric, Amazon Bedrock also provides recommended built-in datasets. To learn more about available task types, see Model evaluation task types in Amazon Bedrock.     Bias in Open-ended Language Generation Dataset (BOLD)     The Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.     Prompt datasets for model evaluation 557Amazon Bedrock User Guide     RealToxicityPrompts     RealToxicityPrompts is a dataset that evaluates toxicity., row=3Amazon Bedrock User Guide     Task type MetricBuilt-in datasets     Computed metric     Robustnes s     Gigaword BERTScore and deltaBERTScore     BoolQ     NaturalQu estions     Accuracy     TriviaQA     NLP-F1     BoolQ     NaturalQu estions     Robustnes s     TriviaQA     F1 and deltaF1     BoolQ     NaturalQu estions     Question and answer     Toxicity     TriviaQA     Toxicity     AccuracyWomen's Ecommerce Clothing Reviews     Accuracy (Binary accuracy from classification_accuracy_s core)     Text classific ation     Robustnes s     Women's Ecommerce Clothing Reviews     classification_accuracy_score and delta_classifica tion_accuracy_score     Topics     ? General text generation for model evaluation in Amazon Bedrock     Model evaluation task types 550           https://huggingface.co/datasets/gigaword?row=3         https://github.com/google-research-datasets/boolean-questions         https://github.com/google-research-datasets/natural-questions         https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/         https://github.com/google-research-datasets/boolean-questions         https://github.com/google-research-datasets/natural-questions         https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/         https://github.com/google-research-datasets/boolean-questions         https://github.com/google-research-datasets/natural-questions         https://github.com/google-research-datasets/natural-questions         https://nlp.cs.washington.edu/triviaqa/         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews         https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviewsAmazon Bedrock User Guide     ? Text summarization for model evaluation in Amazon Bedrock     ? Question and answer for model evaluation in Amazon Bedrock     ? Text classification for model evaluation in Amazon Bedrock     General text generation for model evaluation in Amazon Bedrock     General text generation is a task used by applications that include chatbots. The responses generated by a model to general questions are influenced by the correctness, relevance, and bias contained in the text used to train the model.     Important     For general text generation, there is a known system issue that prevents Cohere models from completing the toxicity evaluation successfully.     The following built-in datasets contain prompts that are well-suited for use in general text generation tasks.     Bias in Open-ended Language Generation Dataset (BOLD)     The Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.     RealToxicityPrompts     RealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.     T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)     TREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".     Model evaluation task types 551Amazon Bedrock User Guide     WikiText2     WikiText2 is a HuggingFace dataset that contains prompts used in general text generation.     The following table summarizes the metrics calculated, and recommended built-in dataset that are available for automatic model evaluation jobs., RealToxicityPrompts     RealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.     T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)     TREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".     Model evaluation task types 551Amazon Bedrock User Guide     WikiText2     WikiText2 is a HuggingFace dataset that contains prompts used in general text generation.     The following table summarizes the metrics calculated, and recommended built-in dataset that are available for automatic model evaluation jobs. To successfully specify the available built-in datasets using the AWS CLI, or a supported AWSSDK use the parameter names in the column, Built- in datasets (API).     Available built-in datasets for general text generation in Amazon Bedrock     Task type Metric Built-in datasets (Console)     Built-in datasets (API)     Computed metric     Accuracy TREX Builtin.T-REx Real world knowledge (RWK) score     BOLD Builtin.BOLD     WikiText2 Builtin.W ikiText2     Robustnes s     TREX Builtin.T-REx     Word error rate     RealToxicityPrompts Builtin.R ealToxici tyPrompts     General text generation     Toxicity     BOLD Builtin.Bold     Toxicity     To learn more about how the computed metric for each built-in dataset is calculated, see Review model evaluation job reports and metrics in Amazon Bedrock     Text summarization for model evaluation in Amazon Bedrock     Text summarization is used for tasks including creating summaries of news, legal documents, academic papers, content previews, and content curation. The ambiguity, coherence, bias, and     Model evaluation task types 552           https://hadyelsahar.github.io/t-rex/         https://github.com/amazon-science/bold         https://huggingface.co/datasets/wikitext         https://hadyelsahar.github.io/t-rex/         https://github.com/allenai/real-toxicity-prompts         https://github.com/amazon-science/boldAmazon Bedrock User Guide     fluency of the text used to train the model as well as information loss, accuracy, relevance, or context mismatch can influence the quality of responses.     Important     For text summarization, there is a known system issue that prevents Cohere models from completing the toxicity evaluation successfully.     The following built-in dataset is supported for use with the task summarization task type.     Gigaword     The Gigaword dataset consists of news article headlines. This dataset is used in text summarization tasks.     The following table summarizes the metrics calculated, and recommended built-in dataset. To successfully specify the available built-in datasets using the AWS CLI, or a supported AWSSDK use the parameter names in the column, Built-in datasets (API).     Available built-in datasets for text summarization in Amazon Bedrock     Task type Metric Built-in datasets (console)     Built-in datasets (API) Computed metric     Accuracy Gigaword Builtin.Gigaword BERTScore     Toxicity Gigaword Builtin.Gigaword Toxicity     Text summariza tion     Robustnes s     Gigaword Builtin.Gigaword BERTScore and deltaBERT Score     To learn more about how the computed metric for each built-in dataset is calculated, see Review model evaluation job reports and metrics in Amazon Bedrock     Model evaluation task types 553           https://huggingface.co/datasets/gigaword?row=3         https://huggingface.co/datasets/gigaword?row=3         https://huggingface.co/datasets/gigaword?row=3Amazon Bedrock User Guide     Question and answer for model evaluation in Amazon Bedrock     Question and answer is used for tasks including generating automatic help-desk responses, information retrieval, and e-learning. If the text used to train the foundation model contains issues including incomplete or inaccurate data, sarcasm or irony, the quality of responses can deteriorate.     Important     For question and answer, there is a known system issue that prevents Cohere models from completing the toxicity evaluation successfully.     The following built-in datasets are recommended for use with the question andg answer task type.     BoolQ     BoolQ is a dataset consisting of yes/no question and answer pairs.]</td>\n",
       "      <td>The following built-in datasets are available on Amazon Bedrock for model evaluation of text generation:<br><br>- Bias in Open-ended Language Generation Dataset (BOLD): Evaluates fairness in general text generation across domains like profession, gender, race, religious ideologies, and political ideologies.<br>- RealToxicityPrompts: Evaluates toxicity by attempting to get the model to generate racist, sexist, or otherwise toxic language.<br>- T-Rex: A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX): Consists of Knowledge Base Triples extracted from Wikipedia to evaluate real-world knowledge.<br>- WikiText2: Contains prompts used in general text generation.</td>\n",
       "      <td>The following built-in datasets contain prompts that are well-suited for use in general text generation tasks. Bias in Open-ended Language Generation Dataset (BOLD)<br>The Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.<br><br>RealToxicityPrompts<br>RealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.<br><br>T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)<br>TREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".<br><br>WikiText2<br>WikiText2 is a HuggingFace dataset that contains prompts used in general text generation.</td>\n",
       "      <td>0.538792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ragas_df_ac.style.set_properties(**{'text-align': 'left', 'border': '1px solid black'})\n",
    "ragas_df_ac.to_string(justify='left', index=False)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    pp.pprint(ragas_df_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb223107-9e30-4449-9745-a7a21e0b549c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Access to Amazon Bedrock foundation models isn't granted by default. You can request access, or modify access, to foundation models only by using the Amazon Bedrock console. First, make sure the IAM role that you use has\\xa0sufficent IAM permissions\\xa0to manage access to foundation models. Then, add or remove access to a model by following the instructions at\\xa0Add or remove access to Amazon Bedrock foundation models.\",\n",
       " 'amazon.titan-text-premier-v1:0',\n",
       " 'Anthropic Claude Instant v1.2, Anthropic Claude v2, Anthropic Claude v2.1',\n",
       " 'You can configure the following policies in a guardrail to avoid undesirable and harmful content and remove sensitive information for privacy protection. Content filters\\xa0– Adjust filter strengths to block input prompts or model responses containing harmful content.\\nDenied topics\\xa0– Define a set of topics that are undesirable in the context of your application. These topics will be blocked if detected in user queries or model responses.\\nWord filters\\xa0– Configure filters to block undesirable words, phrases, and profanity. Such words can include offensive terms, competitor names etc.\\nSensitive information filters\\xa0– Block or mask sensitive information such as personally identifiable information (PII) or custom regex in user inputs and model responses.\\nContextual grounding check\\xa0– Detect and filter hallucinations in model responses based on grounding in a source and relevance to the user query.',\n",
       " 'The following built-in datasets contain prompts that are well-suited for use in general text generation tasks. Bias in Open-ended Language Generation Dataset (BOLD)\\nThe Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.\\n\\nRealToxicityPrompts\\nRealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.\\n\\nT-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)\\nTREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".\\n\\nWikiText2\\nWikiText2 is a HuggingFace dataset that contains prompts used in general text generation.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb27ab",
   "metadata": {},
   "source": [
    "### <a >Challenge Exercise :: Try it Yourself! </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c62acdc",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto;\">\n",
    "    <br>\n",
    "    <p style=\"text-align: center; margin: auto;\"><b>Try the following exercises on this lab and note the observations.</b></p>\n",
    "<p style=\" text-align: left; margin: auto;\">\n",
    "<ol>\n",
    "    <li>Test the RAG based LLM with more questions about Amazon Bedrock. </li>\n",
    "<li>Look the the citations or retrieved references and see if the answer generated by the RAG chatbot aligns with these retrieved contexts. What response do you get when the retrieved context comes up empty? </li>\n",
    "<li>Apply system prompts to RAG as well as amazon Bedrock Guardrails and test which is more consistent in blocking responses when the model response is hallucinated </li>\n",
    "<li>Run the tutorial for RAG Checker and compare the difference with RAGAS evaluation framework: https://github.com/amazon-science/RAGChecker/blob/main/tutorial/ragchecker_tutorial_en.md </li>\n",
    "</ol>\n",
    "<br>\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc89ac-b0e8-438a-bba2-12bc3a4a3f94",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We now have an understanding of parameters which influence hallucinations in Large Language Models. We learnt how to set up Retrieval Augmented Generation to provide a context to the model while answering.\n",
    "We used Contextual grounding in Amazon Bedrock Guardrials to intervene when hallucinations are detected.\n",
    "Finally we looked into the metrics of RAGAS and how to use them to measure hallucinations in your RAG powered chatbot.\n",
    "\n",
    "In the next lab, we will:\n",
    "1. Build a custom hallucination detector\n",
    "2. Use Amazon Bedrock Agents to intervene when hallucinations are detected\n",
    "3. Call a human for support when the LLM hallucinates\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
