{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc84eb37-3b34-4506-8ebc-c70f28166077",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center><img src=\"images/2024_reInvent_Logo_wDate_Black_V3.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# <a name=\"0\">re:Invent 2024 | Lab 1: Build your RAG powered chatbot  </a>\n",
    "## <a name=\"0\">Build a chatbot with Knowledge Bases and Guardrails to detect and remediate hallucinations </a>\n",
    "\n",
    "## Lab Overview\n",
    "In this lab, you will:\n",
    "1. Take a deeper look at which LLM parameters influence or control for model hallucinations\n",
    "2. Set up Retrieval Augmented Generation and understand how it can control for hallucinations\n",
    "3. Apply contextual grounding in Amazon Bedrock Guardrails to intervene when a model hallucinates\n",
    "4. Use RAGAS evaluation and understand which metrics help us measure hallucinations\n",
    "\n",
    "## Dataset\n",
    "For this workshop, we will use the [Bedrock User Guide](https://docs.aws.amazon.com/pdfs/bedrock/latest/userguide/bedrock-ug.pdf) available as a PDF file.\n",
    "## Use-Case Overview\n",
    "In this lab, we want to develop a chatbot which can answer questions about Amazon Bedrock as factually as possible. We will set up Retrieval Augmented Generation using [Amazon Bedrock Knowledge Bases](https://aws.amazon.com/bedrock/knowledge-bases/) and apply [Amazon Guardrails](https://aws.amazon.com/bedrock/guardrails/) to intervene when hallucinations are detected.\n",
    "\n",
    "\n",
    "#### Lab Sections\n",
    "\n",
    "This lab notebook has the following sections:\n",
    "    \n",
    "Please work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code.\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f260f34e-c753-4456-8643-639a3b4cdcfa",
   "metadata": {},
   "source": [
    "# Star Github repository for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb09da1-5d9e-4496-b0c8-ed5ae80911ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<a class=\"github-button\" href=\"https://github.com/aws-samples/responsible_ai_aim325_reduce_hallucinations_for_genai_apps\" data-color-scheme=\"no-preference: light; light: light; dark: dark;\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star Reduce Hallucinations workshop on GitHub\">Star</a>\n",
       "<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<a class=\"github-button\" href=\"https://github.com/aws-samples/responsible_ai_aim325_reduce_hallucinations_for_genai_apps\" data-color-scheme=\"no-preference: light; light: light; dark: dark;\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star Reduce Hallucinations workshop on GitHub\">Star</a>\n",
    "<script async defer src=\"https://buttons.github.io/buttons.js\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc006a3-48d5-40a5-9eb8-ea9bcd3d85e9",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65860ec8-bbea-4e33-b491-25e57c270470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install --upgrade --quiet pip sagemaker boto3 ragas==0.1.7 pydantic==2.6.1 langchain-core==0.1.40 langchain langchain-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba631f57-61f6-422f-8a42-472cb6046eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "!pip3 install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2ad922-9921-4b84-8608-2a77b584e850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets                                3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85fe2e2d-9fd5-4586-8fd0-6bc7b7922e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "#from IPython.core.display import HTML\n",
    "#HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f420e67-aff9-4065-8525-6fa87fca093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in BedrockBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in BedrockBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.227.0', '1.35.15')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from time import gmtime, strftime, sleep\n",
    "import pprint\n",
    "import random\n",
    "import zipfile\n",
    "#from retrying import retry\n",
    "from rag_setup.create_kb_utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from botocore.config import Config\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import sagemaker\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "(sagemaker.__version__,boto3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6edb7c-dfa1-4460-a365-e3f287951ddb",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b2c77d-ebdb-4d0a-acdd-04558b7797a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::996757723911:role/cfn-SageMakerExecutionRole-bxMsce3pMtli\n",
      "sagemaker-us-west-2-996757723911\n"
     ]
    }
   ],
   "source": [
    "# Get some variables you need to interact with SageMaker service\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "bucket_prefix = \"reduce-hallucinations-in-genai-apps\"  \n",
    "sm_session = sagemaker.Session()\n",
    "sm_client = boto_session.client(\"sagemaker\")\n",
    "sm_role = sagemaker.get_execution_role()\n",
    "\n",
    "initialized = True\n",
    "\n",
    "print(sm_role)\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c34d99ca-e263-44e3-9e35-685a7a8f9859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model_id=\"amazon.titan-embed-text-v2:0\"\n",
    "llm_model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2840d5d1-975e-49cb-9805-a7616c369f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bucket_name' (str)\n",
      "Stored 'bucket_prefix' (str)\n",
      "Stored 'sm_role' (str)\n",
      "Stored 'region' (str)\n",
      "Stored 'initialized' (bool)\n"
     ]
    }
   ],
   "source": [
    "# Store some variables to keep the value between the notebooks\n",
    "%store bucket_name\n",
    "%store bucket_prefix\n",
    "%store sm_role\n",
    "%store region\n",
    "%store initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13d3afab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/responsible_ai_reduce_hallucinations_for_genai_apps/reduce_llm_hallucinations_labs/lab1/rag_setup/create_kb_utils.py:60: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  response = llm(messages)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"No one has ever landed on the sun. The sun is a star with extremely hot temperatures and harsh conditions that make landing on its surface impossible with current technology.\\n\\nThe sun's surface temperature is around 5,500°C (9,940°F). Its powerful gravitational pull and lack of a solid surface also make landing unfeasible. Any spacecraft would burn up long before reaching the sun's surface due to the intense heat and radiation.\\n\\nSpace exploration has focused on studying the sun from a safe distance using spacecraft like the Parker Solar Probe, which has flown through the sun's outer atmosphere but not landed. Landing a crew or rover on the sun remains the stuff of science fiction for now. The extreme conditions simply make it impossible to achieve with present technology and materials.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test if bedrock model access has been enabled \n",
    "input_prompt = \"Who was the first person to land on the sun?\"\n",
    "test_llm_call(input_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44d408-1086-48fc-a329-f757fed9b02a",
   "metadata": {},
   "source": [
    "# 1. Chat with Anthropic Claude 3 Sonnet through Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340537e1-ef81-4aef-a767-f0df5e1fef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "RETRY_CONFIG = Config(\n",
    "    retries={\n",
    "        'max_attempts': 5,            # Maximum number of retry attempts\n",
    "        'mode': 'adaptive'            # Adaptive mode adjusts based on request limits\n",
    "    },\n",
    "    read_timeout=1000,\n",
    "    connect_timeout=1000\n",
    ")\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region,\n",
    "    config=RETRY_CONFIG)\n",
    "\n",
    "def generate_message_claude(\n",
    "    query, system_prompt=\"\", max_tokens=1000, \n",
    "    model_id='anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    temperature=0.9, top_p=0.99, top_k=100\n",
    "):\n",
    "    # Prompt with user turn only.\n",
    "    user_message = {\"role\": \"user\", \"content\": query}\n",
    "    messages = [user_message]\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"system\": system_prompt,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\": top_k\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dd47d4b-8455-4fcf-ae91-874ab2f7c0e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_01SY4qBYRaf7eknVNyeRdHws\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock Guardrails is a service provided by AWS that helps organizations govern their AWS environments at scale. It allows organizations to define and enforce rules, known as guardrails, across their AWS accounts and resources.\\n\\nHere's how Amazon Bedrock Guardrails works:\\n\\n1. Guardrail Definition: Organizations can define guardrails using AWS CloudFormation templates. These templates specify the desired configuration for AWS resources, services, and account settings. Guardrails can cover various aspects, such as resource naming conventions, security controls, cost optimization, and compliance requirements.\\n\\n2. Guardrail Deployment: Once the guardrails are defined, they are deployed across the organization's AWS accounts and regions using AWS Organizations and AWS Config. This ensures that the guardrails are consistently applied across the entire AWS environment.\\n\\n3. Continuous Monitoring: Amazon Bedrock Guardrails continuously monitors the AWS environment for any deviations from the defined guardrails. It uses AWS Config Rules and AWS Config Conformance Packs to evaluate the configuration of resources against the guardrail specifications.\\n\\n4. Remediation and Enforcement: If any non-compliant resources or configurations are detected, Amazon Bedrock Guardrails can take automated remediation actions to bring them back into compliance. These actions can include modifying resource configurations, deleting non-compliant resources, or preventing non-compliant deployments.\\n\\n5. Reporting and Alerting: Amazon Bedrock Guardrails provides visibility into the compliance status of the AWS environment through dashboards, reports, and alerts. This allows organizations to monitor and track their compliance posture over time and take appropriate actions when necessary.\\n\\n6. Governance and Collaboration: Amazon Bedrock Guardrails supports a centralized governance model, allowing organizations to define and manage guardrails from a single location. It also provides mechanisms for collaboration and approval workflows, ensuring that changes to guardrails are reviewed and approved by relevant stakeholders.\\n\\nBy using Amazon Bedrock Guardrails, organizations can enforce consistent governance and security practices across their AWS environments, reducing the risk of misconfigurations and ensuring compliance with internal policies and external regulations.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 19,\n",
      "        \"output_tokens\": 471\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'How do Amazon Bedrock Guardrails work?'\n",
    "\n",
    "response = generate_message_claude(query)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f0fa6-9637-4c65-bad6-0e1eacc692e9",
   "metadata": {},
   "source": [
    "## 1.1 Apply System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e203f5e9-2d93-4a79-b8ad-754d656f3008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_01BgvsJKdMHV4MXiKQ9D7VVX\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Unfortunately, I do not have any specific information about provisioning throughput or using Anthropic's models, including myself, on Amazon Bedrock. Amazon Bedrock appears to be an internal Amazon service, and I do not have details about its capabilities or offerings related to AI models from Anthropic or other providers. My knowledge is limited to what is publicly available about me and Anthropic's products and services.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 65,\n",
      "        \"output_tokens\": 89\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'Is it possible to purchase provisioned throughput for Anthropic Claude models on Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5057db14-729d-4d64-8355-fd6fe2ee2398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_01SWStSGNUMVqkSpwVDAuS5K\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock Guardrails is a service provided by AWS that allows you to establish mandatory, organization-wide governance guardrails for your AWS accounts and resources. It helps ensure your workloads conform to your organization's policies before resources are provisioned.\\n\\nHere's a high-level overview of how Amazon Bedrock Guardrails works:\\n\\n1. Guardrail Definition: You define guardrails as code using AWS CloudFormation templates or Terraform configurations. These guardrails encode your organization's policies and best practices.\\n\\n2. Guardrail Deployment: The guardrail definitions are deployed as stacks across your AWS accounts and regions using a centralized deployment mechanism provided by Bedrock Guardrails.\\n\\n3. Preventive Controls: The deployed guardrails act as preventive controls that evaluate all resource deployment requests against the defined policies before allowing the resources to be provisioned.\\n\\n4. Enforcement: If a resource deployment violates any of the defined guardrails, Bedrock Guardrails prevents the non-compliant resource from being created or updated.\\n\\n5. Reporting: Bedrock Guardrails provides visibility into guardrail violations through centralized logging and reporting mechanisms.\\n\\nThe key benefits of using Bedrock Guardrails include enforcing consistent governance across your AWS environment, preventing policy violations before they occur, and enabling self-service while maintaining control. However, I don't have detailed internal knowledge of how the service works under the hood.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 56,\n",
      "        \"output_tokens\": 321\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'How do Amazon Bedrock Guardrails work?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f9196-7e32-4ef0-b516-b8801a688aa3",
   "metadata": {},
   "source": [
    "## 1.2 Understanding LLM generation parameters\n",
    "### 1. Temperature: The amount of randomness injected into the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f610c2e0-e810-47f4-89f9-9980319e32dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_015s1hUdXGR5RgLrPfzFLqvX\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock is a real-time operating system developed by Amazon for use in embedded systems and internet of things (IoT) devices.\\n\\nSome key points about Amazon Bedrock:\\n\\n- It is a Linux-based operating system optimized for secure IoT applications and microcontroller-based devices.\\n\\n- It provides a minimal trusted code base with real-time performance for constrained devices with limited memory and storage.\\n\\n- It includes built-in support for over-the-air (OTA) updates to allow remote and secure updates of the software on IoT devices.\\n\\n- It supports C and C++ programming languages.\\n\\n- Amazon Bedrock aims to provide a secure, real-time foundation for building IoT products across various sectors like industrial, automotive, consumer, etc.\\n\\n- It was publicly announced and open-sourced by Amazon in 2022, making the code available under an open source Apache 2.0 license.\\n\\nSo in summary, Bedrock is Amazon's real-time operating system tailored specifically for IoT use cases requiring a lightweight, secure and updatable software base for constrained embedded devices.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 51,\n",
      "        \"output_tokens\": 242\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=1)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30ff7dba-2f3f-4bd2-87ce-0d84c3c03a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_01Xfi93y9pwQBkhE36pJWfW6\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock is a real-time operating system developed by Amazon for running applications on resource-constrained devices like microcontrollers and sensors.\\n\\nSome key points about Amazon Bedrock:\\n\\n- It is designed to be a secure, real-time operating system for internet of things (IoT) devices and embedded applications.\\n\\n- It provides a lightweight environment with real-time performance for running multiple software components concurrently.\\n\\n- It supports C and C++ programming languages.\\n\\n- It includes built-in security features like memory protection, encrypted communication, secure boot, and code signing.\\n\\n- It aims to simplify development and deployment of IoT applications across different hardware platforms.\\n\\n- Bedrock is open source and available under the Apache 2.0 license on GitHub.\\n\\n- It can run on microcontroller units (MCUs) from various vendors like NXP, STMicroelectronics, Infineon, etc.\\n\\nSo in summary, Bedrock provides a secure, real-time embedded OS foundation for building and deploying IoT applications on constrained devices used in industrial, automotive, consumer and other domains.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 51,\n",
      "        \"output_tokens\": 244\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=0)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47723758-0f8c-4190-94ef-3bdd4d386908",
   "metadata": {},
   "source": [
    "#### 2. top_p – Use nucleus sampling.\n",
    "\n",
    "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e300c40f-1b7b-4db1-bc5f-5f483507262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_019nwMrWdiHtJnLuvnsXcgum\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock is a real-time operating system (RTOS) developed by Amazon Web Services (AWS) for running lightweight IoT applications on resource-constrained devices.\\n\\nSome key features of Amazon Bedrock:\\n\\n1) Small footprint: It is designed to have a minimal memory footprint, making it suitable for microcontrollers and other devices with limited memory and compute resources.\\n\\n2) Real-time performance: As an RTOS, it provides real-time scheduling and execution capabilities required for time-sensitive IoT applications.\\n\\n3) Secure: It includes security features like memory protection, cryptographic libraries, and secure boot capabilities.\\n\\n4) Connected: It supports connectivity to AWS IoT services, allowing devices to easily integrate with the AWS cloud.\\n\\n5) Open source: The kernel and core components of Bedrock are open source, allowing customization and contributions.\\n\\nBedrock aims to simplify the development of secure, real-time IoT applications for constrained devices by providing a lightweight embedded OS backed by AWS's cloud services. It competes with other embedded RTOSes like FreeRTOS, Zephyr, and ARM Mbed.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 51,\n",
      "        \"output_tokens\": 254\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=1, top_p=1)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7946bd-976d-4a8d-81ef-f7ff7e164f94",
   "metadata": {},
   "source": [
    "#### 3. top_k: Only sample from the top K options for each subsequent token.\n",
    "\n",
    "Use top_k to remove long tail low probability responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cf753a4-8929-46ef-8aea-7ef040abb096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_01SkA6egzjn9mcCuSTZVAgZB\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock is a real-time operating system developed by Amazon for running applications on resource-constrained devices like microcontrollers and sensors.\\n\\nSome key points about Amazon Bedrock:\\n\\n- It is designed to be a secure, real-time operating system for internet of things (IoT) devices and embedded applications.\\n\\n- It provides a lightweight environment with real-time performance for running multiple software components concurrently.\\n\\n- It supports C and C++ programming languages.\\n\\n- It includes built-in security features like memory protection, encrypted communication, secure boot, and code signing.\\n\\n- It aims to simplify development and deployment of IoT applications across different hardware platforms.\\n\\n- Bedrock is open source and available under the Apache 2.0 license on GitHub.\\n\\n- It can run on microcontroller units (MCUs) from various vendors like NXP, STMicroelectronics, Infineon, etc.\\n\\nSo in summary, Bedrock provides a secure, real-time embedded OS foundation for building and deploying IoT applications on constrained devices used in industrial, automotive, consumer and other domains.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 51,\n",
      "        \"output_tokens\": 244\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=0, top_p=1, top_k=100)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9caf35-dccd-4c16-82eb-ea3e1327bc80",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation\n",
    "We are using the Retrieval Augmented Generation (RAG) technique with Amazon Bedrock. A RAG implementation consists of two parts:\n",
    "\n",
    "    1. A data pipeline that ingests that from documents (typically stored in Amazon S3) into a Knowledge Base i.e. a vector database such as Amazon OpenSearch Service Serverless (AOSS) so that it is available for lookup when a question is received.\n",
    "\n",
    "The data pipeline represents an undifferentiated heavy lifting and can be implemented using Amazon Bedrock Knowledge Bases. We can now connect an S3 bucket to a vector database such as AOSS and have a Bedrock Knowledge Bases read the objects (html, pdf, text etc.), chunk them, and then convert these chunks into embeddings using Amazon Titan Embeddings model and then store these embeddings in AOSS. All of this without having to build, deploy, and manage the data pipeline.\n",
    "\n",
    "<center><img src=\"images/fully_managed_ingestion.png\" alt=\"This image shows how Aazon Bedrock Knowledge Bases ingests objects in a S3 bucket into the Knowledge Base for use in a RAG set up. The objects are chunks, embedded and then stored in a vector index.\" height=\"700\" width=\"700\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "    \n",
    "\n",
    "    2. An application that receives a question from the user, looks up the knowledge base for relevant pieces of information (context) and then creates a prompt that includes the question and the context and provides it to an LLM for generating a response.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Once the data is available in the Bedrock knowledge base, then user questions can be answered using the following system design:\n",
    "\n",
    "<center><img src=\"images/retrieveAndGenerate.png\" alt=\"This image shows the retrieval augmented generation (RAG) system design setup with knowledge bases, S3, and AOSS. Knowledge corpus is ingested into a vector database using Amazon Bedrock Knowledge Base Agent and then RAG approach is used to work question answering. The question is converted into embeddings followed by semantic similarity search to get similar documents. With the user prompt being augmented with the RAG search response, the LLM is invoked to get the final raw response for the user.\" height=\"700\" width=\"700\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588c8c3",
   "metadata": {},
   "source": [
    "# Data\n",
    "Let's use the publicly available [Bedrock user guide](https://docs.aws.amazon.com/pdfs/bedrock/latest/userguide/bedrock-ug.pdf) to inform the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b522396d-33e9-4251-9c72-09909436e25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-13 20:31:22--  https://docs.aws.amazon.com/pdfs/bedrock/latest/userguide/bedrock-ug.pdf\n",
      "Resolving docs.aws.amazon.com (docs.aws.amazon.com)... 18.238.238.32, 18.238.238.78, 18.238.238.98, ...\n",
      "Connecting to docs.aws.amazon.com (docs.aws.amazon.com)|18.238.238.32|:443... connected.\n",
      "WARNING: cannot verify docs.aws.amazon.com's certificate, issued by ‘CN=Amazon RSA 2048 M02,O=Amazon,C=US’:\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13669946 (13M) [application/pdf]\n",
      "Saving to: ‘data/bedrock-ug.pdf’\n",
      "\n",
      "bedrock-ug.pdf      100%[===================>]  13.04M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-11-13 20:31:23 (112 MB/s) - ‘data/bedrock-ug.pdf’ saved [13669946/13669946]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P data/ -N https://docs.aws.amazon.com/pdfs/bedrock/latest/userguide/bedrock-ug.pdf --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fb05ed4-b63c-4e3c-a702-28021c506ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload the dataset to s3://sagemaker-us-west-2-996757723911/data/bedrock-ug.pdf\n",
      "Stored 'input_s3_url' (str)\n"
     ]
    }
   ],
   "source": [
    "# Upload data to S3\n",
    "dataset_file_local_path = 'data/bedrock-ug.pdf'\n",
    "input_s3_url = sagemaker.Session().upload_data(\n",
    "    path=dataset_file_local_path,\n",
    "    bucket=bucket_name\n",
    ")\n",
    "print(f\"Upload the dataset to {input_s3_url}\")\n",
    "\n",
    "%store input_s3_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbbc4e-039f-49d8-8de0-7ce89ca30349",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "1. Create Amazon Bedrock Knowledge Base execution role with necessary policies for accessing data from S3 and writing embeddings into OSS.\n",
    "2. Create an empty OpenSearch serverless index.\n",
    "3. Create Amazon Bedrock knowledge base\n",
    "4. Create a data source within knowledge base which will connect to Amazon S3\n",
    "5. Start an ingestion job using KB APIs which will read data from s3, chunk it, convert chunks into embeddings using Amazon Titan Embeddings model and then store these embeddings in AOSS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae93890e-c684-4286-9234-91a3e058cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH='./lab1/'\n",
    "#import sys\n",
    "#sys.path.insert(0,'./lab1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0140ab19-a682-4855-b3ee-10589637211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_db_file_uri='data'\n",
    "\n",
    "# if a kb already exists we can use the same, else the infra setup code will create one by itself using the bedrock user guide.\n",
    "use_existing_kb = False\n",
    "existing_kb_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c31b846-fa1f-43e0-ad9f-814bdb7dc3b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from rag_setup.create_kb_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e53913c-2aeb-42b4-be3e-c2eea8136eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_bedrock_policy :: None\n",
      "agent_s3_schema_policy :: None\n",
      "kb_aws_bedrock_policy :: None\n",
      "kb_db_s3_policy :: None\n",
      "Creating collection...\n",
      "\n",
      "Collection successfully created:\n",
      "\n",
      "Creating index:\n",
      "Knowledge base status -> is it READY ? :: ACTIVE\n",
      "knowledge_base_db_id :: DSALKIXRIV\n",
      "CPU times: user 275 ms, sys: 33.1 ms, total: 308 ms\n",
      "Wall time: 5min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prefix_infra': 'l2ad2e45',\n",
       " 'bucket_name': 'sagemaker-us-west-2-996757723911',\n",
       " 'knowledge_base_db_id': 'DSALKIXRIV',\n",
       " 'agent_bedrock_policy': None,\n",
       " 'agent_s3_schema_policy': None,\n",
       " 'kb_db_collection_name': 'l25929-kbdb-996757723911',\n",
       " 'agent_kb_schema_policy': None,\n",
       " 'kb_db_aoss_policy': None,\n",
       " 'kb_db_s3_policy': None,\n",
       " 'kb_db_role_name': 'AmazonBedrockExecutionRoleForAgentsAIAssistant05',\n",
       " 'kb_db_opensearch_collection_response': {'createCollectionDetail': {'arn': 'arn:aws:aoss:us-west-2:996757723911:collection/zrswlgcemuvny02ltvph',\n",
       "   'createdDate': 1731529886011,\n",
       "   'description': 'OpenSearch collection for Amazon Bedrock Latest User guide Knowledge Base',\n",
       "   'id': 'zrswlgcemuvny02ltvph',\n",
       "   'kmsKeyArn': 'auto',\n",
       "   'lastModifiedDate': 1731529886011,\n",
       "   'name': 'l25929-kbdb-996757723911',\n",
       "   'standbyReplicas': 'DISABLED',\n",
       "   'status': 'CREATING',\n",
       "   'type': 'VECTORSEARCH'},\n",
       "  'ResponseMetadata': {'RequestId': 'b33b1a24-31b0-450f-b481-c1bd338f9ebf',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amzn-requestid': 'b33b1a24-31b0-450f-b481-c1bd338f9ebf',\n",
       "    'date': 'Wed, 13 Nov 2024 20:31:26 GMT',\n",
       "    'content-type': 'application/x-amz-json-1.0',\n",
       "    'content-length': '407',\n",
       "    'connection': 'keep-alive'},\n",
       "   'RetryAttempts': 0}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For new KB it takes around ~6 minutes for this setup to complete on a t2.medium instance.\n",
    "infra_response = setup_knowledge_base(bucket_name, kb_db_file_uri, use_existing_kb, existing_kb_id)\n",
    "infra_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ec5179f-d77c-4d52-918c-f4fb37b70f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'kb_id' (str)\n",
      "Stored 'bucket_name' (str)\n"
     ]
    }
   ],
   "source": [
    "kb_id = infra_response['knowledge_base_db_id']\n",
    "random_id = infra_response['prefix_infra']\n",
    "# keep the kb_id for invocation later in the invoke request\n",
    "%store kb_id\n",
    "%store bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae3cf9eb-6d1e-4ae4-81db-a23379eae74d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DSALKIXRIV'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf3a828f-e46d-4a14-8011-122a399b8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow time for KB to be ready\n",
    "time.sleep(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c35041-9487-46e6-9a36-fd8d408712c4",
   "metadata": {},
   "source": [
    "# Chat with the model using the knowledge base by providing the generated KB_ID\n",
    "### Using RetrieveAndGenerate API\n",
    "Behind the scenes, RetrieveAndGenerate API converts queries into embeddings, searches the knowledge base, and then augments the foundation model prompt with the search results as context information and returns the FM-generated response to the question. For multi-turn conversations, Knowledge Bases manage short-term memory of the conversation to provide more contextual results.The output of the RetrieveAndGenerate API includes the generated response, source attribution as well as the retrieved text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ca09025-187d-4aa4-8a0f-b6524e734ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0480df70-ab90-4c5d-bf07-8acabf7a1a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DSALKIXRIV'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06645e80-eebb-4883-a086-70ccfdf604c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "\n",
    "def ask_bedrock_llm_with_knowledge_base(query,\n",
    "                                        kb_id=kb_id,\n",
    "                                        model_arn=llm_model_id,\n",
    "                                        ) -> str:\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\n",
    "            'text': query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': model_arn\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a151db3d-b340-46b2-bd57-491714d2068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Generated using Anthropic Claude 3 Sonnet:\n",
      "('Amazon Bedrock is a fully managed service that provides access to '\n",
      " 'high-performing foundation models (FMs) from leading AI companies and Amazon '\n",
      " 'through a unified API. It allows you to experiment with and evaluate '\n",
      " 'different foundation models, customize them with your own data using '\n",
      " 'techniques like fine-tuning and Retrieval Augmented Generation (RAG), and '\n",
      " 'build agents that can execute tasks using your systems and data sources. '\n",
      " \"With Amazon Bedrock's serverless experience, you can get started quickly, \"\n",
      " 'customize foundation models with your data, and easily integrate and deploy '\n",
      " 'them into your applications using AWS tools without managing any '\n",
      " 'infrastructure.')\n",
      "---------- The citations for the response:\n",
      "[ '............ 2009     xvAmazon Bedrock User Guide     What is Amazon '\n",
      "  'Bedrock?     Amazon Bedrock is a fully managed service that makes '\n",
      "  'high-performing foundation models (FMs) from leading AI companies and '\n",
      "  'Amazon available for your use through a unified API. You can choose from a '\n",
      "  'wide range of foundation models to find the model that is best suited for '\n",
      "  'your use case. Amazon Bedrock also offers a broad set of capabilities to '\n",
      "  'build generative AI applications with security, privacy, and responsible '\n",
      "  'AI. Using Amazon Bedrock, you can easily experiment with and evaluate top '\n",
      "  'foundation models for your use cases, privately customize them with your '\n",
      "  'data using techniques such as fine-tuning and Retrieval Augmented '\n",
      "  'Generation (RAG), and build agents that execute tasks using your enterprise '\n",
      "  \"systems and data sources.     With Amazon Bedrock's serverless experience, \"\n",
      "  'you can get started quickly, privately customize foundation models with '\n",
      "  'your own data, and easily and securely integrate and deploy them into your '\n",
      "  'applications using AWS tools without having to manage any '\n",
      "  'infrastructure.     Topics     ? What can I do with Amazon Bedrock?     ? '\n",
      "  'How do I get started with Amazon Bedrock?     ? Amazon Bedrock pricing     '\n",
      "  '? Supported AWS Regions in Amazon Bedrock     ? Key terminology     What '\n",
      "  'can I do with Amazon Bedrock?     You can use Amazon Bedrock to do the '\n",
      "  'following:     ? Experiment with prompts and configurations ? Submit '\n",
      "  'prompts and generate responses with model inference by sending prompts '\n",
      "  'using different configurations and foundation models to generate responses. '\n",
      "  'You can use the API or the text, image, and chat playgrounds in the console '\n",
      "  \"to experiment in a graphical interface. When you're ready, set up your \"\n",
      "  'application to make requests to the InvokeModel APIs.     ? Augment '\n",
      "  'response generation with information from your data sources ? Create '\n",
      "  'knowledge bases by uploading data sources to be queried in order to augment '\n",
      "  \"a foundation model's generation of responses.     What can I do with Amazon \"\n",
      "  'Bedrock? 1Amazon Bedrock User Guide     ? Create applications that reason '\n",
      "  'through how to help a customer ? Build agents that use foundation models, '\n",
      "  'make API calls, and (optionally) query knowledge bases in order to reason '\n",
      "  'through and carry out tasks for your customers.     ? Adapt models to '\n",
      "  'specific tasks and domains with training data ? Customize an Amazon Bedrock '\n",
      "  'foundation model by providing training data for fine-tuning or '\n",
      "  \"continued-pretraining in order to adjust a model's parameters and improve \"\n",
      "  'its performance on specific tasks or in certain domains.     ? Improve your '\n",
      "  \"FM-based application's efficiency and output ? Purchase Provisioned \"\n",
      "  'Throughput for a foundation model in order to run inference on models more '\n",
      "  'efficiently and at discounted rates.     ? Determine the best model for '\n",
      "  'your use case ? Evaluate outputs of different models with built-in or '\n",
      "  'custom prompt datasets to determine the model that is best suited for your '\n",
      "  'application.     ? Prevent inappropriate or unwanted content ? Use '\n",
      "  'guardrails to implement safeguards for your generative AI applications.     '\n",
      "  'To see feature limitations by AWS Region, see Model support by AWS '\n",
      "  'Region.     How do I get started with Amazon Bedrock?     We recommend that '\n",
      "  'you start with Amazon Bedrock by doing the following:     1. Familiarize '\n",
      "  'yourself with the terms and concepts that Amazon Bedrock uses.     2. '\n",
      "  'Understand how AWS charges you for using Amazon Bedrock.     3. Try the '\n",
      "  'Getting started with Amazon Bedrock tutorials. In the tutorials, you learn '\n",
      "  'how to use the playgrounds in Amazon Bedrock console. You also learn and '\n",
      "  'how to use the AWS SDK to call Amazon Bedrock API operations.     4. Read '\n",
      "  'the documentation for the features that you want to include in your '\n",
      "  'application.     Amazon Bedrock pricing     When you sign up for AWS, your '\n",
      "  'AWS account is automatically signed up for all services in AWS, including '\n",
      "  'Amazon Bedrock. However, you are charged only for the services that you '\n",
      "  'use.     How do I get started with Amazon Bedrock? 2Amazon Bedrock User '\n",
      "  'Guide     To see your bill, go to the Billing and Cost Management Dashboard '\n",
      "  'in the AWS Billing and Cost Management console. To learn more about AWS '\n",
      "  'account billing, see the AWS Billing User Guide. If you have questions '\n",
      "  'concerning AWS billing and AWS accounts, contact AWS Support.     With '\n",
      "  'Amazon Bedrock, you pay to run inference on any of the third-party '\n",
      "  'foundation models. Pricing is based on the volume of input tokens and '\n",
      "  'output tokens, and on whether you have purchased provisioned throughput for '\n",
      "  'the model. For more information, see the Model providers page in the Amazon '\n",
      "  'Bedrock console. For each model, pricing is listed following the model '\n",
      "  'version. For more information about purchasing Provisioned Throughput, see '\n",
      "  'Increase model invocation capacity with Provisioned Throughput in Amazon '\n",
      "  'Bedrock.     For more information, see Amazon Bedrock Pricing.     '\n",
      "  'Supported AWS Regions in Amazon Bedrock     This topic list the AWS Regions '\n",
      "  'that support Amazon Bedrock and the Amazon Bedrock features that each '\n",
      "  'Region supports. For information about service endpoints for Regions that '\n",
      "  'Amazon Bedrock supports, see Amazon Bedrock endpoints and quotas. To see '\n",
      "  'what foundation models each Region supports, see to Model support by AWS '\n",
      "  'Region.',\n",
      "  '......................................................................................................................... '\n",
      "  '1632     Amazon Bedrock Runtime '\n",
      "  '................................................................................................................... '\n",
      "  '1634 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1641 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1646 AI21 Labs Jurassic-2 '\n",
      "  '........................................................................................................................ '\n",
      "  '1659 Amazon Titan Image Generator '\n",
      "  '.................................................................................................... '\n",
      "  '1677 Amazon Titan Text '\n",
      "  '........................................................................................................................... '\n",
      "  '1686 Amazon Titan Text Embeddings '\n",
      "  '................................................................................................... '\n",
      "  '1717 Anthropic Claude '\n",
      "  '.............................................................................................................................. '\n",
      "  '1722 Cohere Command '\n",
      "  '............................................................................................................................. '\n",
      "  '1791 Meta Llama '\n",
      "  '........................................................................................................................................ '\n",
      "  '1839 Mistral AI '\n",
      "  '............................................................................................................................................ '\n",
      "  '1888 Stable Diffusion '\n",
      "  '................................................................................................................................ '\n",
      "  '1917     Amazon Bedrock Agents '\n",
      "  '...................................................................................................................... '\n",
      "  '1926 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1929 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1957     Amazon Bedrock Agents Runtime '\n",
      "  '..................................................................................................... '\n",
      "  '1970 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1971 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1978     Abuse detection '\n",
      "  '......................................................................................................................... '\n",
      "  '1980 Create resources with AWS CloudFormation '\n",
      "  '........................................................................... '\n",
      "  '1982     Amazon Bedrock and AWS CloudFormation templates '\n",
      "  '................................................................ 1982     '\n",
      "  'xivAmazon Bedrock User Guide     Learn more about AWS CloudFormation '\n",
      "  '.......................................................................................... '\n",
      "  '1983 Troubleshooting Amazon Bedrock API Error Codes '\n",
      "  '................................................................ 1984     '\n",
      "  'AccessDeniedExcpetion '\n",
      "  '......................................................................................................................... '\n",
      "  '1984 IncompleteSignature '\n",
      "  '............................................................................................................................. '\n",
      "  '1984 InternalFailure '\n",
      "  '........................................................................................................................................ '\n",
      "  '1984 InvalidAction '\n",
      "  '........................................................................................................................................... '\n",
      "  '1985 InvalidClientTokenId '\n",
      "  '.............................................................................................................................. '\n",
      "  '1985 NotAuthorized '\n",
      "  '........................................................................................................................................ '\n",
      "  '1985 RequestExpired '\n",
      "  '....................................................................................................................................... '\n",
      "  '1986 ServiceUnavailable '\n",
      "  '................................................................................................................................. '\n",
      "  '1986 ThrottlingException '\n",
      "  '............................................................................................................................... '\n",
      "  '1987 ValidationError '\n",
      "  '....................................................................................................................................... '\n",
      "  '1987 ResourceNotFound '\n",
      "  '................................................................................................................................ '\n",
      "  '1988     Quotas '\n",
      "  '........................................................................................................................................ '\n",
      "  '1989 Request an increase for Amazon Bedrock quotas '\n",
      "  '.......................................................................... '\n",
      "  '1989     Document history '\n",
      "  '...................................................................................................................... '\n",
      "  '1990 AWS Glossary '\n",
      "  '............................................................................................................................. '\n",
      "  '2009     xvAmazon Bedrock User Guide     What is Amazon Bedrock?     Amazon '\n",
      "  'Bedrock is a fully managed service that makes high-performing foundation '\n",
      "  'models (FMs) from leading AI companies and Amazon available for your use '\n",
      "  'through a unified API. You can choose from a wide range of foundation '\n",
      "  'models to find the model that is best suited for your use case. Amazon '\n",
      "  'Bedrock also offers a broad set of capabilities to build generative AI '\n",
      "  'applications with security, privacy, and responsible AI. Using Amazon '\n",
      "  'Bedrock, you can easily experiment with and evaluate top foundation models '\n",
      "  'for your use cases, privately customize them with your data using '\n",
      "  'techniques such as fine-tuning and Retrieval Augmented Generation (RAG), '\n",
      "  'and build agents that execute tasks using your enterprise systems and data '\n",
      "  \"sources.     With Amazon Bedrock's serverless experience, you can get \"\n",
      "  'started quickly, privately customize foundation models with your own data, '\n",
      "  'and easily and securely integrate and deploy them into your applications '\n",
      "  'using AWS tools without having to manage any infrastructure.     Topics     '\n",
      "  '? What can I do with Amazon Bedrock?     ? How do I get started with Amazon '\n",
      "  'Bedrock?     ? Amazon Bedrock pricing     ? Supported AWS Regions in Amazon '\n",
      "  'Bedrock     ? Key terminology     What can I do with Amazon Bedrock?     '\n",
      "  'You can use Amazon Bedrock to do the following:     ? Experiment with '\n",
      "  'prompts and configurations ? Submit prompts and generate responses with '\n",
      "  'model inference by sending prompts using different configurations and '\n",
      "  'foundation models to generate responses. You can use the API or the text, '\n",
      "  'image, and chat playgrounds in the console to experiment in a graphical '\n",
      "  \"interface. When you're ready, set up your application to make requests to \"\n",
      "  'the InvokeModel APIs.     ? Augment response generation with information '\n",
      "  'from your data sources ? Create knowledge bases by uploading data sources '\n",
      "  \"to be queried in order to augment a foundation model's generation of \"\n",
      "  'responses.     What can I do with Amazon Bedrock? 1Amazon Bedrock User '\n",
      "  'Guide     ? Create applications that reason through how to help a customer '\n",
      "  '? Build agents that use foundation models, make API calls, and (optionally) '\n",
      "  'query knowledge bases in order to reason through and carry out tasks for '\n",
      "  'your customers.     ? Adapt models to specific tasks and domains with '\n",
      "  'training data ? Customize an Amazon Bedrock foundation model by providing '\n",
      "  'training data for fine-tuning or continued-pretraining in order to adjust a '\n",
      "  \"model's parameters and improve its performance on specific tasks or in \"\n",
      "  \"certain domains.     ? Improve your FM-based application's efficiency and \"\n",
      "  'output ? Purchase Provisioned Throughput for a foundation model in order to '\n",
      "  'run inference on models more efficiently and at discounted rates.     ? '\n",
      "  'Determine the best model for your use case ? Evaluate outputs of different '\n",
      "  'models with built-in or custom prompt datasets to determine the model that '\n",
      "  'is best suited for your application.     ? Prevent inappropriate or '\n",
      "  'unwanted content ? Use guardrails to implement safeguards for your '\n",
      "  'generative AI applications.     To see feature limitations by AWS Region, '\n",
      "  'see Model support by AWS Region.     How do I get started with Amazon '\n",
      "  'Bedrock?     We recommend that you start with Amazon Bedrock by doing the '\n",
      "  'following:     1.',\n",
      "  '........................................ 1985 RequestExpired '\n",
      "  '....................................................................................................................................... '\n",
      "  '1986 ServiceUnavailable '\n",
      "  '................................................................................................................................. '\n",
      "  '1986 ThrottlingException '\n",
      "  '............................................................................................................................... '\n",
      "  '1987 ValidationError '\n",
      "  '....................................................................................................................................... '\n",
      "  '1987 ResourceNotFound '\n",
      "  '................................................................................................................................ '\n",
      "  '1988     Quotas '\n",
      "  '........................................................................................................................................ '\n",
      "  '1989 Request an increase for Amazon Bedrock quotas '\n",
      "  '.......................................................................... '\n",
      "  '1989     Document history '\n",
      "  '...................................................................................................................... '\n",
      "  '1990 AWS Glossary '\n",
      "  '............................................................................................................................. '\n",
      "  '2009     xvAmazon Bedrock User Guide     What is Amazon Bedrock?     Amazon '\n",
      "  'Bedrock is a fully managed service that makes high-performing foundation '\n",
      "  'models (FMs) from leading AI companies and Amazon available for your use '\n",
      "  'through a unified API. You can choose from a wide range of foundation '\n",
      "  'models to find the model that is best suited for your use case. Amazon '\n",
      "  'Bedrock also offers a broad set of capabilities to build generative AI '\n",
      "  'applications with security, privacy, and responsible AI. Using Amazon '\n",
      "  'Bedrock, you can easily experiment with and evaluate top foundation models '\n",
      "  'for your use cases, privately customize them with your data using '\n",
      "  'techniques such as fine-tuning and Retrieval Augmented Generation (RAG), '\n",
      "  'and build agents that execute tasks using your enterprise systems and data '\n",
      "  \"sources.     With Amazon Bedrock's serverless experience, you can get \"\n",
      "  'started quickly, privately customize foundation models with your own data, '\n",
      "  'and easily and securely integrate and deploy them into your applications '\n",
      "  'using AWS tools without having to manage any infrastructure.     Topics     '\n",
      "  '? What can I do with Amazon Bedrock?     ? How do I get started with Amazon '\n",
      "  'Bedrock?     ? Amazon Bedrock pricing     ? Supported AWS Regions in Amazon '\n",
      "  'Bedrock     ? Key terminology     What can I do with Amazon Bedrock?     '\n",
      "  'You can use Amazon Bedrock to do the following:     ? Experiment with '\n",
      "  'prompts and configurations ? Submit prompts and generate responses with '\n",
      "  'model inference by sending prompts using different configurations and '\n",
      "  'foundation models to generate responses. You can use the API or the text, '\n",
      "  'image, and chat playgrounds in the console to experiment in a graphical '\n",
      "  \"interface. When you're ready, set up your application to make requests to \"\n",
      "  'the InvokeModel APIs.     ? Augment response generation with information '\n",
      "  'from your data sources ? Create knowledge bases by uploading data sources '\n",
      "  \"to be queried in order to augment a foundation model's generation of \"\n",
      "  'responses.     What can I do with Amazon Bedrock? 1Amazon Bedrock User '\n",
      "  'Guide     ? Create applications that reason through how to help a customer '\n",
      "  '? Build agents that use foundation models, make API calls, and (optionally) '\n",
      "  'query knowledge bases in order to reason through and carry out tasks for '\n",
      "  'your customers.     ? Adapt models to specific tasks and domains with '\n",
      "  'training data ? Customize an Amazon Bedrock foundation model by providing '\n",
      "  'training data for fine-tuning or continued-pretraining in order to adjust a '\n",
      "  \"model's parameters and improve its performance on specific tasks or in \"\n",
      "  \"certain domains.     ? Improve your FM-based application's efficiency and \"\n",
      "  'output ? Purchase Provisioned Throughput for a foundation model in order to '\n",
      "  'run inference on models more efficiently and at discounted rates.     ? '\n",
      "  'Determine the best model for your use case ? Evaluate outputs of different '\n",
      "  'models with built-in or custom prompt datasets to determine the model that '\n",
      "  'is best suited for your application.     ? Prevent inappropriate or '\n",
      "  'unwanted content ? Use guardrails to implement safeguards for your '\n",
      "  'generative AI applications.     To see feature limitations by AWS Region, '\n",
      "  'see Model support by AWS Region.     How do I get started with Amazon '\n",
      "  'Bedrock?     We recommend that you start with Amazon Bedrock by doing the '\n",
      "  'following:     1. Familiarize yourself with the terms and concepts that '\n",
      "  'Amazon Bedrock uses.     2. Understand how AWS charges you for using Amazon '\n",
      "  'Bedrock.     3. Try the Getting started with Amazon Bedrock tutorials. In '\n",
      "  'the tutorials, you learn how to use the playgrounds in Amazon Bedrock '\n",
      "  'console. You also learn and how to use the AWS SDK to call Amazon Bedrock '\n",
      "  'API operations.     4. Read the documentation for the features that you '\n",
      "  'want to include in your application.     Amazon Bedrock pricing     When '\n",
      "  'you sign up for AWS, your AWS account is automatically signed up for all '\n",
      "  'services in AWS, including Amazon Bedrock. However, you are charged only '\n",
      "  'for the services that you use.     How do I get started with Amazon '\n",
      "  'Bedrock? 2Amazon Bedrock User Guide     To see your bill, go to the Billing '\n",
      "  'and Cost Management Dashboard in the AWS Billing and Cost Management '\n",
      "  'console. To learn more about AWS account billing, see the AWS Billing User '\n",
      "  'Guide. If you have questions concerning AWS billing and AWS accounts, '\n",
      "  'contact AWS Support.     With Amazon Bedrock, you pay to run inference on '\n",
      "  'any of the third-party foundation models. Pricing is based on the volume of '\n",
      "  'input tokens and output tokens, and on whether you have purchased '\n",
      "  'provisioned throughput for the model. For more information, see the Model '\n",
      "  'providers page in the Amazon Bedrock console. For each model, pricing is '\n",
      "  'listed following the model version.',\n",
      "  '............ 2009     xvAmazon Bedrock User Guide     What is Amazon '\n",
      "  'Bedrock?     Amazon Bedrock is a fully managed service that makes '\n",
      "  'high-performing foundation models (FMs) from leading AI companies and '\n",
      "  'Amazon available for your use through a unified API. You can choose from a '\n",
      "  'wide range of foundation models to find the model that is best suited for '\n",
      "  'your use case. Amazon Bedrock also offers a broad set of capabilities to '\n",
      "  'build generative AI applications with security, privacy, and responsible '\n",
      "  'AI. Using Amazon Bedrock, you can easily experiment with and evaluate top '\n",
      "  'foundation models for your use cases, privately customize them with your '\n",
      "  'data using techniques such as fine-tuning and Retrieval Augmented '\n",
      "  'Generation (RAG), and build agents that execute tasks using your enterprise '\n",
      "  \"systems and data sources.     With Amazon Bedrock's serverless experience, \"\n",
      "  'you can get started quickly, privately customize foundation models with '\n",
      "  'your own data, and easily and securely integrate and deploy them into your '\n",
      "  'applications using AWS tools without having to manage any '\n",
      "  'infrastructure.     Topics     ? What can I do with Amazon Bedrock?     ? '\n",
      "  'How do I get started with Amazon Bedrock?     ? Amazon Bedrock pricing     '\n",
      "  '? Supported AWS Regions in Amazon Bedrock     ? Key terminology     What '\n",
      "  'can I do with Amazon Bedrock?     You can use Amazon Bedrock to do the '\n",
      "  'following:     ? Experiment with prompts and configurations ? Submit '\n",
      "  'prompts and generate responses with model inference by sending prompts '\n",
      "  'using different configurations and foundation models to generate responses. '\n",
      "  'You can use the API or the text, image, and chat playgrounds in the console '\n",
      "  \"to experiment in a graphical interface. When you're ready, set up your \"\n",
      "  'application to make requests to the InvokeModel APIs.     ? Augment '\n",
      "  'response generation with information from your data sources ? Create '\n",
      "  'knowledge bases by uploading data sources to be queried in order to augment '\n",
      "  \"a foundation model's generation of responses.     What can I do with Amazon \"\n",
      "  'Bedrock? 1Amazon Bedrock User Guide     ? Create applications that reason '\n",
      "  'through how to help a customer ? Build agents that use foundation models, '\n",
      "  'make API calls, and (optionally) query knowledge bases in order to reason '\n",
      "  'through and carry out tasks for your customers.     ? Adapt models to '\n",
      "  'specific tasks and domains with training data ? Customize an Amazon Bedrock '\n",
      "  'foundation model by providing training data for fine-tuning or '\n",
      "  \"continued-pretraining in order to adjust a model's parameters and improve \"\n",
      "  'its performance on specific tasks or in certain domains.     ? Improve your '\n",
      "  \"FM-based application's efficiency and output ? Purchase Provisioned \"\n",
      "  'Throughput for a foundation model in order to run inference on models more '\n",
      "  'efficiently and at discounted rates.     ? Determine the best model for '\n",
      "  'your use case ? Evaluate outputs of different models with built-in or '\n",
      "  'custom prompt datasets to determine the model that is best suited for your '\n",
      "  'application.     ? Prevent inappropriate or unwanted content ? Use '\n",
      "  'guardrails to implement safeguards for your generative AI applications.     '\n",
      "  'To see feature limitations by AWS Region, see Model support by AWS '\n",
      "  'Region.     How do I get started with Amazon Bedrock?     We recommend that '\n",
      "  'you start with Amazon Bedrock by doing the following:     1. Familiarize '\n",
      "  'yourself with the terms and concepts that Amazon Bedrock uses.     2. '\n",
      "  'Understand how AWS charges you for using Amazon Bedrock.     3. Try the '\n",
      "  'Getting started with Amazon Bedrock tutorials. In the tutorials, you learn '\n",
      "  'how to use the playgrounds in Amazon Bedrock console. You also learn and '\n",
      "  'how to use the AWS SDK to call Amazon Bedrock API operations.     4. Read '\n",
      "  'the documentation for the features that you want to include in your '\n",
      "  'application.     Amazon Bedrock pricing     When you sign up for AWS, your '\n",
      "  'AWS account is automatically signed up for all services in AWS, including '\n",
      "  'Amazon Bedrock. However, you are charged only for the services that you '\n",
      "  'use.     How do I get started with Amazon Bedrock? 2Amazon Bedrock User '\n",
      "  'Guide     To see your bill, go to the Billing and Cost Management Dashboard '\n",
      "  'in the AWS Billing and Cost Management console. To learn more about AWS '\n",
      "  'account billing, see the AWS Billing User Guide. If you have questions '\n",
      "  'concerning AWS billing and AWS accounts, contact AWS Support.     With '\n",
      "  'Amazon Bedrock, you pay to run inference on any of the third-party '\n",
      "  'foundation models. Pricing is based on the volume of input tokens and '\n",
      "  'output tokens, and on whether you have purchased provisioned throughput for '\n",
      "  'the model. For more information, see the Model providers page in the Amazon '\n",
      "  'Bedrock console. For each model, pricing is listed following the model '\n",
      "  'version. For more information about purchasing Provisioned Throughput, see '\n",
      "  'Increase model invocation capacity with Provisioned Throughput in Amazon '\n",
      "  'Bedrock.     For more information, see Amazon Bedrock Pricing.     '\n",
      "  'Supported AWS Regions in Amazon Bedrock     This topic list the AWS Regions '\n",
      "  'that support Amazon Bedrock and the Amazon Bedrock features that each '\n",
      "  'Region supports. For information about service endpoints for Regions that '\n",
      "  'Amazon Bedrock supports, see Amazon Bedrock endpoints and quotas. To see '\n",
      "  'what foundation models each Region supports, see to Model support by AWS '\n",
      "  'Region.']\n",
      "DSALKIXRIV\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon Bedrock?\"\n",
    "\n",
    "response = ask_bedrock_llm_with_knowledge_base(query, kb_id)\n",
    "generated_text = response['output']['text']\n",
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "        contexts.append(reference[\"content\"][\"text\"])\n",
    "print(f\"---------- Generated using Anthropic Claude 3 Sonnet:\")\n",
    "pp.pprint(generated_text )\n",
    "print(f'---------- The citations for the response:')\n",
    "pp.pprint(contexts)\n",
    "print(kb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0892703-6fa4-4bac-a3b1-7cd30523b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Generated using Anthropic Claude 3 Sonnet:\n",
      "('Yes, it is possible to purchase provisioned throughput for Anthropic Claude '\n",
      " 'Sonnet models on Amazon Bedrock. Specifically, you can purchase provisioned '\n",
      " 'throughput for the following Anthropic Claude Sonnet models:\\n'\n",
      " '\\n'\n",
      " '- Anthropic Claude 3 Sonnet 28K\\n'\n",
      " '- Anthropic Claude 3 Sonnet 200K\\n'\n",
      " '- Anthropic Claude 3.5 Sonnet 18K (only available in US West (Oregon) '\n",
      " 'region)\\n'\n",
      " '- Anthropic Claude 3.5 Sonnet 51K (only available in US West (Oregon) '\n",
      " 'region)\\n'\n",
      " '- Anthropic Claude 3.5 Sonnet 200K (only available in US West (Oregon) '\n",
      " 'region)')\n",
      "---------- The citations for the response:\n",
      "[ 'Virginia)     US West (Oregon)     Asia Pacific (Mumbai)     Asia Pacific '\n",
      "  '(Sydney)     Canada (Central)     Europe (London)     Europe (Paris)     '\n",
      "  'Europe (Ireland)     South America (São Paulo)     AWS GovCloud (US-West) '\n",
      "  '(only for custom models with no commitment)     If you purchase Provisioned '\n",
      "  'Throughput through the Amazon Bedrock API, you must specify a contextual '\n",
      "  'variant of Amazon Bedrock FMs for the model ID. The following table shows '\n",
      "  'the models for which you can purchase Provisioned Throughput, whether you '\n",
      "  'can purchase without commitment for the base model, and the model ID to use '\n",
      "  'when purchasing Provisioned Throughput.     Model name No-commitment '\n",
      "  'purchase supported for base model     Model ID for Provisioned '\n",
      "  'Throughput     Notes     Amazon Titan Text G1 - Express     Yes '\n",
      "  'amazon.titan-text- express-v1:0:8k     \\xa0     Supported regions and '\n",
      "  'models 1375Amazon Bedrock User Guide     Model name No-commitment purchase '\n",
      "  'supported for base model     Model ID for Provisioned Throughput     '\n",
      "  'Notes     Amazon Titan Text G1 - Lite     Yes amazon.titan-text- '\n",
      "  'lite-v1:0:4k     \\xa0     Amazon Titan Text Premier (preview)     Yes '\n",
      "  'amazon.titan-text- premier-v1:0:32K     \\xa0     Amazon Titan Embeddings G1 '\n",
      "  '- Text     Yes amazon.titan-embed- text-v1:2:8k     \\xa0     Amazon Titan '\n",
      "  'Embeddings G1 - Text v2     Yes amazon.titan-embed- '\n",
      "  'text-v2:0:8k     \\xa0     Amazon Titan Multimodal Embeddings G1     Yes '\n",
      "  'amazon.titan-embed- image-v1:0     \\xa0     Amazon Titan Image Generator G1 '\n",
      "  'V1     No amazon.titan-image- generator-v1:0     \\xa0     Amazon Titan '\n",
      "  'Image Generator G1 V1 V2     No amazon.titan-image- '\n",
      "  'generator-v2:0     \\xa0     Anthropic Claude v2 18K     Yes '\n",
      "  'anthropic.claude-v 2:0:18k     \\xa0     Anthropic Claude v2 100K     Yes '\n",
      "  'anthropic.claude-v 2:0:100k     \\xa0     Anthropic Claude v2.1 18K     Yes '\n",
      "  'anthropic.claude-v 2:1:18k     \\xa0     Anthropic Claude v2.1 200K     Yes '\n",
      "  'anthropic.claude-v 2:1:200k     \\xa0     Supported regions and models '\n",
      "  '1376Amazon Bedrock User Guide     Model name No-commitment purchase '\n",
      "  'supported for base model     Model ID for Provisioned Throughput     '\n",
      "  'Notes     Anthropic Claude 3 Haiku 48K     Yes anthropic.claude-3- '\n",
      "  'haiku-20240307-v1 :0:48k     \\xa0     Anthropic Claude 3 Haiku 200K     Yes '\n",
      "  'anthropic.claude-3- haiku-20240307-v1 :0:200k     \\xa0     Anthropic Claude '\n",
      "  'Instant v1 100K     Yes anthropic.claude-i nstant-v1:2:100k     \\xa0     '\n",
      "  'Anthropic Claude 3 Sonnet 28K     Yes anthropic.claude-3- sonnet-20240229-v '\n",
      "  '1:0:28k     \\xa0     Anthropic Claude 3 Sonnet 200K     Yes '\n",
      "  'anthropic.claude-3- sonnet-20240229-v 1:0:200k     \\xa0     Anthropic '\n",
      "  'Claude 3.5 Sonnet 18K     Yes anthropic.claude-3-5- sonnet-20240620- '\n",
      "  'v1:0:18k     Only available in US West (Oregon).     Anthropic Claude 3.5 '\n",
      "  'Sonnet 51K     Yes anthropic.claude-3-5- sonnet-20240620- v1:0:51k     Only '\n",
      "  'available in US West (Oregon).     Anthropic Claude 3.5 Sonnet 200K     Yes '\n",
      "  'anthropic.claude-3-5- sonnet-20240620- v1:0:200k     Only available in US '\n",
      "  'West (Oregon).',\n",
      "  'The following steps outline the process of setting up and using Provisioned '\n",
      "  'Throughput.     1. Determine the number of MUs you wish to purchase for a '\n",
      "  'Provisioned Throughput and the amount of time for which you want to commit '\n",
      "  'to using the Provisioned Throughput.     2. Purchase Provisioned Throughput '\n",
      "  'for a base or custom model.     3. After the provisioned model is created, '\n",
      "  'you can use it to run model inference.     Topics     ? Supported region '\n",
      "  'and models for Provisioned Throughput     ? Prerequisites for Provisioned '\n",
      "  'Throughput     ? Purchase a Provisioned Throughput for an Amazon Bedrock '\n",
      "  'model     ? View information about a Provisioned Throughput     ? Modify a '\n",
      "  'Provisioned Throughput     ? Use a Provisioned Throughput with an Amazon '\n",
      "  'Bedrock resource     ? Delete a Provisioned Throughput     ? Code examples '\n",
      "  'for Provisioned Throughput     Supported region and models for Provisioned '\n",
      "  'Throughput     Provisioned Throughput is supported in the following '\n",
      "  'regions:     Supported regions and models 1374Amazon Bedrock User Guide     '\n",
      "  'Region     US East (N. Virginia)     US West (Oregon)     Asia Pacific '\n",
      "  '(Mumbai)     Asia Pacific (Sydney)     Canada (Central)     Europe '\n",
      "  '(London)     Europe (Paris)     Europe (Ireland)     South America (São '\n",
      "  'Paulo)     AWS GovCloud (US-West) (only for custom models with no '\n",
      "  'commitment)     If you purchase Provisioned Throughput through the Amazon '\n",
      "  'Bedrock API, you must specify a contextual variant of Amazon Bedrock FMs '\n",
      "  'for the model ID. The following table shows the models for which you can '\n",
      "  'purchase Provisioned Throughput, whether you can purchase without '\n",
      "  'commitment for the base model, and the model ID to use when purchasing '\n",
      "  'Provisioned Throughput.     Model name No-commitment purchase supported for '\n",
      "  'base model     Model ID for Provisioned Throughput     Notes     Amazon '\n",
      "  'Titan Text G1 - Express     Yes amazon.titan-text- '\n",
      "  'express-v1:0:8k     \\xa0     Supported regions and models 1375Amazon '\n",
      "  'Bedrock User Guide     Model name No-commitment purchase supported for base '\n",
      "  'model     Model ID for Provisioned Throughput     Notes     Amazon Titan '\n",
      "  'Text G1 - Lite     Yes amazon.titan-text- lite-v1:0:4k     \\xa0     Amazon '\n",
      "  'Titan Text Premier (preview)     Yes amazon.titan-text- '\n",
      "  'premier-v1:0:32K     \\xa0     Amazon Titan Embeddings G1 - Text     Yes '\n",
      "  'amazon.titan-embed- text-v1:2:8k     \\xa0     Amazon Titan Embeddings G1 - '\n",
      "  'Text v2     Yes amazon.titan-embed- text-v2:0:8k     \\xa0     Amazon Titan '\n",
      "  'Multimodal Embeddings G1     Yes amazon.titan-embed- '\n",
      "  'image-v1:0     \\xa0     Amazon Titan Image Generator G1 V1     No '\n",
      "  'amazon.titan-image- generator-v1:0     \\xa0     Amazon Titan Image '\n",
      "  'Generator G1 V1 V2     No amazon.titan-image- generator-v2:0     \\xa0     '\n",
      "  'Anthropic Claude v2 18K     Yes anthropic.claude-v 2:0:18k     \\xa0     '\n",
      "  'Anthropic Claude v2 100K     Yes anthropic.claude-v 2:0:100k     \\xa0     '\n",
      "  'Anthropic Claude v2.1 18K     Yes anthropic.claude-v 2:1:18k     \\xa0     '\n",
      "  'Anthropic Claude v2.1 200K     Yes anthropic.claude-v 2:1:200k     \\xa0     '\n",
      "  'Supported regions and models 1376Amazon Bedrock User Guide     Model name '\n",
      "  'No-commitment purchase supported for base model     Model ID for '\n",
      "  'Provisioned Throughput     Notes     Anthropic Claude 3 Haiku 48K     Yes '\n",
      "  'anthropic.claude-3- haiku-20240307-v1 :0:48k     \\xa0     Anthropic Claude '\n",
      "  '3 Haiku 200K     Yes anthropic.claude-3- haiku-20240307-v1 '\n",
      "  ':0:200k     \\xa0     Anthropic Claude Instant v1 100K     Yes '\n",
      "  'anthropic.claude-i nstant-v1:2:100k     \\xa0     Anthropic Claude 3 Sonnet '\n",
      "  '28K     Yes anthropic.claude-3- sonnet-20240229-v 1:0:28k     \\xa0     '\n",
      "  'Anthropic Claude 3 Sonnet 200K     Yes anthropic.claude-3- '\n",
      "  'sonnet-20240229-v 1:0:200k     \\xa0     Anthropic Claude 3.5 Sonnet 18K     '\n",
      "  'Yes anthropic.claude-3-5- sonnet-20240620- v1:0:18k     Only available in '\n",
      "  'US West (Oregon).']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Is it possible to purchase provisioned throughput for Anthropic Claude Sonnet on Amazon Bedrock?\"\n",
    "\n",
    "response = ask_bedrock_llm_with_knowledge_base(query, kb_id)\n",
    "generated_text = response['output']['text']\n",
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "        contexts.append(reference[\"content\"][\"text\"])\n",
    "print(f\"---------- Generated using Anthropic Claude 3 Sonnet:\")\n",
    "pp.pprint(generated_text )\n",
    "print(f'---------- The citations for the response:')\n",
    "pp.pprint(contexts)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0f09-2ecf-40c5-9dd2-1c42a7af6231",
   "metadata": {},
   "source": [
    "# Contextual Grounding with Amazon Bedrock Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "810e1acf-ddbe-4e93-bf96-32e7282a7db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrock-rag-grounding-guardrail-l2ad2e45\n"
     ]
    }
   ],
   "source": [
    "# Create guardrail\n",
    "bedrock_client = boto3.client('bedrock')\n",
    "guardrail_name = f\"bedrock-rag-grounding-guardrail-{random_id}\"\n",
    "print(guardrail_name)\n",
    "guardrail_response = bedrock_client.create_guardrail(\n",
    "    name=guardrail_name,\n",
    "    description='Guardrail for ensuring relevance and grounding of model responses in RAG powered chatbot',\n",
    "    contextualGroundingPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {\n",
    "                'type': 'GROUNDING',\n",
    "                'threshold': 0.5\n",
    "            },\n",
    "            {\n",
    "                'type': 'RELEVANCE',\n",
    "                'threshold': 0.5\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging='Can you please rephrase your question?',\n",
    "    blockedOutputsMessaging='Sorry, I am not able to find the correct answer to your query - Can you try reframing your query to be more specific'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d615898-b2a3-4b8c-8830-f6710fc86ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '8d13ae15-11c1-4baa-9cf5-850bb9bf54d5',\n",
       "  'HTTPStatusCode': 202,\n",
       "  'HTTPHeaders': {'date': 'Wed, 13 Nov 2024 20:40:26 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '172',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '8d13ae15-11c1-4baa-9cf5-850bb9bf54d5'},\n",
       "  'RetryAttempts': 0},\n",
       " 'guardrailId': '5qsclikqvcxn',\n",
       " 'guardrailArn': 'arn:aws:bedrock:us-west-2:996757723911:guardrail/5qsclikqvcxn',\n",
       " 'version': 'DRAFT',\n",
       " 'createdAt': datetime.datetime(2024, 11, 13, 20, 40, 26, 553590, tzinfo=tzlocal())}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guardrailId = guardrail_response['guardrailId']\n",
    "guardrail_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a503292a-b84c-46d5-8fe2-f9d199198f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '501376b1-218d-4d0b-9aff-a57a9a42444b', 'HTTPStatusCode': 202, 'HTTPHeaders': {'date': 'Wed, 13 Nov 2024 20:40:27 GMT', 'content-type': 'application/json', 'content-length': '44', 'connection': 'keep-alive', 'x-amzn-requestid': '501376b1-218d-4d0b-9aff-a57a9a42444b'}, 'RetryAttempts': 0}, 'guardrailId': '5qsclikqvcxn', 'version': '1'}\n",
      "5qsclikqvcxn\n",
      "Stored 'guardrailId' (str)\n"
     ]
    }
   ],
   "source": [
    "guardrail_version = bedrock_client.create_guardrail_version(\n",
    "    guardrailIdentifier=guardrail_response['guardrailId'],\n",
    "    description='Working version of RAG app guardrail with higher thresholds for contextual grounding'\n",
    ")\n",
    "print(guardrail_version)\n",
    "guardrailVersion = guardrail_response['version']\n",
    "print(guardrailId)\n",
    "%store guardrailId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0dfbd6ac-6411-47dd-b645-33df81614878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and Generate using Guardrail\n",
    "\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "\n",
    "def retrieve_and_generate_with_guardrail(\n",
    "    query,\n",
    "    kb_id,\n",
    "    model_arn=llm_model_id,\n",
    "    session_id=None\n",
    "):\n",
    "\n",
    "    prompt_template = 'You are a helpful AI assistant to help users understand documented risks in various projects. \\\n",
    "    Answer the user query based on the context retrieved. If you dont know the answer, dont make up anything. \\\n",
    "    Only answer based on what you know from the provided context. You can ask the user for clarifying questions if anything is unclear\\\n",
    "    But generate an answer only when you are confident about it and based on the provided context.\\\n",
    "    User Query: $query$\\\n",
    "    Context: $search_results$'\n",
    "\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\n",
    "            'text': query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'generationConfiguration': {\n",
    "                    'guardrailConfiguration': {\n",
    "                        'guardrailId': guardrailId,\n",
    "                        'guardrailVersion': guardrailVersion\n",
    "                    },\n",
    "                    'inferenceConfig': {\n",
    "                        'textInferenceConfig': {\n",
    "                            'temperature': 0.7,\n",
    "                            'topP': 0.25\n",
    "                        }\n",
    "                    },\n",
    "                    'promptTemplate': {\n",
    "                        'textPromptTemplate': prompt_template\n",
    "                    }\n",
    "                },\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': model_arn,\n",
    "                'retrievalConfiguration': {\n",
    "                    'vectorSearchConfiguration': {\n",
    "                        'overrideSearchType': 'SEMANTIC'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6f710a5-74c9-4480-8308-e9b362730428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'c527ebad-1b09-45e7-9ed3-2c6fb0e059ae', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 13 Nov 2024 20:40:36 GMT', 'content-type': 'application/json', 'content-length': '1383', 'connection': 'keep-alive', 'x-amzn-requestid': 'c527ebad-1b09-45e7-9ed3-2c6fb0e059ae'}, 'RetryAttempts': 0}, 'citations': [], 'guardrailAction': 'NONE', 'output': {'text': 'According to the context provided, Amazon Bedrock is a fully managed service from AWS that provides access to high-performing foundation models (FMs) from leading AI companies and Amazon through a unified API.\\n\\nSome key points about Amazon Bedrock:\\n\\n- It allows you to choose from a wide range of foundation models to find the best one for your use case.\\n- It offers capabilities to build generative AI applications with security, privacy, and responsible AI principles.\\n- You can experiment with and evaluate different foundation models, privately customize them with your own data using techniques like fine-tuning and retrieval augmented generation (RAG).\\n- You can build agents that use foundation models, make API calls, and query knowledge bases to reason through and carry out tasks.\\n- It provides a serverless experience where you can get started quickly without managing infrastructure.\\n- You only pay for the services you use, with pricing based on input/output tokens and whether you purchase provisioned throughput for a model.\\n\\nSo in summary, Amazon Bedrock is an AWS service that gives developers access to state-of-the-art foundation models from multiple providers through a unified API and set of tools for building generative AI applications.'}, 'sessionId': 'b6c32625-9905-4fef-bf96-a77e90cda7eb'}\n"
     ]
    }
   ],
   "source": [
    "# Knowledge BAse ID\n",
    "\n",
    "query = 'What is Amazon Bedrock?'\n",
    "#query = \"Is it possible to purchase provisioned throughput for Anthropic Claude Sonnet on Amazon Bedrock?\"\n",
    "\n",
    "model_response = retrieve_and_generate_with_guardrail(query, kb_id)\n",
    "\n",
    "print(model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56677a75-464c-453b-b2bd-7813f2a65d1a",
   "metadata": {},
   "source": [
    "# Evaluating RAG with RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e33826a-0836-4ad1-9553-dcb7df3f87c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3982/422286211.py:22: LangChainDeprecationWarning: The class `BedrockEmbeddings` was deprecated in LangChain 0.2.11 and will be removed in 1.0. An updated version of the class exists in the langchain-aws package and should be used instead. To use it run `pip install -U langchain-aws` and import as `from langchain_aws import BedrockEmbeddings`.\n",
      "  bedrock_embeddings = BedrockEmbeddings(model_id=embedding_model_id,client=bedrock_client)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain_community.chat_models.bedrock import BedrockChat\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config\n",
    "                              )\n",
    "\n",
    "llm_for_text_generation = BedrockChat(model_id=llm_model_id, client=bedrock_client)\n",
    "\n",
    "llm_for_evaluation = BedrockChat(model_id=llm_model_id, client=bedrock_client)\n",
    "\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=embedding_model_id,client=bedrock_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3511743-c8c2-4e3c-949a-79bf9bec79cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question/prompt</th>\n",
       "      <th>Correct answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are all models accessible on Amazon Bedrock by default?</td>\n",
       "      <td>Access to Amazon Bedrock foundation models isn't granted by default. You can request access, or modify access, to foundation models only by using the Amazon Bedrock console. First, make sure the IAM role that you use has sufficent IAM permissions to manage access to foundation models. Then, add or remove access to a model by following the instructions at Add or remove access to Amazon Bedrock foundation models.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Model ID of Amazon Titan Text Premier</td>\n",
       "      <td>amazon.titan-text-premier-v1:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With which Anthropic Claude models can I use the Text Completions API?</td>\n",
       "      <td>Anthropic Claude Instant v1.2, Anthropic Claude v2, Anthropic Claude v2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What policies can I configure in Amazon Bedrock guardrails?</td>\n",
       "      <td>You can configure the following policies in a guardrail to avoid undesirable and harmful content and remove sensitive information for privacy protection. Content filters – Adjust filter strengths to block input prompts or model responses containing harmful content.<br>Denied topics – Define a set of topics that are undesirable in the context of your application. These topics will be blocked if detected in user queries or model responses.<br>Word filters – Configure filters to block undesirable words, phrases, and profanity. Such words can include offensive terms, competitor names etc.<br>Sensitive information filters – Block or mask sensitive information such as personally identifiable information (PII) or custom regex in user inputs and model responses.<br>Contextual grounding check – Detect and filter hallucinations in model responses based on grounding in a source and relevance to the user query.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which built in datasets are available on Amazon Bedrock for model evaluation of text generation?</td>\n",
       "      <td>The following built-in datasets contain prompts that are well-suited for use in general text generation tasks. Bias in Open-ended Language Generation Dataset (BOLD)<br>The Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.<br><br>RealToxicityPrompts<br>RealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.<br><br>T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)<br>TREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".<br><br>WikiText2<br>WikiText2 is a HuggingFace dataset that contains prompts used in general text generation.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('data/bedrock-user-guide-test.csv')\n",
    "test = test.dropna()\n",
    "test.style.set_properties(**{'text-align': 'left', 'border': '1px solid black'})\n",
    "test.to_string(justify='left', index=False)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    pretty_print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0a5f15a-8053-4edc-97e5-c6b96641c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = test['Question/prompt'].tolist()\n",
    "ground_truths = [[gt] for gt in test['Correct answer'].tolist()]\n",
    "\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    response = ask_bedrock_llm_with_knowledge_base(query, kb_id)\n",
    "    generatedResult = response['output']['text']\n",
    "    answers.append(generatedResult)\n",
    "    contexts.append([doc['content']['text'] for doc in response['citations'][0]['retrievedReferences']])\n",
    "\n",
    "# To dict\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e67dd3e8-eeaf-4285-a16e-00347089b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.25.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.15.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install datasets -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe7cfc0-2dd6-4b8e-9caf-e4f03d705ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets                                3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16eb532-3c65-4adf-b6f2-cab77d11cc81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_entity_recall,\n",
    "    answer_similarity,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "#specify the metrics here, kept one for now, we can add more.\n",
    "metrics = [\n",
    "        answer_relevancy\n",
    "    ]\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=metrics,\n",
    "    llm=llm_for_evaluation,\n",
    "    embeddings=bedrock_embeddings,\n",
    "    raise_exceptions=False\n",
    ")\n",
    "\n",
    "ragas_df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c76503a5-36de-4365-a390-a37dba57c439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are all models accessible on Amazon Bedrock by default?</td>\n",
       "      <td>[aws-marketplace:Unsubscribe     ? aws-marketplace:ViewSubscriptions     For information creating the policy, see I already have an AWS account.     For the aws-marketplace:Subscribe action only, you can use the aws- marketplace:ProductId condition key to restrict subscription to specific models.     Grant permissions to request access to foundation models 29           https://aws.amazon.com/bedrock/pricing/         https://docs.aws.amazon.com/service-authorization/latest/reference/list_awsmarketplace.html#awsmarketplace-actions-as-permissions         https://docs.aws.amazon.com/service-authorization/latest/reference/list_awsmarketplace.html#awsmarketplace-policy-keysAmazon Bedrock User Guide     Note     You can't remove request access from the Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models. You can prevent users from making inference calls to these models by using an IAM policy and specifying the model ID. For more information, see Deny access for inference on specific models.     The following table lists product IDs for Amazon Bedrock foundation models:     The following is the format of the IAM policy you can attach to a role to control model access permissions:     Model Product ID     AI21 Labs Jurassic-2 Mid 1d288c71-65f9-489a-a3e2-9c7f4f6e6a85     AI21 Labs Jurassic-2 Ultra cc0bdd50-279a-40d8-829c-4009b77a1fcc     AI21 Jamba-Instruct prod-dr2vpvd4k73aq     AI21 Labs Jamba 1.5 Large prod-evcp4w4lurj26     AI21 Labs Jamba 1.5 Mini prod-ggrzjm65qmjhm     Anthropic Claude c468b48a-84df-43a4-8c46-8870630108a7     Anthropic Claude Instant b0eb9475-3a2c-43d1-94d3-56756fd43737     Anthropic Claude 3 Sonnet prod-6dw3qvchef7zy     Anthropic Claude 3.5 Sonnet prod-m5ilt4siql27k     Anthropic Claude 3.5 Sonnet v2 prod-cx7ovbu5wex7g     Anthropic Claude 3 Haiku prod-ozonys2hmmpeu     Anthropic Claude 3.5 Haiku prod-5oba7y7jpji56     Anthropic Claude 3 Opus prod-fm3feywmwerog     Grant permissions to request access to foundation models 30Amazon Bedrock User Guide     Model Product ID     Cohere Command a61c46fe-1747-41aa-9af0-2e0ae8a9ce05     Cohere Command Light 216b69fd-07d5-4c7b-866b-936456d68311     Cohere Command R prod-tukx4z3hrewle     Cohere Command R+ prod-nb4wqmplze2pm     Cohere Embed (English) b7568428-a1ab-46d8-bab3-37def50f6f6a     Cohere Embed (Multilingual) 38e55671-c3fe-4a44-9783-3584906e7cad     Stable Diffusion XL 1.0 prod-2lvuzn4iy6n6o     Stable Image Core 1.0 prod-eacdrmv7zfc5e     Stable Diffusion 3 Large 1.0 prod-cqfmszl26sxu4     Stable Image Ultra 1.0 prod-7boen2z2wnxrg     { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow|Deny\", \"Action\": [ \"aws-marketplace:Subscribe\" ], \"Resource\": \"*\", \"Condition\": { \"ForAnyValue:StringEquals\": { \"aws-marketplace:ProductId\": [ model-product-id-1, model-product-id-2, ... ] } } },     Grant permissions to request access to foundation models 31Amazon Bedrock User Guide      { \"Effect\": \"Allow|Deny\", \"Action\": [ \"aws-marketplace:Unsubscribe\" \"aws-marketplace:ViewSubscriptions\" ], \"Resource\": \"*\" } ] }     To see an example policy, refer to Allow access to third-party model subscriptions.     Add or remove access to Amazon Bedrock foundation models     Before you can use a foundation model in Amazon Bedrock, you must request access to it. If you no longer need access to a model, you can remove access from it.     Note     You can't remove request access from the Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models., Once access is provided to a model, it is available for all users in the AWS account.     To add or remove access to foundation models     1. Make sure you have permissions to request access, or modify access, to Amazon Bedrock foundation models.     2. Sign into the Amazon Bedrock console at https://console.aws.amazon.com/bedrock/.     3. In the left navigation pane, under Bedrock configurations, choose Model access.     4. On the Model access page, choose Modify model access.     5. Select the models that you want the account to have access to and unselect the models that you don't want the account to have access to. You have the following options:     Add or remove access to foundation models 32           https://console.aws.amazon.com/bedrock/Amazon Bedrock User Guide     Be sure to review the End User License Agreement (EULA) for terms and conditions of using a model before requesting access to it.     ? Select the check box next to an individual model to check or uncheck it.     ? Select the top check box to check or uncheck all models.     ? Select how the models are grouped and then check or uncheck all the models in a group by selecting the check box next to the group. For example, you can choose to Group by provider and then select the check box next to Cohere to check or uncheck all Cohere models.     6. Choose Next.     7. If you add access to Anthropic models, you must describe your use case details. Choose Submit use case details, fill out the form, and then select Submit form. Notification of access is granted or denied based on your answers when completing the form for the provider.     8. Review the access changes you're making, and then read the Terms.     Note     Your use of Amazon Bedrock foundation models is subject to the seller's pricing terms, EULA, and the AWS service terms.     9. If you agree with the terms, choose Submit. The changes can take several minutes to be reflected in the console.     Note     If you revoke access to a model, it can still be accessed through the API for some time after you complete this action while the changes propagate. To immediately remove access in the meantime, add an IAM policy to a role to deny access to the model.     10. If your request is successful, the Access status changes to Access granted or Available to request.     Note     For AWS GovCloud (US) customers, follow these steps to access models that are available in AWS GovCloud (US):     Add or remove access to foundation models 33           https://aws.amazon.com/bedrock/pricing/         https://aws.amazon.com/service-termsAmazon Bedrock User Guide     ? AWS GovCloud (US) users must locate their standard AWS account ID associated with their AWS GovCloud (US) account ID. AWS GovCloud (US) users can follow this guide Finding your associated standard AWS account ID, if they don't already know their ID. Navigate to the model access page on Amazon Bedrock console. Select the model(s) that you want to enable. Select Request model access and follow the step-by-step subscription flow.     ? AWS GovCloud (US) customers use their standard AWS account ID (which is linked to their AWS GovCloud (US) account ID) to first enable model access. Navigate to the model access page on Amazon Bedrock console in either us-east-1 or us-west-2. Select the model(s) that you want to enable. Select Request model access and follow the step-by- step subscription flow.     ? Log into your AWS GovCloud (US) account and navigate to Amazon Bedrock in us-gov- west-1 and follow the same model access sign-up steps. This will grant you a regional entitlement to access the models in us-gov-west-1.     ? The model will be accessible to the linked AWS GovCloud (US) account on us-gov- west-1.     If you don't have permissions to request access to a model, an error banner appears. Contact your account administrator to ask them to request access to the model for you or to provide you permissions to request access to the model.     Add or remove access to foundation models 34           https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/govcloud-account-ID-alias.html#find-standard-idAmazon Bedrock User Guide     Amazon Bedrock foundation model information     A foundation model is an Artificial Intellgence model with a large number of parameters and trained on a massive amount of diverse data. A foundation model can generate a variety of responses for a wide range of use cases. Foundation models can generate text or image, and can also convert input into embeddings. This section provides information about the foundation models (FM) that you can use in Amazon Bedrock, such as the features that models support and the AWS regions in which models are available.]</td>\n",
       "      <td>No, not all models are accessible on Amazon Bedrock by default. Before you can use a foundation model in Amazon Bedrock, you must request access to it. Some models require you to go through an approval process before access is granted. You cannot remove access from certain models like Amazon Titan, Mistral AI, and Meta Llama 3 Instruct models. However, you can prevent users from making inference calls to these models by using an IAM policy and specifying the model ID.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Model ID of Amazon Titan Text Premier</td>\n",
       "      <td>[Amazon Titan Text Embeddings models     ? Amazon Titan Multimodal Embeddings G1 model     ? Amazon Titan Image Generator G1 models     Amazon Titan Text models     Amazon Titan text models include Amazon Titan Text G1 - Premier, Amazon Titan Text G1 - Express and Amazon Titan Text G1 - Lite.     Amazon Titan Text G1 - Premier     Amazon Titan Text G1 - Premier is a large language model for text generation. It is useful for a wide range of tasks including open-ended and context-based question answering, code generation, and summarization. This model is integrated with Amazon Bedrock Knowledge Base and Amazon Bedrock Agents. The model also supports Custom Finetuning in preview.     ? Model ID ? amazon.titan-text-premier-v1:0     ? Max tokens ? 32K     ? Languages ? English     Amazon Titan Text 1399Amazon Bedrock User Guide     ? Supported use cases ? 32k context window, open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, chat, Knowledge Base support, Agents support, Model Customization (preview).     ? Inference parameters ? Temperature, Top P (defaults: Temperature = 0.7, Top P = 0.9)     AWS AI Service Card - Amazon Titan Text Premier     Amazon Titan Text G1 - Express     Amazon Titan Text G1 - Express is a large language model for text generation. It is useful for a wide range of advanced, general language tasks such as open-ended text generation and conversational chat, as well as support within Retrieval Augmented Generation (RAG). At launch, the model is optimized for English, with multilingual support for more than 30 additional languages available in preview.     ? Model ID ? amazon.titan-text-express-v1     ? Max tokens ? 8K     ? Languages ? English (GA), 100 additional languages (Preview)     ? Supported use cases ? Retrieval augmented generation, open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, and chat.     Amazon Titan Text G1 - Lite     Amazon Titan Text G1 - Lite is a light weight efficient model, ideal for fine-tuning of English- language tasks, including like summarizations and copy writing, where customers want a smaller, more cost-effective model that is also highly customizable.     ? Model ID ? amazon.titan-text-lite-v1     ? Max tokens ? 4K     ? Languages ? English     ? Supported use cases ? Open-ended text generation, brainstorming, summarizations, code generation, table creation, data formatting, paraphrasing, chain of thought, rewrite, extraction, QnA, and chat.     Amazon Titan Text G1 - Express 1400           https://aws.amazon.com/machine-learning/responsible-machine-learning/titan-text-premier/Amazon Bedrock User Guide     Amazon Titan Text Model Customization     For more information on customizing Amazon Titan text models, see the following pages.     ? Prepare the datasets     ? Amazon Titan text model customization hyperparameters     Amazon Titan Text Prompt Engineering Guidelines     Amazon Titan text models can be used in a wide variety of applications for different use cases. Amazon Titan Text models have prompt engineering guidelines for the following applications including:     ? Chatbot     ? Text2SQL     ? Function Calling     ? RAG (Retrieval Augmented Generation)     For more information on Amazon Titan Text prompt engineering guidelines, see Amazon Titan Text Prompt Engineering Guidelines.     For general prompt engineering guidelines, see Prompt Engineering Guidelines.     AWS AI Service Card - Amazon Titan Text     AI Service Cards provide transparency and document the intended use cases and fairness considerations for our AWS AI services. AI Service Cards provide a single place to find information on the intended use cases, responsible AI design choices, best practices, and performance for a set of AI service use cases.     Amazon Titan Text Embeddings models     Amazon Titan Embeddings text models include Amazon Titan Text Embeddings v2 and Titan Text Embeddings G1 model.     Text embeddings represent meaningful vector representations of unstructured text such as documents, paragraphs, and sentences. You input a body of text and the output is a (1 x n) vector. You can use embedding vectors for a wide variety of applications.]</td>\n",
       "      <td>The Model ID of Amazon Titan Text Premier is amazon.titan-text-premier-v1:0.</td>\n",
       "      <td>0.995229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With which Anthropic Claude models can I use the Text Completions API?</td>\n",
       "      <td>[Anthropic Claude 3 model, such as Anthropic Claude 3 Opus     For information about creating system prompts, see https://docs.anthropic.com/claude/ docs/how-to-use-system-prompts in the Anthropic Claude documentation. To avoid timeouts with Anthropic Claude version 2.1, we recommend limiting the input token count in the prompt field to 180K. We expect to address this timeout issue soon.     In the inference call, fill the body field with a JSON object that conforms the type call you want to make, Anthropic Claude Text Completions API or Anthropic Claude Messages API.     Topics     ? Anthropic Claude Text Completions API     ? Anthropic Claude Messages API     Anthropic Claude models 131           https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview         https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags         https://docs.anthropic.com/en/docs/welcome         https://docs.anthropic.com/claude/docs/how-to-use-system-prompts         https://docs.anthropic.com/claude/docs/how-to-use-system-promptsAmazon Bedrock User Guide     Anthropic Claude Text Completions API     This section provides inference parameters and code examples for using Anthropic Claude models with the Text Completions API.     Topics     ? Anthropic Claude Text Completions API overview     ? Supported models     ? Request and Response     ? Code example     Anthropic Claude Text Completions API overview     Use the Text Completion API for single-turn text generation from a user supplied prompt. For example, you can use the Text Completion API to generate text for a blog post or to summarize text input from a user.     For information about creating prompts for Anthropic Claude models, see Introduction to prompt design. If you want to use your existing Text Completions prompts with the Anthropic Claude Messages API, see Migrating from Text Completions.     Supported models     You can use the Text Completions API with the following Anthropic Claude models.     ? Anthropic Claude Instant v1.2     ? Anthropic Claude v2     ? Anthropic Claude v2.1     Request and Response     The request body is passed in the body field of a request to InvokeModel or InvokeModelWithResponseStream.     For more information, see https://docs.anthropic.com/claude/reference/complete_post in the Anthropic Claude documentation.     Anthropic Claude models 132           https://docs.anthropic.com/claude/docs/introduction-to-prompt-design         https://docs.anthropic.com/claude/docs/introduction-to-prompt-design         https://docs.anthropic.com/claude/reference/migrating-from-text-completions-to-messages         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html         https://docs.anthropic.com/claude/reference/complete_postAmazon Bedrock User Guide     Request     Anthropic Claude has the following inference parameters for a Text Completion inference call.     { \"prompt\": \"<br><br>Human:&lt;prompt&gt;<br><br>Assistant:\", \"temperature\": float, \"top_p\": float, \"top_k\": int, \"max_tokens_to_sample\": int, \"stop_sequences\": [string] }     The following are required parameters.     ? prompt ? (Required) The prompt that you want Claude to complete. For proper response generation you need to format your prompt using alternating <br><br>Human: and <br> <br>Assistant: conversational turns. For example:     \"<br><br>Human: {userQuestion}<br><br>Assistant:\"     For more information, see Prompt validation in the Anthropic Claude documentation.     ? max_tokens_to_sample ? (Required) The maximum number of tokens to generate before stopping. We recommend a limit of 4,000 tokens for optimal performance.     Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens_to_sample. Different Anthropic Claude models have different maximum values for this parameter. For more information, see Model comparison in the Anthropic Claude documentation.     Default Minimum Maximum     200 0 4096     The following are optional parameters.     ? stop_sequences ? (Optional) Sequences that will cause the model to stop generating.     Anthropic Claude models 133           https://docs.anthropic.com/claude/reference/prompt-validation         https://docs.anthropic.com/claude/docs/models-overview#model-comparisonAmazon Bedrock User Guide     Anthropic Claude models stop on \"<br><br>Human:\", and may include additional built-in stop sequences in the future. Use the stop_sequences inference parameter to include additional strings that will signal the model to stop generating text.     ? temperature ?]</td>\n",
       "      <td>You can use the Text Completions API with the following Anthropic Claude models:<br>- Anthropic Claude Instant v1.2<br>- Anthropic Claude v2<br>- Anthropic Claude v2.1</td>\n",
       "      <td>0.676724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What policies can I configure in Amazon Bedrock guardrails?</td>\n",
       "      <td>[Specify DENY in the action field.     ? (Optional) Provide up to five examples that you would categorize as belonging to the topic in the examples list.     ? Specify filter strengths for the harmful categories defined in Amazon Bedrock in the contentPolicy object. Each item in the filters list pertains to a harmful category. For more information, see Block harmful words and conversations with content filters. For more information about the fields in a content filter, see ContentFilter.     ? Specify the category in the type field.     ? Specify the strength of the filter for prompts in the strength field of the textToTextFiltersForPrompt field and for model responses in the strength field of the textToTextFiltersForResponse.     ? (Optional) Attach any tags to the guardrail. For more information, see Tagging Amazon Bedrock resources.     ? (Optional) For security, include the ARN of a KMS key in the kmsKeyId field.     The response format is as follows:     HTTP/1.1 202 Content-type: application/json     { \"createdAt\": \"string\", \"guardrailArn\": \"string\", \"guardrailId\": \"string\", \"version\": \"string\" }     Create a guardrail 464           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Topic.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_ContentFilter.htmlAmazon Bedrock User Guide     Set up permissions to use guardrails for content filtering     To set up a role with permissions for guardrails, create an IAM role and attach the following permissions by following the steps at Creating a role to delegate permissions to an AWS service.     If you are using guardrails with an agent, attach the permissions to a service role with permissions to create and manage agents. You can set up this role in the console or create a custom role by following the steps at Create a service role for Amazon Bedrock Agents.     ? Permissions to invoke guardrails with foundation models     ? Permissions to create and manage guardrails     ? (Optional) Permissions to decrypt your customer-managed AWS KMS key for the guardrail     Permissions to create and manage guardrails for the policy role     Append the following statement to the Statement field in the policy for your role to use guardrails.     { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"CreateAndManageGuardrails\", \"Effect\": \"Allow\", \"Action\": [ \"bedrock:CreateGuardrail\", \"bedrock:CreateGuardrailVersion\", \"bedrock:DeleteGuardrail\", \"bedrock:GetGuardrail\", \"bedrock:ListGuardrails\", \"bedrock:UpdateGuardrail\" ], \"Resource\": \"*\" } ] }     Permissions for Amazon Bedrock Guardrails 465           https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.htmlAmazon Bedrock User Guide     Permissions you need to invoke guardrails to filter content     Append the following statement to the Statement field in the policy for the role to allow for model inference and to invoke guardrails.     { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"InvokeFoundationModel\", \"Effect\": \"Allow\", \"Action\": [ \"bedrock:InvokeModel\", \"bedrock:InvokeModelWithResponseStream\" ], \"Resource\": [ \"arn:aws:bedrock:region::foundation-model/*\" ] }, { \"Sid\": \"ApplyGuardrail\", \"Effect\": \"Allow\", \"Action\": [ \"bedrock:ApplyGuardrail\" ], \"Resource\": [ \"arn:aws:bedrock:region:account-id:guardrail/guardrail-id\" ] } ] }     (Optional) Create a customer managed key for your guardrail for additional security     Any user with CreateKey permissions can create customer managed keys using either the AWS Key Management Service (AWS KMS) console or the CreateKey operation. Make sure to create a symmetric encryption key. After you create your key, set up the following permissions.     Permissions you need to invoke guardrails to filter content 466           https://docs.aws.amazon.com/kms/latest/APIReference/API_CreateKey.htmlAmazon Bedrock User Guide     1. Follow the steps at Creating a key policy to create a resource-based policy for your KMS key. Add the following policy statements to grant permissions to guardrails users and guardrails creators. Replace each role with the role that you want to allow to carry out the specified actions., b. In the Relevance field, select Enable relevance check to check if model responses are relevant..     c. Select Next.     10. Review and create ? Review the settings for your guardrail.     a. Select Edit in any section you want to make changes to.     b. When you are satisfied with the settings for your guardrail, select Create to create the guardrail.     API     To create a guardrail, send a CreateGuardrail request. The request format is as follows:     POST /guardrails HTTP/1.1 Content-type: application/json     { \"blockedInputMessaging\": \"string\", \"blockedOutputsMessaging\": \"string\", \"contentPolicyConfig\": { \"filtersConfig\": [ { \"inputStrength\": \"NONE | LOW | MEDIUM | HIGH\", \"outputStrength\": \"NONE | LOW | MEDIUM | HIGH\", \"type\": \"SEXUAL | VIOLENCE | HATE | INSULTS | MISCONDUCT | PROMPT_ATTACK\" } ] }, \"wordPolicyConfig\": { \"wordsConfig\": [     Create a guardrail 462           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_CreateGuardrail.htmlAmazon Bedrock User Guide      { \"text\": \"string\" } ], \"managedWordListsConfig\": [ { \"type\": \"string\" } ] }, \"sensitiveInformationPolicyConfig\": { \"piiEntitiesConfig\": [ { \"type\": \"string\", \"action\": \"string\" } ], \"regexesConfig\": [ { \"name\": \"string\", \"description\": \"string\", \"regex\": \"string\", \"action\": \"string\" } ] }, \"description\": \"string\", \"kmsKeyId\": \"string\", \"name\": \"string\", \"tags\": [ { \"key\": \"string\", \"value\": \"string\" } ], \"topicPolicyConfig\": { \"topicsConfig\": [ { \"definition\": \"string\", \"examples\": [ \"string\" ], \"name\": \"string\", \"type\": \"DENY\" } ]     Create a guardrail 463Amazon Bedrock User Guide      } }     ? Specify a name and description for the guardrail.     ? Specify messages for when the guardrail successfully blocks a prompt or a model response in the blockedInputMessaging and blockedOutputsMessaging fields.     ? Specify topics for the guardrail to deny in the topicPolicy object. Each item in the topics list pertains to one topic. For more information about the fields in a topic, see Topic.     ? Give a name and description so that the guardrail can properly identify the topic.     ? Specify DENY in the action field.     ? (Optional) Provide up to five examples that you would categorize as belonging to the topic in the examples list.     ? Specify filter strengths for the harmful categories defined in Amazon Bedrock in the contentPolicy object. Each item in the filters list pertains to a harmful category. For more information, see Block harmful words and conversations with content filters. For more information about the fields in a content filter, see ContentFilter.     ? Specify the category in the type field.     ? Specify the strength of the filter for prompts in the strength field of the textToTextFiltersForPrompt field and for model responses in the strength field of the textToTextFiltersForResponse.     ? (Optional) Attach any tags to the guardrail. For more information, see Tagging Amazon Bedrock resources.     ? (Optional) For security, include the ARN of a KMS key in the kmsKeyId field.     The response format is as follows:     HTTP/1.1 202 Content-type: application/json     { \"createdAt\": \"string\", \"guardrailArn\": \"string\", \"guardrailId\": \"string\", \"version\": \"string\" }     Create a guardrail 464           https://docs.aws.amazon.com/bedrock/latest/APIReference/API_Topic.html         https://docs.aws.amazon.com/bedrock/latest/APIReference/API_ContentFilter.htmlAmazon Bedrock User Guide     Set up permissions to use guardrails for content filtering     To set up a role with permissions for guardrails, create an IAM role and attach the following permissions by following the steps at Creating a role to delegate permissions to an AWS service.     If you are using guardrails with an agent, attach the permissions to a service role with permissions to create and manage agents. You can set up this role in the console or create a custom role by following the steps at Create a service role for Amazon Bedrock Agents.     ? Permissions to invoke guardrails with foundation models     ? Permissions to create and manage guardrails     ? (Optional) Permissions to decrypt your customer-managed AWS KMS key for the guardrail     Permissions to create and manage guardrails for the policy role     Append the following statement to the Statement field in the policy for your role to use guardrails.]</td>\n",
       "      <td>In Amazon Bedrock guardrails, you can configure the following policies:<br><br>1. Content filters: You can specify filter strengths for harmful categories like sexual content, violence, hate speech, insults, misconduct, and prompt attacks.<br><br>2. Topic policy: You can specify topics to deny, provide a definition and examples for each topic.<br><br>3. Word policy: You can specify custom words or managed word lists (e.g. profanity) to block.<br><br>4. Sensitive information policy: You can specify personally identifiable information (PII) entities like addresses, ages, etc. to block or anonymize, and regular expressions to match sensitive information.</td>\n",
       "      <td>0.996602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which built in datasets are available on Amazon Bedrock for model evaluation of text generation?</td>\n",
       "      <td>[It contains 23,679 different text generation prompts.     RealToxicityPrompts     RealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.     T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)     TREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".     Model evaluation task types 533Amazon Bedrock User Guide     WikiText2     WikiText2 is a HuggingFace dataset that contains prompts used in general text generation.     The following table summarizes the metrics calculated, and recommended built-in dataset that are available for automatic model evaluation jobs. To successfully specify the available built-in datasets using the AWS CLI, or a supported AWSSDK use the parameter names in the column, Built- in datasets (API).     Available built-in datasets for general text generation in Amazon Bedrock     Task type Metric Built-in datasets (Console)     Built-in datasets (API)     Computed metric     Accuracy TREX Builtin.T-REx Real world knowledge (RWK) score     BOLD Builtin.BOLD     WikiText2 Builtin.W ikiText2     Robustnes s     TREX Builtin.T-REx     Word error rate     RealToxicityPrompts Builtin.R ealToxici tyPrompts     General text generation     Toxicity     BOLD Builtin.Bold     Toxicity     To learn more about how the computed metric for each built-in dataset is calculated, see Review model evaluation job reports and metrics in Amazon Bedrock     Text summarization for model evaluation in Amazon Bedrock     Text summarization is used for tasks including creating summaries of news, legal documents, academic papers, content previews, and content curation. The ambiguity, coherence, bias, and     Model evaluation task types 534           https://hadyelsahar.github.io/t-rex/         https://github.com/amazon-science/bold         https://huggingface.co/datasets/wikitext         https://hadyelsahar.github.io/t-rex/         https://github.com/allenai/real-toxicity-prompts         https://github.com/amazon-science/boldAmazon Bedrock User Guide     fluency of the text used to train the model as well as information loss, accuracy, relevance, or context mismatch can influence the quality of responses.     Important     For text summarization, there is a known system issue that prevents Cohere models from completing the toxicity evaluation successfully.     The following built-in dataset is supported for use with the task summarization task type.     Gigaword     The Gigaword dataset consists of news article headlines. This dataset is used in text summarization tasks.     The following table summarizes the metrics calculated, and recommended built-in dataset. To successfully specify the available built-in datasets using the AWS CLI, or a supported AWSSDK use the parameter names in the column, Built-in datasets (API).     Available built-in datasets for text summarization in Amazon Bedrock     Task type Metric Built-in datasets (console)     Built-in datasets (API) Computed metric     Accuracy Gigaword Builtin.Gigaword BERTScore     Toxicity Gigaword Builtin.Gigaword Toxicity     Text summariza tion     Robustnes s     Gigaword Builtin.Gigaword BERTScore and deltaBERT Score     To learn more about how the computed metric for each built-in dataset is calculated, see Review model evaluation job reports and metrics in Amazon Bedrock     Model evaluation task types 535           https://huggingface.co/datasets/gigaword?row=3         https://huggingface.co/datasets/gigaword?row=3         https://huggingface.co/datasets/gigaword?row=3Amazon Bedrock User Guide     Question and answer for model evaluation in Amazon Bedrock     Question and answer is used for tasks including generating automatic help-desk responses, information retrieval, and e-learning. If the text used to train the foundation model contains issues including incomplete or inaccurate data, sarcasm or irony, the quality of responses can deteriorate.     Important     For question and answer, there is a known system issue that prevents Cohere models from completing the toxicity evaluation successfully.     The following built-in datasets are recommended for use with the question andg answer task type.]</td>\n",
       "      <td>The following built-in datasets are available on Amazon Bedrock for model evaluation of general text generation tasks:<br><br>- Bias in Open-ended Language Generation Dataset (BOLD)<br>- RealToxicityPrompts<br>- T-Rex: A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)<br>- WikiText2</td>\n",
       "      <td>0.965784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ragas_df.style.set_properties(**{'text-align': 'left', 'border': '1px solid black'})\n",
    "ragas_df.to_string(justify='left', index=False)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    pretty_print(ragas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb27ab",
   "metadata": {},
   "source": [
    "### <a >Challenge Exercise :: Try it Yourself! </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c62acdc",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto;\">\n",
    "    <br>\n",
    "    <p style=\"text-align: center; margin: auto;\"><b>Try the following exercises on this lab and note the observations.</b></p>\n",
    "<p style=\" text-align: left; margin: auto;\">\n",
    "<ol>\n",
    "    <li>Test the RAG based LLM with more questions about Amazon Bedrock. </li>\n",
    "<li>Look the the citations or retrieved references and see if the answer generated by the RAG chatbot aligns with these retrieved contexts. What response do you get when the retrieved context comes up empty? </li>\n",
    "<li>Apply system prompts to RAG as well as amazon Bedrock Guardrails and test which is more consistent in blocking responses when the model response is hallucinated </li>\n",
    "<li>Run the tutorial for RAG Checker and compare the difference with RAGAS evaluation framework: https://github.com/amazon-science/RAGChecker/blob/main/tutorial/ragchecker_tutorial_en.md </li>\n",
    "</ol>\n",
    "<br>\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc89ac-b0e8-438a-bba2-12bc3a4a3f94",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We now have an understanding of parameters which influence hallucinations in Large Language Models. We learnt how to set up Retrieval Augmented Generation to provide a context to the model while answering.\n",
    "We used Contextual grounding in Amazon Bedrock Guardrials to intervene when hallucinations are detected.\n",
    "Finally we looked into the metrics of RAGAS and how to use them to measure hallucinations in your RAG powered chatbot.\n",
    "\n",
    "In the next lab, we will:\n",
    "1. Build a custom hallucination detector\n",
    "2. Use Amazon Bedrock Agents to intervene when hallucinations are detected\n",
    "3. Call a human for support when the LLM hallucinates\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
