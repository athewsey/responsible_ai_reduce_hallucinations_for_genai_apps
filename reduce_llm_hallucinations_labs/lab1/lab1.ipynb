{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc84eb37-3b34-4506-8ebc-c70f28166077",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center><img src=\"images/2024_reInvent_Logo_wDate_Black_V3.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# <a name=\"0\">re:Invent 2024 | Lab 1: Build your RAG powered chatbot  </a>\n",
    "## <a name=\"0\">Build a chatbot with Knowledge Bases and Guardrails to detect and remediate hallucinations </a>\n",
    "\n",
    "## Lab Overview\n",
    "In this lab, you will:\n",
    "1. Take a deeper look at which LLM parameters influence or control for model hallucinations\n",
    "2. Set up Retrieval Augmented Generation and understand how it can control for hallucinations\n",
    "3. Apply contextual grounding in Amazon Bedrock Guardrails to intervene when a model hallucinates\n",
    "4. Use RAGAS evaluation and understand which metrics help us measure hallucinations\n",
    "\n",
    "## Dataset\n",
    "For this workshop, we will use the [Bedrock User Guide](https://docs.aws.amazon.com/pdfs/bedrock/latest/userguide/bedrock-ug.pdf) available as a PDF file.\n",
    "## Use-Case Overview\n",
    "In this lab, we want to develop a chatbot which can answer questions about Amazon Bedrock as factually as possible. We will set up Retrieval Augmented Generation using [Amazon Bedrock Knowledge Bases](https://aws.amazon.com/bedrock/knowledge-bases/) and apply [Amazon Guardrails](https://aws.amazon.com/bedrock/guardrails/) to intervene when hallucinations are detected.\n",
    "\n",
    "\n",
    "#### Lab Sections\n",
    "\n",
    "This lab notebook has the following sections:\n",
    "    \n",
    "Please work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code.\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f260f34e-c753-4456-8643-639a3b4cdcfa",
   "metadata": {},
   "source": [
    "# Star Github repository for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb09da1-5d9e-4496-b0c8-ed5ae80911ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<a class=\"github-button\" href=\"https://github.com/aws-samples/responsible_ai_aim325_reduce_hallucinations_for_genai_apps\" data-color-scheme=\"no-preference: light; light: light; dark: dark;\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star Reduce Hallucinations workshop on GitHub\">Star</a>\n",
       "<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<a class=\"github-button\" href=\"https://github.com/aws-samples/responsible_ai_aim325_reduce_hallucinations_for_genai_apps\" data-color-scheme=\"no-preference: light; light: light; dark: dark;\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star Reduce Hallucinations workshop on GitHub\">Star</a>\n",
    "<script async defer src=\"https://buttons.github.io/buttons.js\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc006a3-48d5-40a5-9eb8-ea9bcd3d85e9",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65860ec8-bbea-4e33-b491-25e57c270470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install --upgrade --quiet pip sagemaker boto3 ragas==0.1.7 pydantic==2.6.1 langchain-core==0.1.40 langchain langchain-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba631f57-61f6-422f-8a42-472cb6046eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fe2e2d-9fd5-4586-8fd0-6bc7b7922e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "#from IPython.core.display import HTML\n",
    "#HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f420e67-aff9-4065-8525-6fa87fca093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in BedrockBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in BedrockBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.227.0', '1.35.15')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from time import gmtime, strftime, sleep\n",
    "import pprint\n",
    "import random\n",
    "import zipfile\n",
    "#from retrying import retry\n",
    "from rag_setup.create_kb_utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import sagemaker\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "(sagemaker.__version__,boto3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6edb7c-dfa1-4460-a365-e3f287951ddb",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b2c77d-ebdb-4d0a-acdd-04558b7797a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::040238304754:role/cfn-SageMakerExecutionRole-OXlXFaWIRw9w\n",
      "sagemaker-us-west-2-040238304754\n"
     ]
    }
   ],
   "source": [
    "# Get some variables you need to interact with SageMaker service\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "bucket_prefix = \"reduce-hallucinations-in-genai-apps\"  \n",
    "sm_session = sagemaker.Session()\n",
    "sm_client = boto_session.client(\"sagemaker\")\n",
    "sm_role = sagemaker.get_execution_role()\n",
    "\n",
    "initialized = True\n",
    "\n",
    "print(sm_role)\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c34d99ca-e263-44e3-9e35-685a7a8f9859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model_id=\"amazon.titan-embed-text-v2:0\"\n",
    "llm_model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2840d5d1-975e-49cb-9805-a7616c369f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bucket_name' (str)\n",
      "Stored 'bucket_prefix' (str)\n",
      "Stored 'sm_role' (str)\n",
      "Stored 'region' (str)\n",
      "Stored 'initialized' (bool)\n"
     ]
    }
   ],
   "source": [
    "# Store some variables to keep the value between the notebooks\n",
    "%store bucket_name\n",
    "%store bucket_prefix\n",
    "%store sm_role\n",
    "%store region\n",
    "%store initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13d3afab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/responsible_ai_reduce_hallucinations_for_genai_apps/reduce_llm_hallucinations_labs/lab1/rag_setup/create_kb_utils.py:60: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  response = llm(messages)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"No one has ever landed on the sun. The sun is a star with extremely hot temperatures and harsh conditions that make landing on its surface impossible with current technology.\\n\\nSome key facts:\\n\\n- The sun's surface temperature is around 5,500°C (10,000°F). Most materials would vaporize in such extreme heat.\\n\\n- The sun does not have a solid surface to land on. It is a ball of hot plasma and gases.\\n\\n- The gravitational forces and radiation levels on the sun are enormously high and would destroy any spacecraft trying to land.\\n\\n- The distance from Earth to the sun is about 93 million miles (150 million km), an immense distance that spacecraft would have difficulty traveling.\\n\\nWhile future advanced technologies may someday allow exploration of the sun from a safe distance, actually landing on the scorching hot solar surface is physically impossible, at least with anything resembling modern technology and materials. All current sun observations and studies are done from a far distance or using specialized sun-observing spacecraft and instruments.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test if bedrock model access has been enabled \n",
    "input_prompt = \"Who was the first person to land on the sun?\"\n",
    "test_llm_call(input_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44d408-1086-48fc-a329-f757fed9b02a",
   "metadata": {},
   "source": [
    "# 1. Chat with Anthropic Claude 3 Sonnet through Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "340537e1-ef81-4aef-a767-f0df5e1fef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "\n",
    "def generate_message_claude(\n",
    "    query, system_prompt=\"\", max_tokens=1000, \n",
    "    model_id='anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    temperature=0.9, top_p=0.99, top_k=100\n",
    "):\n",
    "    # Prompt with user turn only.\n",
    "    user_message = {\"role\": \"user\", \"content\": query}\n",
    "    messages = [user_message]\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"system\": system_prompt,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\": top_k\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dd47d4b-8455-4fcf-ae91-874ab2f7c0e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_01EXSdTCUQLSSCRDUyBqfuW7\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock Guardrails is a service that allows you to define and enforce organizational policies across your Amazon Web Services (AWS) accounts and resources. It is part of the AWS Bedrock initiative, which aims to help organizations establish a secure and compliant foundation for their cloud environments.\\n\\nHere's a high-level overview of how Amazon Bedrock Guardrails work:\\n\\n1. Policy Definition: You define policies using the AWS Bedrock Guardrails policy language, which is based on the AWS Control Tower Lifecycle Event Handshake protocol. These policies specify the desired configuration for your AWS resources, such as restricting the creation of certain resource types, enforcing tagging requirements, or limiting access to specific services.\\n\\n2. Policy Deployment: After defining your policies, you deploy them to your AWS Organizations management account. This account acts as the central control plane for managing policies across your entire organization.\\n\\n3. Policy Distribution: AWS Bedrock Guardrails automatically distributes the deployed policies to all your AWS accounts within your organization. This ensures that the policies are consistently applied across your entire AWS environment.\\n\\n4. Policy Enforcement: When an AWS service attempts to create, update, or delete a resource, AWS Bedrock Guardrails intercepts the request and evaluates it against the defined policies. If the request violates any policy, AWS Bedrock Guardrails prevents the operation from occurring and provides detailed information about the policy violation.\\n\\n5. Monitoring and Reporting: AWS Bedrock Guardrails integrates with AWS CloudTrail and AWS Config to provide visibility into policy evaluations and compliance status. You can monitor policy violations, generate reports, and take corrective actions as needed.\\n\\nBy using Amazon Bedrock Guardrails, organizations can establish and enforce consistent governance and compliance policies across their entire AWS environment. This helps ensure that resources are created and managed in accordance with organizational standards, reducing the risk of misconfigurations and potential security or compliance issues.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 19,\n",
      "        \"output_tokens\": 424\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'How do Amazon Bedrock Guardrails work?'\n",
    "\n",
    "response = generate_message_claude(query)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f0fa6-9637-4c65-bad6-0e1eacc692e9",
   "metadata": {},
   "source": [
    "## 1.1 Apply System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e203f5e9-2d93-4a79-b8ad-754d656f3008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_019xLzBQ3Dh8bH5PQjdoofM5\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Unfortunately, I do not have any specific information about purchasing provisioned throughput for Anthropic Claude models on Amazon Bedrock. Amazon Bedrock appears to be a new managed service offering from Amazon Web Services, but details are limited in my training data. As an AI assistant created by Anthropic, I do not have inside knowledge about Anthropic's commercial offerings or integrations with cloud providers. My role is to provide helpful information to users, but in this case, I do not have enough factual details to definitively answer your query. You may need to check the official documentation or contact Anthropic or Amazon for the latest updates on any integration between Claude and Amazon Bedrock.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 65,\n",
      "        \"output_tokens\": 146\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'Is it possible to purchase provisioned throughput for Anthropic Claude models on Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5057db14-729d-4d64-8355-fd6fe2ee2398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_01R3HyWCKds8XMfFu8SqKnat\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock Guardrails are a service provided by AWS that helps organizations govern their use of AWS resources through automated guardrails and preventive controls. Here's a brief overview of how Bedrock Guardrails work:\\n\\n1. Guardrails Definition: Organizations can define guardrails as code using the Bedrock Guardrails Domain Specific Language (DSL). Guardrails are essentially rules that enforce best practices, organizational policies, and regulatory requirements.\\n\\n2. Deployment: The defined guardrails are deployed as AWS CloudFormation stacks in the customer's AWS accounts and AWS Organizations. This allows the guardrails to span multiple accounts and organizational units.\\n\\n3. Continuous Evaluation: Bedrock Guardrails continuously evaluates the deployed AWS resources against the defined guardrails. It checks for violations of the rules specified in the guardrails.\\n\\n4. Preventive Controls: If a violation is detected, Bedrock Guardrails can automatically take preventive actions based on the configured rules. These actions can include denying non-compliant resource deployments, modifying resources to bring them into compliance, or triggering notifications and alerts.\\n\\n5. Reporting and Audit: Bedrock Guardrails provides reporting and auditing capabilities, allowing organizations to track compliance status, identify violations, and generate reports for auditing and compliance purposes.\\n\\nThe key benefits of Amazon Bedrock Guardrails include enforcing consistent governance across multiple accounts, automating compliance checks, and preventing non-compliant resource deployments or modifications. By codifying organizational policies as guardrails, AWS customers can ensure their AWS environments adhere to their security, operational, and regulatory requirements.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 56,\n",
      "        \"output_tokens\": 366\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'How do Amazon Bedrock Guardrails work?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f9196-7e32-4ef0-b516-b8801a688aa3",
   "metadata": {},
   "source": [
    "## 1.2 Understanding LLM generation parameters\n",
    "### 1. Temperature: The amount of randomness injected into the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f610c2e0-e810-47f4-89f9-9980319e32dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_014VeKKVs1mM3iAG99PxN375\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock is a set of internal tools, services, and foundational libraries used by Amazon's software engineers to build and deploy applications and services.\\n\\nSome key points about Amazon Bedrock:\\n\\n- It is an internal Amazon platform, not a customer-facing product or service.\\n\\n- It provides a common set of infrastructure components and frameworks that Amazon's engineering teams can leverage when building new applications.\\n\\n- It aims to increase development velocity and operational efficiency by providing reusable building blocks instead of having teams reinvent core functionality.\\n\\n- Components of Bedrock include services for compute, storage, database, networking, analytics, machine learning, and other cloud capabilities.\\n\\n- It allows Amazon to have standardized, scalable foundations across its many internal teams rather than siloed codebases.\\n\\n- Details are not publicly shared by Amazon, as Bedrock is considered proprietary internal infrastructure.\\n\\nSo in essence, Bedrock serves as Amazon's centralized platform and toolkit to enable faster innovation across its retail, AWS, logistics and other business areas through code reuse and standardization.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 51,\n",
      "        \"output_tokens\": 228\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=1)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30ff7dba-2f3f-4bd2-87ce-0d84c3c03a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_01DZAeAozMFoLUk8S1MWKKZ8\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock is a real-time operating system developed by Amazon for running applications on resource-constrained devices like microcontrollers and sensors.\\n\\nSome key points about Amazon Bedrock:\\n\\n- It is designed to be a secure, real-time operating system for internet of things (IoT) devices and embedded applications.\\n\\n- It provides a lightweight environment with real-time performance for running multiple software components concurrently.\\n\\n- It supports C and C++ programming languages.\\n\\n- It includes built-in security features like memory protection, encrypted communication, secure boot, and code signing.\\n\\n- It aims to simplify development and deployment of IoT applications across different hardware platforms.\\n\\n- Bedrock is open source and available under the Apache 2.0 license on GitHub.\\n\\n- It can run on microcontroller units (MCUs) from various vendors like NXP, STMicroelectronics, Infineon, etc.\\n\\nSo in summary, Bedrock provides a secure, real-time embedded OS foundation for building and deploying IoT applications on constrained devices used in industrial, automotive, consumer and other domains.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 51,\n",
      "        \"output_tokens\": 244\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=0)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47723758-0f8c-4190-94ef-3bdd4d386908",
   "metadata": {},
   "source": [
    "#### 2. top_p – Use nucleus sampling.\n",
    "\n",
    "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e300c40f-1b7b-4db1-bc5f-5f483507262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_0181MNg8JQzMHxZ46yTkYKsu\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock is not a term or product that I'm familiar with in relation to Amazon. Amazon has many different services and products, but I don't have any specific information about something called \\\"Amazon Bedrock.\\\"\\n\\nIt's possible this could be referring to some internal codename or project at Amazon, but without more context, I can't provide any definitive details. Amazon does offer cloud computing services through Amazon Web Services (AWS), which provides infrastructure and platforms like servers, databases, networking, etc. But I haven't seen any public references to \\\"Bedrock\\\" in relation to AWS or other Amazon offerings.\\n\\nUnless you can provide some more specifics about what context \\\"Amazon Bedrock\\\" is being used in, I don't want to speculate too much. Amazon has a vast array of products and services across e-commerce, cloud computing, media, hardware and more. But I don't have factual information about something called \\\"Bedrock\\\" from Amazon.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 51,\n",
      "        \"output_tokens\": 205\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=1, top_p=1)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7946bd-976d-4a8d-81ef-f7ff7e164f94",
   "metadata": {},
   "source": [
    "#### 3. top_k: Only sample from the top K options for each subsequent token.\n",
    "\n",
    "Use top_k to remove long tail low probability responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cf753a4-8929-46ef-8aea-7ef040abb096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User turn only.\n",
      "{\n",
      "    \"id\": \"msg_bdrk_01U5pLGkaUX9cjzRXwqfh7rA\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Amazon Bedrock is a real-time operating system developed by Amazon for running applications on resource-constrained devices like microcontrollers and sensors.\\n\\nSome key points about Amazon Bedrock:\\n\\n- It is designed to be a secure, real-time operating system for internet of things (IoT) devices and embedded applications.\\n\\n- It provides a lightweight environment with real-time performance for running multiple software components concurrently.\\n\\n- It supports C and C++ programming languages.\\n\\n- It includes built-in security features like memory protection, encrypted communication, secure boot, and code signing.\\n\\n- It aims to simplify development and deployment of IoT applications across different hardware platforms.\\n\\n- Bedrock is open source and available under the Apache 2.0 license on GitHub.\\n\\n- It can run on microcontroller units (MCUs) from various vendors like NXP, STMicroelectronics, Infineon, etc.\\n\\nSo in summary, Bedrock provides a secure, real-time embedded OS foundation for building and deploying IoT applications on constrained devices used in industrial, automotive, consumer and other domains.\"\n",
      "        }\n",
      "    ],\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "        \"input_tokens\": 51,\n",
      "        \"output_tokens\": 244\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'What is Amazon Bedrock?'\n",
    "system_prompt = 'You are a helpful AI assistant. You try to answer the user queries to the best of your knowledge. If you are unsure of the answer, do not make up any information.'\n",
    "\n",
    "response = generate_message_claude(query, system_prompt, temperature=0, top_p=1, top_k=100)\n",
    "print(\"User turn only.\")\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9caf35-dccd-4c16-82eb-ea3e1327bc80",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation\n",
    "We are using the Retrieval Augmented Generation (RAG) technique with Amazon Bedrock. A RAG implementation consists of two parts:\n",
    "\n",
    "    1. A data pipeline that ingests that from documents (typically stored in Amazon S3) into a Knowledge Base i.e. a vector database such as Amazon OpenSearch Service Serverless (AOSS) so that it is available for lookup when a question is received.\n",
    "\n",
    "The data pipeline represents an undifferentiated heavy lifting and can be implemented using Amazon Bedrock Knowledge Bases. We can now connect an S3 bucket to a vector database such as AOSS and have a Bedrock Knowledge Bases read the objects (html, pdf, text etc.), chunk them, and then convert these chunks into embeddings using Amazon Titan Embeddings model and then store these embeddings in AOSS. All of this without having to build, deploy, and manage the data pipeline.\n",
    "\n",
    "<center><img src=\"images/fully_managed_ingestion.png\" alt=\"This image shows how Aazon Bedrock Knowledge Bases ingests objects in a S3 bucket into the Knowledge Base for use in a RAG set up. The objects are chunks, embedded and then stored in a vector index.\" height=\"700\" width=\"700\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "    \n",
    "\n",
    "    2. An application that receives a question from the user, looks up the knowledge base for relevant pieces of information (context) and then creates a prompt that includes the question and the context and provides it to an LLM for generating a response.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Once the data is available in the Bedrock knowledge base, then user questions can be answered using the following system design:\n",
    "\n",
    "<center><img src=\"images/retrieveAndGenerate.png\" alt=\"This image shows the retrieval augmented generation (RAG) system design setup with knowledge bases, S3, and AOSS. Knowledge corpus is ingested into a vector database using Amazon Bedrock Knowledge Base Agent and then RAG approach is used to work question answering. The question is converted into embeddings followed by semantic similarity search to get similar documents. With the user prompt being augmented with the RAG search response, the LLM is invoked to get the final raw response for the user.\" height=\"700\" width=\"700\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588c8c3",
   "metadata": {},
   "source": [
    "# Data\n",
    "Let's use the publicly available [Bedrock user guide](https://docs.aws.amazon.com/pdfs/bedrock/latest/userguide/bedrock-ug.pdf) to inform the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b522396d-33e9-4251-9c72-09909436e25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-10 17:48:40--  https://docs.aws.amazon.com/pdfs/bedrock/latest/userguide/bedrock-ug.pdf\n",
      "Resolving docs.aws.amazon.com (docs.aws.amazon.com)... 3.163.24.36, 3.163.24.65, 3.163.24.45, ...\n",
      "Connecting to docs.aws.amazon.com (docs.aws.amazon.com)|3.163.24.36|:443... connected.\n",
      "WARNING: cannot verify docs.aws.amazon.com's certificate, issued by ‘CN=Amazon RSA 2048 M02,O=Amazon,C=US’:\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13669967 (13M) [application/pdf]\n",
      "Saving to: ‘data/bedrock-ug.pdf’\n",
      "\n",
      "bedrock-ug.pdf      100%[===================>]  13.04M  28.5MB/s    in 0.5s    \n",
      "\n",
      "2024-11-10 17:48:41 (28.5 MB/s) - ‘data/bedrock-ug.pdf’ saved [13669967/13669967]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P data/ -N https://docs.aws.amazon.com/pdfs/bedrock/latest/userguide/bedrock-ug.pdf --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fb05ed4-b63c-4e3c-a702-28021c506ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload the dataset to s3://sagemaker-us-west-2-040238304754/data/bedrock-ug.pdf\n",
      "Stored 'input_s3_url' (str)\n"
     ]
    }
   ],
   "source": [
    "# Upload data to S3\n",
    "dataset_file_local_path = 'data/bedrock-ug.pdf'\n",
    "input_s3_url = sagemaker.Session().upload_data(\n",
    "    path=dataset_file_local_path,\n",
    "    bucket=bucket_name\n",
    ")\n",
    "print(f\"Upload the dataset to {input_s3_url}\")\n",
    "\n",
    "%store input_s3_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbbc4e-039f-49d8-8de0-7ce89ca30349",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "1. Create Amazon Bedrock Knowledge Base execution role with necessary policies for accessing data from S3 and writing embeddings into OSS.\n",
    "2. Create an empty OpenSearch serverless index.\n",
    "3. Create Amazon Bedrock knowledge base\n",
    "4. Create a data source within knowledge base which will connect to Amazon S3\n",
    "5. Start an ingestion job using KB APIs which will read data from s3, chunk it, convert chunks into embeddings using Amazon Titan Embeddings model and then store these embeddings in AOSS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae93890e-c684-4286-9234-91a3e058cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH='./lab1/'\n",
    "#import sys\n",
    "#sys.path.insert(0,'./lab1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0140ab19-a682-4855-b3ee-10589637211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_db_file_uri='data'\n",
    "\n",
    "# if a kb already exists we can use the same, else the infra setup code will create one by itself using the bedrock user guide.\n",
    "use_existing_kb = False\n",
    "existing_kb_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c31b846-fa1f-43e0-ad9f-814bdb7dc3b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from rag_setup.create_kb_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e53913c-2aeb-42b4-be3e-c2eea8136eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_bedrock_policy :: None\n",
      "agent_s3_schema_policy :: None\n",
      "kb_aws_bedrock_policy :: None\n",
      "kb_db_s3_policy :: None\n",
      "Creating collection...\n",
      "Creating collection...\n",
      "Creating collection...\n",
      "Creating collection...\n",
      "Creating collection...\n",
      "Creating collection...\n",
      "Creating collection...\n",
      "Creating collection...\n",
      "Creating collection...\n",
      "Creating collection...\n",
      "Creating collection...\n",
      "\n",
      "Collection successfully created:\n",
      "\n",
      "Creating index:\n",
      "Knowledge base status -> is it READY ? :: ACTIVE\n",
      "knowledge_base_db_id :: TLPZHUIWOK\n",
      "CPU times: user 281 ms, sys: 50.3 ms, total: 331 ms\n",
      "Wall time: 10min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prefix_infra': 'l2678edb',\n",
       " 'bucket_name': 'sagemaker-us-west-2-040238304754',\n",
       " 'knowledge_base_db_id': 'TLPZHUIWOK',\n",
       " 'agent_bedrock_policy': None,\n",
       " 'agent_s3_schema_policy': None,\n",
       " 'kb_db_collection_name': 'l2ef9d-kbdb-040238304754',\n",
       " 'agent_kb_schema_policy': None,\n",
       " 'kb_db_aoss_policy': None,\n",
       " 'kb_db_s3_policy': None,\n",
       " 'kb_db_role_name': 'AmazonBedrockExecutionRoleForAgentsAIAssistant05',\n",
       " 'kb_db_opensearch_collection_response': {'createCollectionDetail': {'arn': 'arn:aws:aoss:us-west-2:040238304754:collection/iwqtdgih6qesm7wg8huk',\n",
       "   'createdDate': 1731260924042,\n",
       "   'description': 'OpenSearch collection for Amazon Bedrock Latest User guide Knowledge Base',\n",
       "   'id': 'iwqtdgih6qesm7wg8huk',\n",
       "   'kmsKeyArn': 'auto',\n",
       "   'lastModifiedDate': 1731260924042,\n",
       "   'name': 'l2ef9d-kbdb-040238304754',\n",
       "   'standbyReplicas': 'DISABLED',\n",
       "   'status': 'CREATING',\n",
       "   'type': 'VECTORSEARCH'},\n",
       "  'ResponseMetadata': {'RequestId': '9c9b87fb-7b14-4f39-ab4e-1aa325b527b2',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amzn-requestid': '9c9b87fb-7b14-4f39-ab4e-1aa325b527b2',\n",
       "    'date': 'Sun, 10 Nov 2024 17:48:44 GMT',\n",
       "    'content-type': 'application/x-amz-json-1.0',\n",
       "    'content-length': '407',\n",
       "    'connection': 'keep-alive'},\n",
       "   'RetryAttempts': 0}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For new KB it takes around ~6 minutes for this setup to complete on a t2.medium instance.\n",
    "infra_response = setup_knowledge_base(bucket_name, kb_db_file_uri, use_existing_kb, existing_kb_id)\n",
    "infra_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ec5179f-d77c-4d52-918c-f4fb37b70f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'kb_id' (str)\n",
      "Stored 'bucket_name' (str)\n"
     ]
    }
   ],
   "source": [
    "kb_id = infra_response['knowledge_base_db_id']\n",
    "random_id = infra_response['prefix_infra']\n",
    "# keep the kb_id for invocation later in the invoke request\n",
    "%store kb_id\n",
    "%store bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae3cf9eb-6d1e-4ae4-81db-a23379eae74d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TLPZHUIWOK'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf3a828f-e46d-4a14-8011-122a399b8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow time for KB to be ready\n",
    "time.sleep(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c35041-9487-46e6-9a36-fd8d408712c4",
   "metadata": {},
   "source": [
    "# Chat with the model using the knowledge base by providing the generated KB_ID\n",
    "### Using RetrieveAndGenerate API\n",
    "Behind the scenes, RetrieveAndGenerate API converts queries into embeddings, searches the knowledge base, and then augments the foundation model prompt with the search results as context information and returns the FM-generated response to the question. For multi-turn conversations, Knowledge Bases manage short-term memory of the conversation to provide more contextual results.The output of the RetrieveAndGenerate API includes the generated response, source attribution as well as the retrieved text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ca09025-187d-4aa4-8a0f-b6524e734ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0480df70-ab90-4c5d-bf07-8acabf7a1a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TLPZHUIWOK'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06645e80-eebb-4883-a086-70ccfdf604c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "\n",
    "def ask_bedrock_llm_with_knowledge_base(query,\n",
    "                                        kb_id=kb_id,\n",
    "                                        model_arn=llm_model_id,\n",
    "                                        ) -> str:\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\n",
    "            'text': query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': model_arn\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a151db3d-b340-46b2-bd57-491714d2068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Generated using Anthropic Claude 3 Sonnet:\n",
      "('Amazon Bedrock is a fully managed service that provides access to '\n",
      " 'high-performing foundation models (FMs) from leading AI companies and Amazon '\n",
      " 'through a unified API. It allows you to experiment with and evaluate '\n",
      " 'different foundation models, customize them with your own data using '\n",
      " 'techniques like fine-tuning and Retrieval Augmented Generation (RAG), and '\n",
      " 'build agents that can execute tasks using your systems and data sources. '\n",
      " \"With Amazon Bedrock's serverless experience, you can get started quickly, \"\n",
      " 'customize foundation models with your data, and easily integrate and deploy '\n",
      " 'them into your applications using AWS tools without managing any '\n",
      " 'infrastructure.')\n",
      "---------- The citations for the response:\n",
      "[ '............ 2009     xvAmazon Bedrock User Guide     What is Amazon '\n",
      "  'Bedrock?     Amazon Bedrock is a fully managed service that makes '\n",
      "  'high-performing foundation models (FMs) from leading AI companies and '\n",
      "  'Amazon available for your use through a unified API. You can choose from a '\n",
      "  'wide range of foundation models to find the model that is best suited for '\n",
      "  'your use case. Amazon Bedrock also offers a broad set of capabilities to '\n",
      "  'build generative AI applications with security, privacy, and responsible '\n",
      "  'AI. Using Amazon Bedrock, you can easily experiment with and evaluate top '\n",
      "  'foundation models for your use cases, privately customize them with your '\n",
      "  'data using techniques such as fine-tuning and Retrieval Augmented '\n",
      "  'Generation (RAG), and build agents that execute tasks using your enterprise '\n",
      "  \"systems and data sources.     With Amazon Bedrock's serverless experience, \"\n",
      "  'you can get started quickly, privately customize foundation models with '\n",
      "  'your own data, and easily and securely integrate and deploy them into your '\n",
      "  'applications using AWS tools without having to manage any '\n",
      "  'infrastructure.     Topics     ? What can I do with Amazon Bedrock?     ? '\n",
      "  'How do I get started with Amazon Bedrock?     ? Amazon Bedrock pricing     '\n",
      "  '? Supported AWS Regions in Amazon Bedrock     ? Key terminology     What '\n",
      "  'can I do with Amazon Bedrock?     You can use Amazon Bedrock to do the '\n",
      "  'following:     ? Experiment with prompts and configurations ? Submit '\n",
      "  'prompts and generate responses with model inference by sending prompts '\n",
      "  'using different configurations and foundation models to generate responses. '\n",
      "  'You can use the API or the text, image, and chat playgrounds in the console '\n",
      "  \"to experiment in a graphical interface. When you're ready, set up your \"\n",
      "  'application to make requests to the InvokeModel APIs.     ? Augment '\n",
      "  'response generation with information from your data sources ? Create '\n",
      "  'knowledge bases by uploading data sources to be queried in order to augment '\n",
      "  \"a foundation model's generation of responses.     What can I do with Amazon \"\n",
      "  'Bedrock? 1Amazon Bedrock User Guide     ? Create applications that reason '\n",
      "  'through how to help a customer ? Build agents that use foundation models, '\n",
      "  'make API calls, and (optionally) query knowledge bases in order to reason '\n",
      "  'through and carry out tasks for your customers.     ? Adapt models to '\n",
      "  'specific tasks and domains with training data ? Customize an Amazon Bedrock '\n",
      "  'foundation model by providing training data for fine-tuning or '\n",
      "  \"continued-pretraining in order to adjust a model's parameters and improve \"\n",
      "  'its performance on specific tasks or in certain domains.     ? Improve your '\n",
      "  \"FM-based application's efficiency and output ? Purchase Provisioned \"\n",
      "  'Throughput for a foundation model in order to run inference on models more '\n",
      "  'efficiently and at discounted rates.     ? Determine the best model for '\n",
      "  'your use case ? Evaluate outputs of different models with built-in or '\n",
      "  'custom prompt datasets to determine the model that is best suited for your '\n",
      "  'application.     ? Prevent inappropriate or unwanted content ? Use '\n",
      "  'guardrails to implement safeguards for your generative AI applications.     '\n",
      "  'To see feature limitations by AWS Region, see Model support by AWS '\n",
      "  'Region.     How do I get started with Amazon Bedrock?     We recommend that '\n",
      "  'you start with Amazon Bedrock by doing the following:     1. Familiarize '\n",
      "  'yourself with the terms and concepts that Amazon Bedrock uses.     2. '\n",
      "  'Understand how AWS charges you for using Amazon Bedrock.     3. Try the '\n",
      "  'Getting started with Amazon Bedrock tutorials. In the tutorials, you learn '\n",
      "  'how to use the playgrounds in Amazon Bedrock console. You also learn and '\n",
      "  'how to use the AWS SDK to call Amazon Bedrock API operations.     4. Read '\n",
      "  'the documentation for the features that you want to include in your '\n",
      "  'application.     Amazon Bedrock pricing     When you sign up for AWS, your '\n",
      "  'AWS account is automatically signed up for all services in AWS, including '\n",
      "  'Amazon Bedrock. However, you are charged only for the services that you '\n",
      "  'use.     How do I get started with Amazon Bedrock? 2Amazon Bedrock User '\n",
      "  'Guide     To see your bill, go to the Billing and Cost Management Dashboard '\n",
      "  'in the AWS Billing and Cost Management console. To learn more about AWS '\n",
      "  'account billing, see the AWS Billing User Guide. If you have questions '\n",
      "  'concerning AWS billing and AWS accounts, contact AWS Support.     With '\n",
      "  'Amazon Bedrock, you pay to run inference on any of the third-party '\n",
      "  'foundation models. Pricing is based on the volume of input tokens and '\n",
      "  'output tokens, and on whether you have purchased provisioned throughput for '\n",
      "  'the model. For more information, see the Model providers page in the Amazon '\n",
      "  'Bedrock console. For each model, pricing is listed following the model '\n",
      "  'version. For more information about purchasing Provisioned Throughput, see '\n",
      "  'Increase model invocation capacity with Provisioned Throughput in Amazon '\n",
      "  'Bedrock.     For more information, see Amazon Bedrock Pricing.     '\n",
      "  'Supported AWS Regions in Amazon Bedrock     This topic list the AWS Regions '\n",
      "  'that support Amazon Bedrock and the Amazon Bedrock features that each '\n",
      "  'Region supports. For information about service endpoints for Regions that '\n",
      "  'Amazon Bedrock supports, see Amazon Bedrock endpoints and quotas. To see '\n",
      "  'what foundation models each Region supports, see to Model support by AWS '\n",
      "  'Region.',\n",
      "  '......................................................................................................................... '\n",
      "  '1632     Amazon Bedrock Runtime '\n",
      "  '................................................................................................................... '\n",
      "  '1634 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1641 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1646 AI21 Labs Jurassic-2 '\n",
      "  '........................................................................................................................ '\n",
      "  '1659 Amazon Titan Image Generator '\n",
      "  '.................................................................................................... '\n",
      "  '1677 Amazon Titan Text '\n",
      "  '........................................................................................................................... '\n",
      "  '1686 Amazon Titan Text Embeddings '\n",
      "  '................................................................................................... '\n",
      "  '1717 Anthropic Claude '\n",
      "  '.............................................................................................................................. '\n",
      "  '1722 Cohere Command '\n",
      "  '............................................................................................................................. '\n",
      "  '1791 Meta Llama '\n",
      "  '........................................................................................................................................ '\n",
      "  '1839 Mistral AI '\n",
      "  '............................................................................................................................................ '\n",
      "  '1888 Stable Diffusion '\n",
      "  '................................................................................................................................ '\n",
      "  '1917     Amazon Bedrock Agents '\n",
      "  '...................................................................................................................... '\n",
      "  '1926 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1929 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1957     Amazon Bedrock Agents Runtime '\n",
      "  '..................................................................................................... '\n",
      "  '1970 Basics '\n",
      "  '................................................................................................................................................... '\n",
      "  '1971 Scenarios '\n",
      "  '............................................................................................................................................ '\n",
      "  '1978     Abuse detection '\n",
      "  '......................................................................................................................... '\n",
      "  '1980 Create resources with AWS CloudFormation '\n",
      "  '........................................................................... '\n",
      "  '1982     Amazon Bedrock and AWS CloudFormation templates '\n",
      "  '................................................................ 1982     '\n",
      "  'xivAmazon Bedrock User Guide     Learn more about AWS CloudFormation '\n",
      "  '.......................................................................................... '\n",
      "  '1983 Troubleshooting Amazon Bedrock API Error Codes '\n",
      "  '................................................................ 1984     '\n",
      "  'AccessDeniedExcpetion '\n",
      "  '......................................................................................................................... '\n",
      "  '1984 IncompleteSignature '\n",
      "  '............................................................................................................................. '\n",
      "  '1984 InternalFailure '\n",
      "  '........................................................................................................................................ '\n",
      "  '1984 InvalidAction '\n",
      "  '........................................................................................................................................... '\n",
      "  '1985 InvalidClientTokenId '\n",
      "  '.............................................................................................................................. '\n",
      "  '1985 NotAuthorized '\n",
      "  '........................................................................................................................................ '\n",
      "  '1985 RequestExpired '\n",
      "  '....................................................................................................................................... '\n",
      "  '1986 ServiceUnavailable '\n",
      "  '................................................................................................................................. '\n",
      "  '1986 ThrottlingException '\n",
      "  '............................................................................................................................... '\n",
      "  '1987 ValidationError '\n",
      "  '....................................................................................................................................... '\n",
      "  '1987 ResourceNotFound '\n",
      "  '................................................................................................................................ '\n",
      "  '1988     Quotas '\n",
      "  '........................................................................................................................................ '\n",
      "  '1989 Request an increase for Amazon Bedrock quotas '\n",
      "  '.......................................................................... '\n",
      "  '1989     Document history '\n",
      "  '...................................................................................................................... '\n",
      "  '1990 AWS Glossary '\n",
      "  '............................................................................................................................. '\n",
      "  '2009     xvAmazon Bedrock User Guide     What is Amazon Bedrock?     Amazon '\n",
      "  'Bedrock is a fully managed service that makes high-performing foundation '\n",
      "  'models (FMs) from leading AI companies and Amazon available for your use '\n",
      "  'through a unified API. You can choose from a wide range of foundation '\n",
      "  'models to find the model that is best suited for your use case. Amazon '\n",
      "  'Bedrock also offers a broad set of capabilities to build generative AI '\n",
      "  'applications with security, privacy, and responsible AI. Using Amazon '\n",
      "  'Bedrock, you can easily experiment with and evaluate top foundation models '\n",
      "  'for your use cases, privately customize them with your data using '\n",
      "  'techniques such as fine-tuning and Retrieval Augmented Generation (RAG), '\n",
      "  'and build agents that execute tasks using your enterprise systems and data '\n",
      "  \"sources.     With Amazon Bedrock's serverless experience, you can get \"\n",
      "  'started quickly, privately customize foundation models with your own data, '\n",
      "  'and easily and securely integrate and deploy them into your applications '\n",
      "  'using AWS tools without having to manage any infrastructure.     Topics     '\n",
      "  '? What can I do with Amazon Bedrock?     ? How do I get started with Amazon '\n",
      "  'Bedrock?     ? Amazon Bedrock pricing     ? Supported AWS Regions in Amazon '\n",
      "  'Bedrock     ? Key terminology     What can I do with Amazon Bedrock?     '\n",
      "  'You can use Amazon Bedrock to do the following:     ? Experiment with '\n",
      "  'prompts and configurations ? Submit prompts and generate responses with '\n",
      "  'model inference by sending prompts using different configurations and '\n",
      "  'foundation models to generate responses. You can use the API or the text, '\n",
      "  'image, and chat playgrounds in the console to experiment in a graphical '\n",
      "  \"interface. When you're ready, set up your application to make requests to \"\n",
      "  'the InvokeModel APIs.     ? Augment response generation with information '\n",
      "  'from your data sources ? Create knowledge bases by uploading data sources '\n",
      "  \"to be queried in order to augment a foundation model's generation of \"\n",
      "  'responses.     What can I do with Amazon Bedrock? 1Amazon Bedrock User '\n",
      "  'Guide     ? Create applications that reason through how to help a customer '\n",
      "  '? Build agents that use foundation models, make API calls, and (optionally) '\n",
      "  'query knowledge bases in order to reason through and carry out tasks for '\n",
      "  'your customers.     ? Adapt models to specific tasks and domains with '\n",
      "  'training data ? Customize an Amazon Bedrock foundation model by providing '\n",
      "  'training data for fine-tuning or continued-pretraining in order to adjust a '\n",
      "  \"model's parameters and improve its performance on specific tasks or in \"\n",
      "  \"certain domains.     ? Improve your FM-based application's efficiency and \"\n",
      "  'output ? Purchase Provisioned Throughput for a foundation model in order to '\n",
      "  'run inference on models more efficiently and at discounted rates.     ? '\n",
      "  'Determine the best model for your use case ? Evaluate outputs of different '\n",
      "  'models with built-in or custom prompt datasets to determine the model that '\n",
      "  'is best suited for your application.     ? Prevent inappropriate or '\n",
      "  'unwanted content ? Use guardrails to implement safeguards for your '\n",
      "  'generative AI applications.     To see feature limitations by AWS Region, '\n",
      "  'see Model support by AWS Region.     How do I get started with Amazon '\n",
      "  'Bedrock?     We recommend that you start with Amazon Bedrock by doing the '\n",
      "  'following:     1.',\n",
      "  '........................................ 1985 RequestExpired '\n",
      "  '....................................................................................................................................... '\n",
      "  '1986 ServiceUnavailable '\n",
      "  '................................................................................................................................. '\n",
      "  '1986 ThrottlingException '\n",
      "  '............................................................................................................................... '\n",
      "  '1987 ValidationError '\n",
      "  '....................................................................................................................................... '\n",
      "  '1987 ResourceNotFound '\n",
      "  '................................................................................................................................ '\n",
      "  '1988     Quotas '\n",
      "  '........................................................................................................................................ '\n",
      "  '1989 Request an increase for Amazon Bedrock quotas '\n",
      "  '.......................................................................... '\n",
      "  '1989     Document history '\n",
      "  '...................................................................................................................... '\n",
      "  '1990 AWS Glossary '\n",
      "  '............................................................................................................................. '\n",
      "  '2009     xvAmazon Bedrock User Guide     What is Amazon Bedrock?     Amazon '\n",
      "  'Bedrock is a fully managed service that makes high-performing foundation '\n",
      "  'models (FMs) from leading AI companies and Amazon available for your use '\n",
      "  'through a unified API. You can choose from a wide range of foundation '\n",
      "  'models to find the model that is best suited for your use case. Amazon '\n",
      "  'Bedrock also offers a broad set of capabilities to build generative AI '\n",
      "  'applications with security, privacy, and responsible AI. Using Amazon '\n",
      "  'Bedrock, you can easily experiment with and evaluate top foundation models '\n",
      "  'for your use cases, privately customize them with your data using '\n",
      "  'techniques such as fine-tuning and Retrieval Augmented Generation (RAG), '\n",
      "  'and build agents that execute tasks using your enterprise systems and data '\n",
      "  \"sources.     With Amazon Bedrock's serverless experience, you can get \"\n",
      "  'started quickly, privately customize foundation models with your own data, '\n",
      "  'and easily and securely integrate and deploy them into your applications '\n",
      "  'using AWS tools without having to manage any infrastructure.     Topics     '\n",
      "  '? What can I do with Amazon Bedrock?     ? How do I get started with Amazon '\n",
      "  'Bedrock?     ? Amazon Bedrock pricing     ? Supported AWS Regions in Amazon '\n",
      "  'Bedrock     ? Key terminology     What can I do with Amazon Bedrock?     '\n",
      "  'You can use Amazon Bedrock to do the following:     ? Experiment with '\n",
      "  'prompts and configurations ? Submit prompts and generate responses with '\n",
      "  'model inference by sending prompts using different configurations and '\n",
      "  'foundation models to generate responses. You can use the API or the text, '\n",
      "  'image, and chat playgrounds in the console to experiment in a graphical '\n",
      "  \"interface. When you're ready, set up your application to make requests to \"\n",
      "  'the InvokeModel APIs.     ? Augment response generation with information '\n",
      "  'from your data sources ? Create knowledge bases by uploading data sources '\n",
      "  \"to be queried in order to augment a foundation model's generation of \"\n",
      "  'responses.     What can I do with Amazon Bedrock? 1Amazon Bedrock User '\n",
      "  'Guide     ? Create applications that reason through how to help a customer '\n",
      "  '? Build agents that use foundation models, make API calls, and (optionally) '\n",
      "  'query knowledge bases in order to reason through and carry out tasks for '\n",
      "  'your customers.     ? Adapt models to specific tasks and domains with '\n",
      "  'training data ? Customize an Amazon Bedrock foundation model by providing '\n",
      "  'training data for fine-tuning or continued-pretraining in order to adjust a '\n",
      "  \"model's parameters and improve its performance on specific tasks or in \"\n",
      "  \"certain domains.     ? Improve your FM-based application's efficiency and \"\n",
      "  'output ? Purchase Provisioned Throughput for a foundation model in order to '\n",
      "  'run inference on models more efficiently and at discounted rates.     ? '\n",
      "  'Determine the best model for your use case ? Evaluate outputs of different '\n",
      "  'models with built-in or custom prompt datasets to determine the model that '\n",
      "  'is best suited for your application.     ? Prevent inappropriate or '\n",
      "  'unwanted content ? Use guardrails to implement safeguards for your '\n",
      "  'generative AI applications.     To see feature limitations by AWS Region, '\n",
      "  'see Model support by AWS Region.     How do I get started with Amazon '\n",
      "  'Bedrock?     We recommend that you start with Amazon Bedrock by doing the '\n",
      "  'following:     1. Familiarize yourself with the terms and concepts that '\n",
      "  'Amazon Bedrock uses.     2. Understand how AWS charges you for using Amazon '\n",
      "  'Bedrock.     3. Try the Getting started with Amazon Bedrock tutorials. In '\n",
      "  'the tutorials, you learn how to use the playgrounds in Amazon Bedrock '\n",
      "  'console. You also learn and how to use the AWS SDK to call Amazon Bedrock '\n",
      "  'API operations.     4. Read the documentation for the features that you '\n",
      "  'want to include in your application.     Amazon Bedrock pricing     When '\n",
      "  'you sign up for AWS, your AWS account is automatically signed up for all '\n",
      "  'services in AWS, including Amazon Bedrock. However, you are charged only '\n",
      "  'for the services that you use.     How do I get started with Amazon '\n",
      "  'Bedrock? 2Amazon Bedrock User Guide     To see your bill, go to the Billing '\n",
      "  'and Cost Management Dashboard in the AWS Billing and Cost Management '\n",
      "  'console. To learn more about AWS account billing, see the AWS Billing User '\n",
      "  'Guide. If you have questions concerning AWS billing and AWS accounts, '\n",
      "  'contact AWS Support.     With Amazon Bedrock, you pay to run inference on '\n",
      "  'any of the third-party foundation models. Pricing is based on the volume of '\n",
      "  'input tokens and output tokens, and on whether you have purchased '\n",
      "  'provisioned throughput for the model. For more information, see the Model '\n",
      "  'providers page in the Amazon Bedrock console. For each model, pricing is '\n",
      "  'listed following the model version.',\n",
      "  '............ 2009     xvAmazon Bedrock User Guide     What is Amazon '\n",
      "  'Bedrock?     Amazon Bedrock is a fully managed service that makes '\n",
      "  'high-performing foundation models (FMs) from leading AI companies and '\n",
      "  'Amazon available for your use through a unified API. You can choose from a '\n",
      "  'wide range of foundation models to find the model that is best suited for '\n",
      "  'your use case. Amazon Bedrock also offers a broad set of capabilities to '\n",
      "  'build generative AI applications with security, privacy, and responsible '\n",
      "  'AI. Using Amazon Bedrock, you can easily experiment with and evaluate top '\n",
      "  'foundation models for your use cases, privately customize them with your '\n",
      "  'data using techniques such as fine-tuning and Retrieval Augmented '\n",
      "  'Generation (RAG), and build agents that execute tasks using your enterprise '\n",
      "  \"systems and data sources.     With Amazon Bedrock's serverless experience, \"\n",
      "  'you can get started quickly, privately customize foundation models with '\n",
      "  'your own data, and easily and securely integrate and deploy them into your '\n",
      "  'applications using AWS tools without having to manage any '\n",
      "  'infrastructure.     Topics     ? What can I do with Amazon Bedrock?     ? '\n",
      "  'How do I get started with Amazon Bedrock?     ? Amazon Bedrock pricing     '\n",
      "  '? Supported AWS Regions in Amazon Bedrock     ? Key terminology     What '\n",
      "  'can I do with Amazon Bedrock?     You can use Amazon Bedrock to do the '\n",
      "  'following:     ? Experiment with prompts and configurations ? Submit '\n",
      "  'prompts and generate responses with model inference by sending prompts '\n",
      "  'using different configurations and foundation models to generate responses. '\n",
      "  'You can use the API or the text, image, and chat playgrounds in the console '\n",
      "  \"to experiment in a graphical interface. When you're ready, set up your \"\n",
      "  'application to make requests to the InvokeModel APIs.     ? Augment '\n",
      "  'response generation with information from your data sources ? Create '\n",
      "  'knowledge bases by uploading data sources to be queried in order to augment '\n",
      "  \"a foundation model's generation of responses.     What can I do with Amazon \"\n",
      "  'Bedrock? 1Amazon Bedrock User Guide     ? Create applications that reason '\n",
      "  'through how to help a customer ? Build agents that use foundation models, '\n",
      "  'make API calls, and (optionally) query knowledge bases in order to reason '\n",
      "  'through and carry out tasks for your customers.     ? Adapt models to '\n",
      "  'specific tasks and domains with training data ? Customize an Amazon Bedrock '\n",
      "  'foundation model by providing training data for fine-tuning or '\n",
      "  \"continued-pretraining in order to adjust a model's parameters and improve \"\n",
      "  'its performance on specific tasks or in certain domains.     ? Improve your '\n",
      "  \"FM-based application's efficiency and output ? Purchase Provisioned \"\n",
      "  'Throughput for a foundation model in order to run inference on models more '\n",
      "  'efficiently and at discounted rates.     ? Determine the best model for '\n",
      "  'your use case ? Evaluate outputs of different models with built-in or '\n",
      "  'custom prompt datasets to determine the model that is best suited for your '\n",
      "  'application.     ? Prevent inappropriate or unwanted content ? Use '\n",
      "  'guardrails to implement safeguards for your generative AI applications.     '\n",
      "  'To see feature limitations by AWS Region, see Model support by AWS '\n",
      "  'Region.     How do I get started with Amazon Bedrock?     We recommend that '\n",
      "  'you start with Amazon Bedrock by doing the following:     1. Familiarize '\n",
      "  'yourself with the terms and concepts that Amazon Bedrock uses.     2. '\n",
      "  'Understand how AWS charges you for using Amazon Bedrock.     3. Try the '\n",
      "  'Getting started with Amazon Bedrock tutorials. In the tutorials, you learn '\n",
      "  'how to use the playgrounds in Amazon Bedrock console. You also learn and '\n",
      "  'how to use the AWS SDK to call Amazon Bedrock API operations.     4. Read '\n",
      "  'the documentation for the features that you want to include in your '\n",
      "  'application.     Amazon Bedrock pricing     When you sign up for AWS, your '\n",
      "  'AWS account is automatically signed up for all services in AWS, including '\n",
      "  'Amazon Bedrock. However, you are charged only for the services that you '\n",
      "  'use.     How do I get started with Amazon Bedrock? 2Amazon Bedrock User '\n",
      "  'Guide     To see your bill, go to the Billing and Cost Management Dashboard '\n",
      "  'in the AWS Billing and Cost Management console. To learn more about AWS '\n",
      "  'account billing, see the AWS Billing User Guide. If you have questions '\n",
      "  'concerning AWS billing and AWS accounts, contact AWS Support.     With '\n",
      "  'Amazon Bedrock, you pay to run inference on any of the third-party '\n",
      "  'foundation models. Pricing is based on the volume of input tokens and '\n",
      "  'output tokens, and on whether you have purchased provisioned throughput for '\n",
      "  'the model. For more information, see the Model providers page in the Amazon '\n",
      "  'Bedrock console. For each model, pricing is listed following the model '\n",
      "  'version. For more information about purchasing Provisioned Throughput, see '\n",
      "  'Increase model invocation capacity with Provisioned Throughput in Amazon '\n",
      "  'Bedrock.     For more information, see Amazon Bedrock Pricing.     '\n",
      "  'Supported AWS Regions in Amazon Bedrock     This topic list the AWS Regions '\n",
      "  'that support Amazon Bedrock and the Amazon Bedrock features that each '\n",
      "  'Region supports. For information about service endpoints for Regions that '\n",
      "  'Amazon Bedrock supports, see Amazon Bedrock endpoints and quotas. To see '\n",
      "  'what foundation models each Region supports, see to Model support by AWS '\n",
      "  'Region.']\n",
      "TLPZHUIWOK\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon Bedrock?\"\n",
    "\n",
    "response = ask_bedrock_llm_with_knowledge_base(query, kb_id)\n",
    "generated_text = response['output']['text']\n",
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "        contexts.append(reference[\"content\"][\"text\"])\n",
    "print(f\"---------- Generated using Anthropic Claude 3 Sonnet:\")\n",
    "pp.pprint(generated_text )\n",
    "print(f'---------- The citations for the response:')\n",
    "pp.pprint(contexts)\n",
    "print(kb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0892703-6fa4-4bac-a3b1-7cd30523b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Generated using Anthropic Claude 3 Sonnet:\n",
      "('Yes, it is possible to purchase provisioned throughput for Anthropic Claude '\n",
      " 'Sonnet models on Amazon Bedrock. Specifically, you can purchase provisioned '\n",
      " 'throughput for the following Anthropic Claude Sonnet models:\\n'\n",
      " '\\n'\n",
      " '- Anthropic Claude 3 Sonnet 28K (model ID: '\n",
      " 'anthropic.claude-3-sonnet-20240229-v1:0:28k)\\n'\n",
      " '- Anthropic Claude 3 Sonnet 200K (model ID: '\n",
      " 'anthropic.claude-3-sonnet-20240229-v1:0:200k)\\n'\n",
      " '- Anthropic Claude 3.5 Sonnet 18K (model ID: '\n",
      " 'anthropic.claude-3-5-sonnet-20240620-v1:0:18k) - Only available in the US '\n",
      " 'West (Oregon) region\\n'\n",
      " '- Anthropic Claude 3.5 Sonnet 51K (model ID: '\n",
      " 'anthropic.claude-3-5-sonnet-20240620-v1:0:51k) - Only available in the US '\n",
      " 'West (Oregon) region\\n'\n",
      " '- Anthropic Claude 3.5 Sonnet 200K (model ID: '\n",
      " 'anthropic.claude-3-5-sonnet-20240620-v1:0:200k) - Only available in the US '\n",
      " 'West (Oregon) region')\n",
      "---------- The citations for the response:\n",
      "[ 'request. Provisioned Throughput is available for the following models:     '\n",
      "  'Note     Some models have multiple contextual versions whose availability '\n",
      "  'differs by region. For more information, see Model support by AWS '\n",
      "  'Region.     Model name No-commitment purchase supported for base model     '\n",
      "  'Model ID for Provisioned Throughput     Notes     Amazon Titan Text G1 - '\n",
      "  'Express     Yes amazon.titan-text- express-v1:0:8k     \\xa0     Amazon '\n",
      "  'Titan Text G1 - Lite     Yes amazon.titan-text- lite-v1:0:4k     \\xa0     '\n",
      "  'Amazon Titan Text Premier (preview)     Yes amazon.titan-text- '\n",
      "  'premier-v1:0:32K     \\xa0     Base model IDs (for Provisioned Throughput) '\n",
      "  '67           '\n",
      "  'https://docs.aws.amazon.com/bedrock/latest/APIReference/API_CreateProvisionedModelThroughput.htmlAmazon '\n",
      "  'Bedrock User Guide     Model name No-commitment purchase supported for base '\n",
      "  'model     Model ID for Provisioned Throughput     Notes     Amazon Titan '\n",
      "  'Embeddings G1 - Text     Yes amazon.titan-embed- text-v1:2:8k     \\xa0     '\n",
      "  'Amazon Titan Embeddings G1 - Text v2     Yes amazon.titan-embed- '\n",
      "  'text-v2:0:8k     \\xa0     Amazon Titan Multimodal Embeddings G1     Yes '\n",
      "  'amazon.titan-embed- image-v1:0     \\xa0     Amazon Titan Image Generator G1 '\n",
      "  'V1     No amazon.titan-image- generator-v1:0     \\xa0     Amazon Titan '\n",
      "  'Image Generator G1 V1 V2     No amazon.titan-image- '\n",
      "  'generator-v2:0     \\xa0     Anthropic Claude v2 18K     Yes '\n",
      "  'anthropic.claude-v 2:0:18k     \\xa0     Anthropic Claude v2 100K     Yes '\n",
      "  'anthropic.claude-v 2:0:100k     \\xa0     Anthropic Claude v2.1 18K     Yes '\n",
      "  'anthropic.claude-v 2:1:18k     \\xa0     Anthropic Claude v2.1 200K     Yes '\n",
      "  'anthropic.claude-v 2:1:200k     \\xa0     Anthropic Claude 3 Haiku 48K     '\n",
      "  'Yes anthropic.claude-3- haiku-20240307-v1 :0:48k     \\xa0     Base model '\n",
      "  'IDs (for Provisioned Throughput) 68Amazon Bedrock User Guide     Model name '\n",
      "  'No-commitment purchase supported for base model     Model ID for '\n",
      "  'Provisioned Throughput     Notes     Anthropic Claude 3 Haiku 200K     Yes '\n",
      "  'anthropic.claude-3- haiku-20240307-v1 :0:200k     \\xa0     Anthropic Claude '\n",
      "  'Instant v1 100K     Yes anthropic.claude-i nstant-v1:2:100k     \\xa0     '\n",
      "  'Anthropic Claude 3 Sonnet 28K     Yes anthropic.claude-3- sonnet-20240229-v '\n",
      "  '1:0:28k     \\xa0     Anthropic Claude 3 Sonnet 200K     Yes '\n",
      "  'anthropic.claude-3- sonnet-20240229-v 1:0:200k     \\xa0     Anthropic '\n",
      "  'Claude 3.5 Sonnet 18K     Yes anthropic.claude-3-5- sonnet-20240620- '\n",
      "  'v1:0:18k     Only available in US West (Oregon).     Anthropic Claude 3.5 '\n",
      "  'Sonnet 51K     Yes anthropic.claude-3-5- sonnet-20240620- v1:0:51k     Only '\n",
      "  'available in US West (Oregon).     Anthropic Claude 3.5 Sonnet 200K     Yes '\n",
      "  'anthropic.claude-3-5- sonnet-20240620- v1:0:200k     Only available in US '\n",
      "  'West (Oregon).',\n",
      "  'Provisioned Throughput     To purchase Provisioned Throughput through the '\n",
      "  'API, use the corresponding model ID when provisioning the model with a '\n",
      "  'CreateProvisionedModelThroughput request. Provisioned Throughput is '\n",
      "  'available for the following models:     Note     Some models have multiple '\n",
      "  'contextual versions whose availability differs by region. For more '\n",
      "  'information, see Model support by AWS Region.     Model name No-commitment '\n",
      "  'purchase supported for base model     Model ID for Provisioned '\n",
      "  'Throughput     Notes     Amazon Titan Text G1 - Express     Yes '\n",
      "  'amazon.titan-text- express-v1:0:8k     \\xa0     Amazon Titan Text G1 - '\n",
      "  'Lite     Yes amazon.titan-text- lite-v1:0:4k     \\xa0     Amazon Titan Text '\n",
      "  'Premier (preview)     Yes amazon.titan-text- premier-v1:0:32K     \\xa0     '\n",
      "  'Base model IDs (for Provisioned Throughput) 67           '\n",
      "  'https://docs.aws.amazon.com/bedrock/latest/APIReference/API_CreateProvisionedModelThroughput.htmlAmazon '\n",
      "  'Bedrock User Guide     Model name No-commitment purchase supported for base '\n",
      "  'model     Model ID for Provisioned Throughput     Notes     Amazon Titan '\n",
      "  'Embeddings G1 - Text     Yes amazon.titan-embed- text-v1:2:8k     \\xa0     '\n",
      "  'Amazon Titan Embeddings G1 - Text v2     Yes amazon.titan-embed- '\n",
      "  'text-v2:0:8k     \\xa0     Amazon Titan Multimodal Embeddings G1     Yes '\n",
      "  'amazon.titan-embed- image-v1:0     \\xa0     Amazon Titan Image Generator G1 '\n",
      "  'V1     No amazon.titan-image- generator-v1:0     \\xa0     Amazon Titan '\n",
      "  'Image Generator G1 V1 V2     No amazon.titan-image- '\n",
      "  'generator-v2:0     \\xa0     Anthropic Claude v2 18K     Yes '\n",
      "  'anthropic.claude-v 2:0:18k     \\xa0     Anthropic Claude v2 100K     Yes '\n",
      "  'anthropic.claude-v 2:0:100k     \\xa0     Anthropic Claude v2.1 18K     Yes '\n",
      "  'anthropic.claude-v 2:1:18k     \\xa0     Anthropic Claude v2.1 200K     Yes '\n",
      "  'anthropic.claude-v 2:1:200k     \\xa0     Anthropic Claude 3 Haiku 48K     '\n",
      "  'Yes anthropic.claude-3- haiku-20240307-v1 :0:48k     \\xa0     Base model '\n",
      "  'IDs (for Provisioned Throughput) 68Amazon Bedrock User Guide     Model name '\n",
      "  'No-commitment purchase supported for base model     Model ID for '\n",
      "  'Provisioned Throughput     Notes     Anthropic Claude 3 Haiku 200K     Yes '\n",
      "  'anthropic.claude-3- haiku-20240307-v1 :0:200k     \\xa0     Anthropic Claude '\n",
      "  'Instant v1 100K     Yes anthropic.claude-i nstant-v1:2:100k     \\xa0     '\n",
      "  'Anthropic Claude 3 Sonnet 28K     Yes anthropic.claude-3- sonnet-20240229-v '\n",
      "  '1:0:28k     \\xa0     Anthropic Claude 3 Sonnet 200K     Yes '\n",
      "  'anthropic.claude-3- sonnet-20240229-v 1:0:200k     \\xa0     Anthropic '\n",
      "  'Claude 3.5 Sonnet 18K     Yes anthropic.claude-3-5- sonnet-20240620- '\n",
      "  'v1:0:18k     Only available in US West (Oregon).     Anthropic Claude 3.5 '\n",
      "  'Sonnet 51K     Yes anthropic.claude-3-5- sonnet-20240620- v1:0:51k     Only '\n",
      "  'available in US West (Oregon).     Anthropic Claude 3.5 Sonnet 200K     Yes '\n",
      "  'anthropic.claude-3-5- sonnet-20240620- v1:0:200k     Only available in US '\n",
      "  'West (Oregon).',\n",
      "  'The following steps outline the process of setting up and using Provisioned '\n",
      "  'Throughput.     1. Determine the number of MUs you wish to purchase for a '\n",
      "  'Provisioned Throughput and the amount of time for which you want to commit '\n",
      "  'to using the Provisioned Throughput.     2. Purchase Provisioned Throughput '\n",
      "  'for a base or custom model.     3. After the provisioned model is created, '\n",
      "  'you can use it to run model inference.     Topics     ? Supported region '\n",
      "  'and models for Provisioned Throughput     ? Prerequisites for Provisioned '\n",
      "  'Throughput     ? Purchase a Provisioned Throughput for an Amazon Bedrock '\n",
      "  'model     ? View information about a Provisioned Throughput     ? Modify a '\n",
      "  'Provisioned Throughput     ? Use a Provisioned Throughput with an Amazon '\n",
      "  'Bedrock resource     ? Delete a Provisioned Throughput     ? Code examples '\n",
      "  'for Provisioned Throughput     Supported region and models for Provisioned '\n",
      "  'Throughput     Provisioned Throughput is supported in the following '\n",
      "  'regions:     Supported regions and models 1374Amazon Bedrock User Guide     '\n",
      "  'Region     US East (N. Virginia)     US West (Oregon)     Asia Pacific '\n",
      "  '(Mumbai)     Asia Pacific (Sydney)     Canada (Central)     Europe '\n",
      "  '(London)     Europe (Paris)     Europe (Ireland)     South America (São '\n",
      "  'Paulo)     AWS GovCloud (US-West) (only for custom models with no '\n",
      "  'commitment)     If you purchase Provisioned Throughput through the Amazon '\n",
      "  'Bedrock API, you must specify a contextual variant of Amazon Bedrock FMs '\n",
      "  'for the model ID. The following table shows the models for which you can '\n",
      "  'purchase Provisioned Throughput, whether you can purchase without '\n",
      "  'commitment for the base model, and the model ID to use when purchasing '\n",
      "  'Provisioned Throughput.     Model name No-commitment purchase supported for '\n",
      "  'base model     Model ID for Provisioned Throughput     Notes     Amazon '\n",
      "  'Titan Text G1 - Express     Yes amazon.titan-text- '\n",
      "  'express-v1:0:8k     \\xa0     Supported regions and models 1375Amazon '\n",
      "  'Bedrock User Guide     Model name No-commitment purchase supported for base '\n",
      "  'model     Model ID for Provisioned Throughput     Notes     Amazon Titan '\n",
      "  'Text G1 - Lite     Yes amazon.titan-text- lite-v1:0:4k     \\xa0     Amazon '\n",
      "  'Titan Text Premier (preview)     Yes amazon.titan-text- '\n",
      "  'premier-v1:0:32K     \\xa0     Amazon Titan Embeddings G1 - Text     Yes '\n",
      "  'amazon.titan-embed- text-v1:2:8k     \\xa0     Amazon Titan Embeddings G1 - '\n",
      "  'Text v2     Yes amazon.titan-embed- text-v2:0:8k     \\xa0     Amazon Titan '\n",
      "  'Multimodal Embeddings G1     Yes amazon.titan-embed- '\n",
      "  'image-v1:0     \\xa0     Amazon Titan Image Generator G1 V1     No '\n",
      "  'amazon.titan-image- generator-v1:0     \\xa0     Amazon Titan Image '\n",
      "  'Generator G1 V1 V2     No amazon.titan-image- generator-v2:0     \\xa0     '\n",
      "  'Anthropic Claude v2 18K     Yes anthropic.claude-v 2:0:18k     \\xa0     '\n",
      "  'Anthropic Claude v2 100K     Yes anthropic.claude-v 2:0:100k     \\xa0     '\n",
      "  'Anthropic Claude v2.1 18K     Yes anthropic.claude-v 2:1:18k     \\xa0     '\n",
      "  'Anthropic Claude v2.1 200K     Yes anthropic.claude-v 2:1:200k     \\xa0     '\n",
      "  'Supported regions and models 1376Amazon Bedrock User Guide     Model name '\n",
      "  'No-commitment purchase supported for base model     Model ID for '\n",
      "  'Provisioned Throughput     Notes     Anthropic Claude 3 Haiku 48K     Yes '\n",
      "  'anthropic.claude-3- haiku-20240307-v1 :0:48k     \\xa0     Anthropic Claude '\n",
      "  '3 Haiku 200K     Yes anthropic.claude-3- haiku-20240307-v1 '\n",
      "  ':0:200k     \\xa0     Anthropic Claude Instant v1 100K     Yes '\n",
      "  'anthropic.claude-i nstant-v1:2:100k     \\xa0     Anthropic Claude 3 Sonnet '\n",
      "  '28K     Yes anthropic.claude-3- sonnet-20240229-v 1:0:28k     \\xa0     '\n",
      "  'Anthropic Claude 3 Sonnet 200K     Yes anthropic.claude-3- '\n",
      "  'sonnet-20240229-v 1:0:200k     \\xa0     Anthropic Claude 3.5 Sonnet 18K     '\n",
      "  'Yes anthropic.claude-3-5- sonnet-20240620- v1:0:18k     Only available in '\n",
      "  'US West (Oregon).']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Is it possible to purchase provisioned throughput for Anthropic Claude Sonnet on Amazon Bedrock?\"\n",
    "\n",
    "response = ask_bedrock_llm_with_knowledge_base(query, kb_id)\n",
    "generated_text = response['output']['text']\n",
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "        contexts.append(reference[\"content\"][\"text\"])\n",
    "print(f\"---------- Generated using Anthropic Claude 3 Sonnet:\")\n",
    "pp.pprint(generated_text )\n",
    "print(f'---------- The citations for the response:')\n",
    "pp.pprint(contexts)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0f09-2ecf-40c5-9dd2-1c42a7af6231",
   "metadata": {},
   "source": [
    "# Contextual Grounding with Amazon Bedrock Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "810e1acf-ddbe-4e93-bf96-32e7282a7db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrock-rag-grounding-guardrail-l2678edb\n"
     ]
    }
   ],
   "source": [
    "# Create guardrail\n",
    "bedrock_client = boto3.client('bedrock')\n",
    "guardrail_name = f\"bedrock-rag-grounding-guardrail-{random_id}\"\n",
    "print(guardrail_name)\n",
    "guardrail_response = bedrock_client.create_guardrail(\n",
    "    name=guardrail_name,\n",
    "    description='Guardrail for ensuring relevance and grounding of model responses in RAG powered chatbot',\n",
    "    contextualGroundingPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {\n",
    "                'type': 'GROUNDING',\n",
    "                'threshold': 0.5\n",
    "            },\n",
    "            {\n",
    "                'type': 'RELEVANCE',\n",
    "                'threshold': 0.5\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging='Can you please rephrase your question?',\n",
    "    blockedOutputsMessaging='Sorry, I am not able to find the correct answer to your query - Can you try reframing your query to be more specific'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d615898-b2a3-4b8c-8830-f6710fc86ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a2b6d23a-fe09-4ad6-a905-35179f43f22c',\n",
       "  'HTTPStatusCode': 202,\n",
       "  'HTTPHeaders': {'date': 'Sun, 10 Nov 2024 18:02:49 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '172',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'a2b6d23a-fe09-4ad6-a905-35179f43f22c'},\n",
       "  'RetryAttempts': 0},\n",
       " 'guardrailId': 'nj44ju4v72kr',\n",
       " 'guardrailArn': 'arn:aws:bedrock:us-west-2:040238304754:guardrail/nj44ju4v72kr',\n",
       " 'version': 'DRAFT',\n",
       " 'createdAt': datetime.datetime(2024, 11, 10, 18, 2, 49, 42725, tzinfo=tzlocal())}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guardrailId = guardrail_response['guardrailId']\n",
    "guardrail_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a503292a-b84c-46d5-8fe2-f9d199198f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '705cd743-ebd9-4b9d-b8f4-d7bf06744f8d', 'HTTPStatusCode': 202, 'HTTPHeaders': {'date': 'Sun, 10 Nov 2024 18:02:49 GMT', 'content-type': 'application/json', 'content-length': '44', 'connection': 'keep-alive', 'x-amzn-requestid': '705cd743-ebd9-4b9d-b8f4-d7bf06744f8d'}, 'RetryAttempts': 0}, 'guardrailId': 'nj44ju4v72kr', 'version': '1'}\n",
      "nj44ju4v72kr\n",
      "Stored 'guardrailId' (str)\n"
     ]
    }
   ],
   "source": [
    "guardrail_version = bedrock_client.create_guardrail_version(\n",
    "    guardrailIdentifier=guardrail_response['guardrailId'],\n",
    "    description='Working version of RAG app guardrail with higher thresholds for contextual grounding'\n",
    ")\n",
    "print(guardrail_version)\n",
    "guardrailVersion = guardrail_response['version']\n",
    "print(guardrailId)\n",
    "%store guardrailId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dfbd6ac-6411-47dd-b645-33df81614878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and Generate using Guardrail\n",
    "\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "\n",
    "def retrieve_and_generate_with_guardrail(\n",
    "    query,\n",
    "    kb_id,\n",
    "    model_arn=llm_model_id,\n",
    "    session_id=None\n",
    "):\n",
    "\n",
    "    prompt_template = 'You are a helpful AI assistant to help users understand documented risks in various projects. \\\n",
    "    Answer the user query based on the context retrieved. If you dont know the answer, dont make up anything. \\\n",
    "    Only answer based on what you know from the provided context. You can ask the user for clarifying questions if anything is unclear\\\n",
    "    But generate an answer only when you are confident about it and based on the provided context.\\\n",
    "    User Query: $query$\\\n",
    "    Context: $search_results$'\n",
    "\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\n",
    "            'text': query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'generationConfiguration': {\n",
    "                    'guardrailConfiguration': {\n",
    "                        'guardrailId': guardrailId,\n",
    "                        'guardrailVersion': guardrailVersion\n",
    "                    },\n",
    "                    'inferenceConfig': {\n",
    "                        'textInferenceConfig': {\n",
    "                            'temperature': 0.7,\n",
    "                            'topP': 0.25\n",
    "                        }\n",
    "                    },\n",
    "                    'promptTemplate': {\n",
    "                        'textPromptTemplate': prompt_template\n",
    "                    }\n",
    "                },\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': model_arn,\n",
    "                'retrievalConfiguration': {\n",
    "                    'vectorSearchConfiguration': {\n",
    "                        'overrideSearchType': 'SEMANTIC'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6f710a5-74c9-4480-8308-e9b362730428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '70114096-52d5-4753-b31c-27bcbcf0f2aa', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 10 Nov 2024 18:02:57 GMT', 'content-type': 'application/json', 'content-length': '1545', 'connection': 'keep-alive', 'x-amzn-requestid': '70114096-52d5-4753-b31c-27bcbcf0f2aa'}, 'RetryAttempts': 0}, 'citations': [{'generatedResponsePart': {'textResponsePart': {'span': {'end': 50, 'start': 0}, 'text': 'Sorry, I am unable to assist you with this request.'}}, 'retrievedReferences': []}], 'guardrailAction': 'NONE', 'output': {'text': 'According to the context provided, Amazon Bedrock is a fully managed service from AWS that provides access to high-performing foundation models (FMs) from leading AI companies and Amazon through a unified API.\\n\\nSome key points about Amazon Bedrock:\\n\\n- It allows you to choose from a wide range of foundation models to find the best one for your use case.\\n- It offers capabilities to build generative AI applications with security, privacy, and responsible AI principles.\\n- You can experiment with and evaluate different foundation models, privately customize them with your own data using techniques like fine-tuning and retrieval augmented generation (RAG).\\n- You can build agents that use foundation models, make API calls, and query knowledge bases to reason through and carry out tasks.\\n- It provides a serverless experience where you can get started quickly without managing infrastructure.\\n- You only pay for the services you use, with pricing based on input/output tokens and whether you purchase provisioned throughput for a model.\\n\\nSo in summary, Amazon Bedrock is an AWS service that gives developers access to state-of-the-art foundation models from multiple providers through a unified API and set of tools for building generative AI applications.'}, 'sessionId': '00bac82d-2f01-4aa4-b90f-c3d0bbf9b8c0'}\n"
     ]
    }
   ],
   "source": [
    "# Knowledge BAse ID\n",
    "\n",
    "query = 'What is Amazon Bedrock?'\n",
    "#query = \"Is it possible to purchase provisioned throughput for Anthropic Claude Sonnet on Amazon Bedrock?\"\n",
    "\n",
    "model_response = retrieve_and_generate_with_guardrail(query, kb_id)\n",
    "\n",
    "print(model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56677a75-464c-453b-b2bd-7813f2a65d1a",
   "metadata": {},
   "source": [
    "# Evaluating RAG with RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e33826a-0836-4ad1-9553-dcb7df3f87c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_249/422286211.py:22: LangChainDeprecationWarning: The class `BedrockEmbeddings` was deprecated in LangChain 0.2.11 and will be removed in 1.0. An updated version of the class exists in the langchain-aws package and should be used instead. To use it run `pip install -U langchain-aws` and import as `from langchain_aws import BedrockEmbeddings`.\n",
      "  bedrock_embeddings = BedrockEmbeddings(model_id=embedding_model_id,client=bedrock_client)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain_community.chat_models.bedrock import BedrockChat\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config\n",
    "                              )\n",
    "\n",
    "llm_for_text_generation = BedrockChat(model_id=llm_model_id, client=bedrock_client)\n",
    "\n",
    "llm_for_evaluation = BedrockChat(model_id=llm_model_id, client=bedrock_client)\n",
    "\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=embedding_model_id,client=bedrock_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3511743-c8c2-4e3c-949a-79bf9bec79cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question/prompt</th>\n",
       "      <th>Correct answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are all models accessible on Amazon Bedrock by default?</td>\n",
       "      <td>Access to Amazon Bedrock foundation models isn't granted by default. You can request access, or modify access, to foundation models only by using the Amazon Bedrock console. First, make sure the IAM role that you use has sufficent IAM permissions to manage access to foundation models. Then, add or remove access to a model by following the instructions at Add or remove access to Amazon Bedrock foundation models.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Model ID of Amazon Titan Text Premier</td>\n",
       "      <td>amazon.titan-text-premier-v1:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With which Anthropic Claude models can I use the Text Completions API?</td>\n",
       "      <td>Anthropic Claude Instant v1.2, Anthropic Claude v2, Anthropic Claude v2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What policies can I configure in Amazon Bedrock guardrails?</td>\n",
       "      <td>You can configure the following policies in a guardrail to avoid undesirable and harmful content and remove sensitive information for privacy protection. Content filters – Adjust filter strengths to block input prompts or model responses containing harmful content.<br>Denied topics – Define a set of topics that are undesirable in the context of your application. These topics will be blocked if detected in user queries or model responses.<br>Word filters – Configure filters to block undesirable words, phrases, and profanity. Such words can include offensive terms, competitor names etc.<br>Sensitive information filters – Block or mask sensitive information such as personally identifiable information (PII) or custom regex in user inputs and model responses.<br>Contextual grounding check – Detect and filter hallucinations in model responses based on grounding in a source and relevance to the user query.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which built in datasets are available on Amazon Bedrock for model evaluation of text generation?</td>\n",
       "      <td>The following built-in datasets contain prompts that are well-suited for use in general text generation tasks. Bias in Open-ended Language Generation Dataset (BOLD)<br>The Bias in Open-ended Language Generation Dataset (BOLD) is a dataset that evaluates fairness in general text generation, focusing on five domains: profession, gender, race, religious ideologies, and political ideologies. It contains 23,679 different text generation prompts.<br><br>RealToxicityPrompts<br>RealToxicityPrompts is a dataset that evaluates toxicity. It attempts to get the model to generate racist, sexist, or otherwise toxic language. This dataset contains 100,000 different text generation prompts.<br><br>T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples (TREX)<br>TREX is dataset consisting of Knowledge Base Triples (KBTs) extracted from Wikipedia. KBTs are a type of data structure used in natural language processing (NLP) and knowledge representation. They consist of a subject, predicate, and object, where the subject and object are linked by a relation. An example of a Knowledge Base Triple (KBT) is \"George Washington was the president of the United States\". The subject is \"George Washington\", the predicate is \"was the president of\", and the object is \"the United States\".<br><br>WikiText2<br>WikiText2 is a HuggingFace dataset that contains prompts used in general text generation.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('data/bedrock-user-guide-test.csv')\n",
    "test = test.dropna()\n",
    "test.style.set_properties(**{'text-align': 'left', 'border': '1px solid black'})\n",
    "test.to_string(justify='left', index=False)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    pretty_print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0a5f15a-8053-4edc-97e5-c6b96641c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = test['Question/prompt'].tolist()\n",
    "ground_truths = [[gt] for gt in test['Correct answer'].tolist()]\n",
    "\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    response = ask_bedrock_llm_with_knowledge_base(query, kb_id)\n",
    "    generatedResult = response['output']['text']\n",
    "    answers.append(generatedResult)\n",
    "    contexts.append([doc['content']['text'] for doc in response['citations'][0]['retrievedReferences']])\n",
    "\n",
    "# To dict\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b16eb532-3c65-4adf-b6f2-cab77d11cc81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Dataset' has no attribute 'from_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#specify the metrics here, kept one for now, we can add more.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m         answer_relevancy\n\u001b[1;32m     17\u001b[0m     ]\n\u001b[0;32m---> 19\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_for_evaluation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbedrock_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m ragas_df \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mto_pandas()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ragas/evaluation.py:253\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     result \u001b[38;5;241m=\u001b[39m Result(\n\u001b[0;32m--> 253\u001b[0m         scores\u001b[38;5;241m=\u001b[39m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_list\u001b[49m(scores),\n\u001b[1;32m    254\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m    255\u001b[0m         binary_columns\u001b[38;5;241m=\u001b[39mbinary_metrics,\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluation_group_cm\u001b[38;5;241m.\u001b[39mended:\n\u001b[1;32m    258\u001b[0m         evaluation_rm\u001b[38;5;241m.\u001b[39mon_chain_end(result)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Dataset' has no attribute 'from_list'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_entity_recall,\n",
    "    answer_similarity,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "from ragas.metrics.critique import correctness\n",
    "\n",
    "#specify the metrics here, kept one for now, we can add more.\n",
    "metrics = [\n",
    "        answer_relevancy\n",
    "    ]\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=metrics,\n",
    "    llm=llm_for_evaluation,\n",
    "    embeddings=bedrock_embeddings,\n",
    ")\n",
    "\n",
    "ragas_df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c76503a5-36de-4365-a390-a37dba57c439",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ragas_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mragas_df\u001b[49m\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mset_properties(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-align\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mborder\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1px solid black\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      2\u001b[0m ragas_df\u001b[38;5;241m.\u001b[39mto_string(justify\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39moption_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ragas_df' is not defined"
     ]
    }
   ],
   "source": [
    "ragas_df.style.set_properties(**{'text-align': 'left', 'border': '1px solid black'})\n",
    "ragas_df.to_string(justify='left', index=False)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    pretty_print(ragas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb27ab",
   "metadata": {},
   "source": [
    "### <a >Challenge Exercise :: Try it Yourself! </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c62acdc",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto;\">\n",
    "    <br>\n",
    "    <p style=\"text-align: center; margin: auto;\"><b>Try the following exercises on this lab and note the observations.</b></p>\n",
    "<p style=\" text-align: left; margin: auto;\">\n",
    "<ol>\n",
    "    <li>Test the RAG based LLM with more questions about Amazon Bedrock. </li>\n",
    "<li>Look the the citations or retrieved references and see if the answer generated by the RAG chatbot aligns with these retrieved contexts. What response do you get when the retrieved context comes up empty? </li>\n",
    "<li>Apply system prompts to RAG as well as amazon Bedrock Guardrails and test which is more consistent in blocking responses when the model response is hallucinated </li>\n",
    "<li>Run the tutorial for RAG Checker and compare the difference with RAGAS evaluation framework: https://github.com/amazon-science/RAGChecker/blob/main/tutorial/ragchecker_tutorial_en.md </li>\n",
    "</ol>\n",
    "<br>\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc89ac-b0e8-438a-bba2-12bc3a4a3f94",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We now have an understanding of parameters which influence hallucinations in Large Language Models. We learnt how to set up Retrieval Augmented Generation to provide a context to the model while answering.\n",
    "We used Contextual grounding in Amazon Bedrock Guardrials to intervene when hallucinations are detected.\n",
    "Finally we looked into the metrics of RAGAS and how to use them to measure hallucinations in your RAG powered chatbot.\n",
    "\n",
    "In the next lab, we will:\n",
    "1. Build a custom hallucination detector\n",
    "2. Use Amazon Bedrock Agents to intervene when hallucinations are detected\n",
    "3. Call a human for support when the LLM hallucinates\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
